"""
å¤–è®¾æ–°å“ç›‘æ§æŠ¥å‘Šç”Ÿæˆç³»ç»Ÿ (Phase 4 æœ€ç»ˆä¼˜åŒ–ç‰ˆ)
åŠŸèƒ½ï¼šæ•°æ®æ¸…æ´—ã€LLM PMè§†è§’æ·±åº¦åˆ†æã€æ·±è‰²æå®¢é£ HTML æŠ¥å‘Šç”Ÿæˆ
"""

import pandas as pd
import json
import re
import os
import shutil
import subprocess
import sys
from datetime import datetime
from pathlib import Path
from difflib import SequenceMatcher
import requests
from typing import Dict, List, Optional, Any
from itertools import combinations

# ==================== é…ç½®åŒº ====================

# ç›®æ ‡å¹´æœˆé…ç½®
TARGET_YEAR = 2026
TARGET_MONTH = 1

# LLM API é…ç½®ï¼ˆå…¬å¸å†…éƒ¨ DeepSeek V3ï¼‰
LLM_CONFIG = {
    "provider": "deepseek",
    "api_key": "sk-xxx",  # å…¬å¸å†…éƒ¨ API Key
    "model": "xdeepseekv3",  # å†…éƒ¨æ¨¡å‹åç§°
    "base_url": "http://192.168.0.250:7777"  # å†…éƒ¨ API åœ°å€
}

# ==================== Top 15 æ ‡å‡†åŒ–æ•°æ® Schemaï¼ˆä¸­æ–‡ç‰ˆï¼‰====================

# ğŸ–±ï¸ é¼ æ ‡ Top 15 å‚æ•°å®šä¹‰ï¼ˆä¸­æ–‡ç‰ˆï¼‰
MOUSE_SCHEMA = {
    # äº§å“ä¸å®šä»·
    'product_pricing': 'äº§å“ä¸å®šä»·',
    # æ¨¡å…·è¡€ç»Ÿ
    'mold_lineage': 'æ¨¡å…·è¡€ç»Ÿ',
    # é‡é‡ä¸é‡å¿ƒ
    'weight_center': 'é‡é‡ä¸é‡å¿ƒ',
    # ä¼ æ„Ÿå™¨æ–¹æ¡ˆ
    'sensor_solution': 'ä¼ æ„Ÿå™¨æ–¹æ¡ˆ',
    # ä¸»æ§èŠ¯ç‰‡
    'mcu_chip': 'ä¸»æ§èŠ¯ç‰‡',
    # å›æŠ¥ç‡é…ç½®
    'polling_rate': 'å›æŠ¥ç‡é…ç½®',
    # å…¨é“¾è·¯å»¶è¿Ÿ
    'end_to_end_latency': 'å…¨é“¾è·¯å»¶è¿Ÿ',
    # å¾®åŠ¨ç‰¹æ€§
    'switch_features': 'å¾®åŠ¨ç‰¹æ€§',
    # æ»šè½®ç¼–ç å™¨
    'scroll_encoder': 'æ»šè½®ç¼–ç å™¨',
    # æ¶‚å±‚å·¥è‰º
    'coating_process': 'æ¶‚å±‚å·¥è‰º',
    # é«˜åˆ·ç»­èˆª
    'high_refresh_battery': 'é«˜åˆ·ç»­èˆª',
    # ç»“æ„åšå·¥
    'structure_quality': 'ç»“æ„åšå·¥',
    # è„šè´´é…ç½®
    'feet_config': 'è„šè´´é…ç½®',
    # æ— çº¿æŠ—å¹²æ‰°
    'wireless_interference': 'æ— çº¿æŠ—å¹²æ‰°',
    # é©±åŠ¨ä½“éªŒ
    'driver_experience': 'é©±åŠ¨ä½“éªŒ'
}

# âŒ¨ï¸ é”®ç›˜ Top 15 å‚æ•°å®šä¹‰ï¼ˆä¸­æ–‡ç‰ˆï¼‰
KEYBOARD_SCHEMA = {
    # äº§å“ä¸é…åˆ—
    'product_layout': 'äº§å“ä¸é…åˆ—',
    # ç»“æ„å½¢å¼
    'structure_form': 'ç»“æ„å½¢å¼',
    # æŠ€æœ¯è·¯çº¿
    'tech_route': 'æŠ€æœ¯è·¯çº¿',
    # RTå‚æ•°
    'rt_params': 'RTå‚æ•°',
    # å£°éŸ³åŒ…å¡«å……
    'sound_dampening': 'å£°éŸ³åŒ…å¡«å……',
    # è½´ä½“è¯¦è§£
    'switch_details': 'è½´ä½“è¯¦è§£',
    # å®æµ‹å»¶è¿Ÿ
    'measured_latency': 'å®æµ‹å»¶è¿Ÿ',
    # é”®å¸½å·¥è‰º
    'keycap_craftsmanship': 'é”®å¸½å·¥è‰º',
    # å¤§é”®è°ƒæ ¡
    'bigkey_tuning': 'å¤§é”®è°ƒæ ¡',
    # PCBç‰¹æ€§
    'pcb_features': 'PCBç‰¹æ€§',
    # å¤–å£³å·¥è‰º
    'case_craftsmanship': 'å¤–å£³å·¥è‰º',
    # å‰é«˜æ•°æ®
    'front_height': 'å‰é«˜æ•°æ®',
    # ç”µæ± æ•ˆç‡
    'battery_efficiency': 'ç”µæ± æ•ˆç‡',
    # è¿æ¥ä¸æ”¶çº³
    'connection_storage': 'è¿æ¥ä¸æ”¶çº³',
    # è½¯ä½“æ”¯æŒ
    'software_support': 'è½¯ä½“æ”¯æŒ'
}

# å…³é”®å­—æ®µå®šä¹‰ï¼ˆç”¨äºæ£€æŸ¥å®Œæ•´æ€§ï¼‰
MOUSE_CRITICAL_FIELDS = ['product_pricing', 'mold_lineage', 'weight_center', 'sensor_solution', 'polling_rate']
KEYBOARD_CRITICAL_FIELDS = ['product_layout', 'structure_form', 'switch_details', 'tech_route']

# Schema æ˜ å°„ï¼ˆç”¨äºå¿«é€Ÿè®¿é—®ï¼‰
CATEGORY_SCHEMAS = {
    'é¼ æ ‡': MOUSE_SCHEMA,
    'é”®ç›˜': KEYBOARD_SCHEMA
}

# å…³é”®è¯åˆ—è¡¨ï¼ˆç™½åå•ï¼‰
KEYWORDS = [
    "é¼ æ ‡", "é”®ç›˜", "é”®é¼ ", "å®¢åˆ¶åŒ–", "è½´ä½“",
    "æœºæ¢°é”®ç›˜", "ç£è½´", "æ‰‹æŸ„"
]

# é»‘åå•å…³é”®è¯ï¼ˆç›´æ¥è¿‡æ»¤æ‰ - ä»…ä¿ç•™é”®ç›˜å’Œé¼ æ ‡ï¼‰
BLACKLIST = [
    "é¼ æ ‡å«", "æ¡Œå«", "çº¿æ", "æ”¶çº³åŒ…", "è€³æœºæ¶", "è€³æœºæ¶",
    "ç†çº¿å™¨", "è„šè´´", "é˜²æ»‘è´´", "æ‰‹æ‰˜", "è…•æ‰˜",
    "è€³æœº", "è€³æœº", "éŸ³ç®±", "æ‰¬å£°å™¨", "éº¦å…‹é£", "æ‘„åƒå¤´",
    "æ˜¾ç¤ºå™¨", "æ”¯æ¶", "hub", "é›†çº¿å™¨", "æ‰©å±•å"
]

# ==================== å­—æ®µå€¼åˆ¤å®šæ ‡å‡† (å£å¾„-å®ç°ä¸€è‡´æ€§) ====================
"""
æ€»åŸåˆ™: å±•ç¤ºæœ‰æ•ˆ vs ç»Ÿè®¡æœ‰æ•ˆ

- å±•ç¤ºæœ‰æ•ˆ: ç”¨äºå‰ç«¯å›¾è¡¨æ˜¾ç¤ºï¼ŒåŒ…æ‹¬"æœªå…¬å¼€"ã€"å¾…å®æµ‹"ç­‰æè¿°æ€§å€¼
- ç»Ÿè®¡æœ‰æ•ˆ: ç”¨äº coverage è®¡ç®—ï¼Œä»…åŒ…æ‹¬æœ‰å®é™…å†…å®¹çš„å€¼

ä¸‰ç§åˆ¤å®šå‡½æ•°:
1. is_coverage_value(): ç»Ÿè®¡æœ‰æ•ˆ â†’ ç”¨äº coverage è®¡ç®—çš„åˆ†å­
2. bucket_value(): å±•ç¤ºæœ‰æ•ˆ â†’ ç”¨äºå›¾è¡¨åˆ†æ¡¶
3. is_display_value(): å‰ç«¯æ˜¾ç¤º â†’ ç”¨äºå‰ç«¯å±•ç¤ºï¼ˆè¿‡æ»¤"æœªæåŠ"ç­‰ï¼‰
"""

# å®Œå…¨æ— æ•ˆå€¼ (ä¸è®¡å…¥ä»»ä½•ç»Ÿè®¡)
INVALID_VALUES = ['', 'null', 'none', 'unknown', 'N/A', 'æœªçŸ¥']

# ç»Ÿè®¡æ— æ•ˆä½†å±•ç¤ºæœ‰æ•ˆçš„å€¼ (ä¸è®¡å…¥ coverage åˆ†å­ï¼Œä½†è®¡å…¥å›¾è¡¨æ¡¶)
BUCKET_ONLY_VALUES = ['æœªå…¬å¼€', 'å¾…å®š', 'å¾…å®æµ‹', 'æš‚æ— ', 'TBD']

# ç»Ÿè®¡æœ‰æ•ˆå€¼ (è®¡å…¥ coverage åˆ†å­)
# åŒ…æ‹¬: ä»»ä½•å…·ä½“çš„å‚æ•°å€¼ (å¦‚ "PAW3395", "99å…ƒ", "æœ‰çº¿" ç­‰)

# ä»·æ ¼åˆ†æ¡¶ä¸“ç”¨: "æœªå…¬å¼€"æ¡¶åªæ¥å—è¿™äº›æ˜ç¡®æ ‡è®°
PRICE_UNDISCLOSED_MARKERS = ['æœªå…¬å¼€', 'å¾…å®š', 'æš‚æ— ', 'TBD', 'å¾…å…¬å¸ƒ']

# æ±‡ç‡é…ç½® (é»˜è®¤ä¸è·¨å¸ç§æ¢ç®—)
ENABLE_CURRENCY_CONVERSION = False
DEFAULT_CURRENCY = 'CNY'

EXCHANGE_RATES = {
    'USD': 7.2, '$': 7.2,
    'JPY': 0.048, 'Â¥': 0.048,
    'EUR': 7.8,
    'CNY': 1.0, 'Â¥': 1.0, 'å…ƒ': 1.0
}

# ==================== äºŒæ¬¡è¡¥å…¨é…ç½® (Phase 3 - å¿…ç»æµç¨‹) ====================
# [FIX E] äºŒæ¬¡è¡¥å…¨æ”¹ä¸ºå¿…ç»æµç¨‹ï¼Œä¸å†æ”¯æŒå¼€å…³å…³é—­
# ä»¥ä¸‹é…ç½®ä»…ç”¨äº"ä¸Šé™æ§åˆ¶/æˆæœ¬é™åˆ¶"ï¼Œä¸å½±å“æ˜¯å¦æ‰§è¡Œ

# å…¼å®¹æ€§æ£€æŸ¥ï¼šæ£€æµ‹ç”¨æˆ·æ˜¯å¦è®¾ç½®äº†å·²åºŸå¼ƒçš„å¼€å…³
_LEGACY_ENABLED_ENV = os.getenv('SECOND_ROUND_ENABLED', '').lower()
_LEGACY_COMPLETION_ENABLED_ENV = os.getenv('SECOND_ROUND_COMPLETION_ENABLED', '').lower()
_HAS_LEGACY_DISABLE_FLAG = (_LEGACY_ENABLED_ENV == 'false' or _LEGACY_COMPLETION_ENABLED_ENV == 'false')

# äºŒæ¬¡è¡¥å…¨æ¨¡å¼ï¼šlocal ä¸ºå¿…è·‘æ¨¡å¼
SECOND_ROUND_MODE = os.getenv('SECOND_ROUND_MODE', 'local')  # local|search|both
# æ³¨ï¼šlocal æ¨¡å¼å§‹ç»ˆæ‰§è¡Œï¼›search/both ä½œä¸ºå¢å¼ºæ¨¡å¼å åŠ 

# ä¸Šé™æ§åˆ¶é…ç½®
SECOND_ROUND_MAX_ITEMS = int(os.getenv('SECOND_ROUND_MAX_ITEMS', '10'))
SECOND_ROUND_MAX_FIELDS_PER_ITEM = int(os.getenv('SECOND_ROUND_MAX_FIELDS_PER_ITEM', '6'))
SECOND_ROUND_MAX_SEARCH_PER_PRODUCT = int(os.getenv('SECOND_ROUND_MAX_SEARCH_PER_PRODUCT', '2'))

# å…³é”®å­—æ®µå®šä¹‰ï¼ˆç”¨äºäºŒæ¬¡è¡¥å…¨ä¼˜å…ˆçº§æ’åºï¼‰
MOUSE_KEY_FIELDS_PRIORITY = ['sensor_solution', 'weight_center', 'polling_rate', 'connection_storage']
KEYBOARD_KEY_FIELDS_PRIORITY = ['switch_details', 'connection_storage', 'battery_efficiency', 'product_layout']

# å£å¾„ä¿æŠ¤ï¼šinferred æ˜¯å¦è®¡å…¥ coverageï¼ˆé»˜è®¤ falseï¼‰
COUNT_INFERRED_IN_COVERAGE = os.getenv('COUNT_INFERRED_IN_COVERAGE', 'false').lower() == 'true'

# ==================== å­—æ®µåˆ¤å®šå‡½æ•° ====================

def is_coverage_value(value: Any) -> bool:
    """
    åˆ¤æ–­å€¼æ˜¯å¦ç»Ÿè®¡æœ‰æ•ˆ (ç”¨äº coverage è®¡ç®—)

    è§„åˆ™:
        - éç©ºã€éçº¯ç©ºç™½
        - ä¸åœ¨ INVALID_VALUES ä¸­
        - ä¸åœ¨ BUCKET_ONLY_VALUES ä¸­ (å¦‚"æœªå…¬å¼€"ã€"å¾…å®æµ‹")
        - ä¸ä¸º "æœªæåŠ"ã€"æå–å¤±è´¥"ã€"æ— æ³•åˆ¤æ–­"

    ç”¨é€”:
        - è®¡ç®—è¦†ç›–ç‡: coverage = ç»Ÿè®¡æœ‰æ•ˆæ•° / æ€»æ•°
        - è¿‡æ»¤å‡ºæœ‰å®é™…å†…å®¹çš„å€¼ç”¨äºè´¨é‡è¯„ä¼°

    Args:
        value: å¾…åˆ¤æ–­çš„å€¼

    Returns:
        bool: True è¡¨ç¤ºç»Ÿè®¡æœ‰æ•ˆ

    ç¤ºä¾‹:
        >>> is_coverage_value("PAW3395")
        True
        >>> is_coverage_value("æœªå…¬å¼€")
        False  # "æœªå…¬å¼€"ä¸è®¡å…¥ coverage åˆ†å­
        >>> is_coverage_value("å¾…å®æµ‹")
        False  # "å¾…å®æµ‹"ä¸è®¡å…¥ coverage åˆ†å­
        >>> is_coverage_value("")
        False
    """
    if value is None:
        return False

    if not isinstance(value, (str, int, float, bool)):
        return False

    value_str = str(value).strip()

    # ç©ºå€¼
    if not value_str:
        return False

    # å®Œå…¨æ— æ•ˆå€¼
    if value_str.lower() in [v.lower() for v in INVALID_VALUES]:
        return False

    # å±•ç¤ºæœ‰æ•ˆä½†ç»Ÿè®¡æ— æ•ˆçš„å€¼
    if value_str in BUCKET_ONLY_VALUES:
        return False

    # æ˜ç¡®çš„"æ— æ•ˆæè¿°"
    if value_str in ['æœªæåŠ', 'æå–å¤±è´¥', 'æ— æ³•åˆ¤æ–­']:
        return False

    # å…¶ä»–ä»»ä½•å­—ç¬¦ä¸²éƒ½è§†ä¸ºç»Ÿè®¡æœ‰æ•ˆ
    return True


def bucket_value(value: Any) -> Optional[str]:
    """
    è·å–ç”¨äºå›¾è¡¨åˆ†æ¡¶çš„å€¼ (å±•ç¤ºæœ‰æ•ˆ)

    è§„åˆ™:
        - å®Œå…¨æ— æ•ˆå€¼ â†’ None (ä¸è®¡å…¥å›¾è¡¨)
        - "æœªå…¬å¼€"ç±»å€¼ â†’ "æœªå…¬å¼€" (å•ç‹¬æ¡¶)
        - "å¾…å®æµ‹"ç±»å€¼ â†’ "å¾…å®æµ‹" (å•ç‹¬æ¡¶)
        - å…¶ä»–å€¼ â†’ åŸå€¼

    ç”¨é€”:
        - å›¾è¡¨åˆ†æ¡¶ (å¦‚ä»·æ ¼åŒºé—´ã€ä¼ æ„Ÿå™¨åˆ†å¸ƒ)
        - å‰ç«¯å±•ç¤º

    Args:
        value: å¾…åˆ¤æ–­çš„å€¼

    Returns:
        Optional[str]: åˆ†æ¡¶å€¼ï¼ŒNone è¡¨ç¤ºä¸è®¡å…¥å›¾è¡¨

    ç¤ºä¾‹:
        >>> bucket_value("PAW3395")
        'PAW3395'
        >>> bucket_value("æœªå…¬å¼€")
        'æœªå…¬å¼€'
        >>> bucket_value("")
        None  # ç©ºå€¼ä¸è®¡å…¥å›¾è¡¨
        >>> bucket_value("æœªæåŠ")
        None  # "æœªæåŠ"ä¸è®¡å…¥å›¾è¡¨
    """
    if value is None:
        return None

    value_str = str(value).strip()

    # ç©ºå€¼
    if not value_str or value_str.lower() in [v.lower() for v in INVALID_VALUES]:
        return None

    # ç»Ÿè®¡æ— æ•ˆä½†å±•ç¤ºæœ‰æ•ˆçš„å€¼ (å½’å…¥å•ç‹¬æ¡¶)
    if value_str in BUCKET_ONLY_VALUES:
        return value_str

    # æ˜ç¡®çš„"æ— æ•ˆæè¿°"ä¸è®¡å…¥å›¾è¡¨
    if value_str in ['æœªæåŠ', 'æå–å¤±è´¥', 'æ— æ³•åˆ¤æ–­']:
        return None

    return value_str


def is_display_value(value: Any) -> bool:
    """
    åˆ¤æ–­å€¼æ˜¯å¦å‰ç«¯æ˜¾ç¤ºæœ‰æ•ˆ

    è§„åˆ™:
        - éç©º
        - ä¸åœ¨ INVALID_VALUES ä¸­
        - ä¸ä¸º "æœªæåŠ"ã€"æå–å¤±è´¥"ã€"æ— æ³•åˆ¤æ–­"
        - "æœªå…¬å¼€"ã€"å¾…å®æµ‹" ç­‰å¯ä»¥æ˜¾ç¤º

    ç”¨é€”:
        - å‰ç«¯å±•ç¤ºæ—¶è¿‡æ»¤æ— æ•ˆå€¼
        - ç”Ÿæˆ HTML æ—¶åˆ¤æ–­æ˜¯å¦æ˜¾ç¤ºè¯¥å­—æ®µ

    Args:
        value: å¾…åˆ¤æ–­çš„å€¼

    Returns:
        bool: True è¡¨ç¤ºå‰ç«¯æ˜¾ç¤ºæœ‰æ•ˆ

    ç¤ºä¾‹:
        >>> is_display_value("PAW3395")
        True
        >>> is_display_value("æœªå…¬å¼€")
        True  # "æœªå…¬å¼€"å¯ä»¥æ˜¾ç¤º
        >>> is_display_value("æœªæåŠ")
        False  # "æœªæåŠ"ä¸æ˜¾ç¤º
        >>> is_display_value("")
        False
    """
    if value is None:
        return False

    value_str = str(value).strip()

    # ç©ºå€¼
    if not value_str:
        return False

    # å®Œå…¨æ— æ•ˆå€¼
    if value_str.lower() in [v.lower() for v in INVALID_VALUES]:
        return False

    # æ˜ç¡®çš„"æ— æ•ˆæè¿°"ä¸æ˜¾ç¤º
    if value_str in ['æœªæåŠ', 'æå–å¤±è´¥', 'æ— æ³•åˆ¤æ–­']:
        return False

    # å…¶ä»–ä»»ä½•å­—ç¬¦ä¸²éƒ½æ˜¾ç¤º (åŒ…æ‹¬"æœªå…¬å¼€"ã€"å¾…å®æµ‹")
    return True


def normalize_innovation_tags(tags: List[str]) -> List[str]:
    """
    å½’ä¸€åŒ–åˆ›æ–°æ ‡ç­¾

    è§„åˆ™:
        1. å»æ‰ # å‰ç¼€
        2. å…¨åŠè§’ç»Ÿä¸€ (# ï¼ƒ â†’ #)
        3. å»é‡
        4. è¿‡æ»¤ç©ºæ ‡ç­¾

    Args:
        tags: åŸå§‹æ ‡ç­¾åˆ—è¡¨

    Returns:
        List[str]: å½’ä¸€åŒ–åçš„æ ‡ç­¾åˆ—è¡¨

    ç¤ºä¾‹:
        >>> normalize_innovation_tags(["#å·ç‹", "ï¼ƒç£è½´", "ç£è½´"])
        ['å·ç‹', 'ç£è½´']
    """
    if not tags:
        return []

    normalized = []
    seen = set()

    for tag in tags:
        if not isinstance(tag, str):
            continue

        # å»æ‰ # å‰ç¼€
        tag = tag.lstrip('#')

        # å…¨åŠè§’ç»Ÿä¸€ (ï¼ƒ â†’ #, å…¨è§’ç©ºæ ¼ â†’ åŠè§’ç©ºæ ¼)
        tag = tag.replace('ï¼ƒ', '#').replace('ã€€', ' ').replace('ï¼Œ', ',').strip()

        # å»é‡
        if tag and tag not in seen:
            seen.add(tag)
            normalized.append(tag)

    return normalized


# ==================== äºŒæ¬¡è¡¥å…¨æ¡†æ¶ (Phase 3 - å¯ç”¨åŠŸèƒ½) ====================
# [FIX D] äºŒæ¬¡è¡¥å…¨æ¡†æ¶ - æ£€æµ‹ç¼ºå¤±å­—æ®µ + åŒæºè¡¥å…¨ + è·¨æºè¡¥å…¨(å¯é€‰)

def detect_missing_fields(products: List[Dict]) -> List[Dict]:
    """
    [FIX B] æ£€æµ‹äº§å“ä¸­ç¼ºå¤±çš„å…³é”®å­—æ®µï¼Œè¾“å‡ºè¡¥å…¨è®¡åˆ’

    Args:
        products: äº§å“åˆ—è¡¨

    Returns:
        List[Dict]: è¡¥å…¨è®¡åˆ’ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«:
            - product_id: äº§å“ç´¢å¼•
            - product_name: äº§å“åç§°
            - category: å“ç±»
            - missing_fields: ç¼ºå¤±å­—æ®µåˆ—è¡¨
            - reason_map: å­—æ®µ->ç¼ºå¤±åŸå› æ˜ å°„
    """
    missing_plan = []

    for idx, product in enumerate(products):
        category = product.get('category', '')
        specs = product.get('specs', {})

        # æ ¹æ®å“ç±»ç¡®å®šå…³é”®å­—æ®µ
        if category == 'é¼ æ ‡':
            critical_fields = MOUSE_CRITICAL_FIELDS
        elif category == 'é”®ç›˜':
            critical_fields = KEYBOARD_CRITICAL_FIELDS
        else:
            continue

        missing = []
        reason_map = {}

        for field in critical_fields:
            value = specs.get(field, '')
            value_str = str(value).lower().strip() if value else ''

            # [FIX B.1] åˆ¤å®šå­—æ®µçŠ¶æ€
            if not value or not value_str:
                # ç©ºå€¼ â†’ éœ€è¦è¡¥å…¨
                missing.append(field)
                reason_map[field] = 'missing'
            elif any(marker in value_str for marker in [
                'æœªæåŠ', 'åŸæ–‡æœªæåŠ', 'æœªæä¾›', 'æå–å¤±è´¥', 'æ— æ³•åˆ¤æ–­'
            ]):
                # ç¼ºå¤±çŠ¶æ€ â†’ éœ€è¦è¡¥å…¨
                missing.append(field)
                reason_map[field] = 'extract_failed'
            elif any(marker in value_str for marker in [
                'æœªå…¬å¼€', 'tbd', 'å¾…å…¬å¸ƒ'
            ]):
                # æœªå…¬å¼€ â†’ ä¸éœ€è¦è¡¥å…¨ï¼ˆå‚å•†ç¡®å®æ²¡å…¬å¸ƒï¼‰
                reason_map[field] = 'undisclosed'
            elif any(marker in value_str for marker in [
                'å¾…å®æµ‹', 'é¢„ä¼°', 'æ¨æ–­', 'æ¨æµ‹'
            ]):
                # å¾…å®æµ‹/é¢„ä¼° â†’ æš‚ä¸éœ€è¦è¡¥å…¨
                reason_map[field] = 'pending'
            # else: æœ‰æ˜ç¡®å€¼ï¼Œä¸éœ€è¦å¤„ç†

        if missing:
            # [FIX B.3] æŒ‰ä¼˜å…ˆçº§æ’åºç¼ºå¤±å­—æ®µ
            priority_fields = MOUSE_KEY_FIELDS_PRIORITY if category == 'é¼ æ ‡' else KEYBOARD_KEY_FIELDS_PRIORITY
            missing.sort(key=lambda f: priority_fields.index(f) if f in priority_fields else 999)

            missing_plan.append({
                'product_id': idx,
                'product_name': product.get('product_name', 'Unknown')[:50],
                'category': category,
                'missing_fields': missing,
                'reason_map': reason_map
            })

    return missing_plan


def _extract_from_html_or_text(text: str, field: str, category: str) -> Dict:
    """
    [FIX C.2] ä»æ–‡ç« å†…å®¹ä¸­æå–å­—æ®µå€¼ï¼ˆè§„åˆ™/æ­£åˆ™ä¼˜å…ˆï¼‰

    Args:
        text: æ–‡ç« å†…å®¹
        field: ç›®æ ‡å­—æ®µå
        category: å“ç±»

    Returns:
        Dict: {value, evidence_snippet, confidence, source}
    """
    if not text:
        return {'value': None, 'evidence_snippet': '', 'confidence': None, 'source': 'local'}

    text_lower = text.lower()

    # å®šä¹‰å­—æ®µæå–è§„åˆ™ï¼ˆæ­£åˆ™è¡¨è¾¾å¼ï¼‰
    extraction_rules = {
        # é¼ æ ‡å­—æ®µ
        'sensor_solution': [
            (r'(?:PAW|paw)(\d{4})', 'PAWä¼ æ„Ÿå™¨'),
            (r'(?:HERO|Hero)(?:\s*)(\d+[kK]?)', 'Heroç³»åˆ—'),
            (r'(?:PMW|pmw)(\d{4})', 'PMWä¼ æ„Ÿå™¨'),
            (r'(?:åŸç›¸|pixart)[^ã€‚]{0,30}?(\d{4})', 'åŸç›¸ä¼ æ„Ÿå™¨'),
        ],
        'weight_center': [
            (r'é‡é‡[ï¼š:]\s*(\d+(?:\.\d+)?)\s*[ggå…‹]', 'é‡é‡'),
            (r'(\d+(?:\.\d+)?)\s*[ggå…‹](?:\s*é‡é‡)', 'é‡é‡'),
            (r'è£¸é‡[ï¼š:]\s*(\d+(?:\.\d+)?)\s*[ggå…‹]', 'è£¸é‡'),
        ],
        'polling_rate': [
            (r'(?:å›æŠ¥ç‡|åˆ·æ–°ç‡)[ï¼š:]\s*(1000|2000|4000|8000)\s*[hH][zZ]', 'å›æŠ¥ç‡'),
            (r'(1000|2000|4000|8000)\s*[hH][zZ](?:\s*(?:å›æŠ¥ç‡|åˆ·æ–°ç‡))', 'å›æŠ¥ç‡'),
        ],
        'connection_storage': [
            (r'(?:è¿æ¥|æ”¯æŒ)[^ã€‚]{0,50}?((?:æœ‰çº¿|æ— çº¿|è“ç‰™|2\.4G)[^ã€‚]{0,30})', 'è¿æ¥æ–¹å¼'),
            (r'(?:ä¸‰æ¨¡|åŒæ¨¡)(?:è¿æ¥)?[^ã€‚]{0,30}', 'è¿æ¥æ–¹å¼'),
        ],
        # é”®ç›˜å­—æ®µ
        'switch_details': [
            (r'(?:è½´ä½“)[ï¼š:][^ã€‚]{1,50}?((?:ä½³éš†|å‡¯å|TTC|cherry)[^ã€‚]{0,30})', 'è½´ä½“'),
            (r'(?:ç£è½´|æœºæ¢°è½´|é™ç”µå®¹|å…‰è½´)[^ã€‚]{0,30}', 'è½´ä½“ç±»å‹'),
        ],
        'product_layout': [
            (r'(?:é…åˆ—|å¸ƒå±€)[ï¼š:]\s*(\d+[%ï¼…]?é…åˆ—|å…¨å°ºå¯¸|75%|80%|87%|60%|40%|96%)', 'é…åˆ—'),
            (r'(?:å…¨å°ºå¯¸|75%|80%|87%|60%|40%|96%)(?:\s*(?:é…åˆ—|å¸ƒå±€|é”®ç›˜))', 'é…åˆ—'),
        ],
        'battery_efficiency': [
            (r'(?:ç”µæ± |ç»­èˆª)[ï¼š:][^ã€‚]{0,50}?(\d+(?:\.\d+)?\s*[mM][aA][hH])', 'ç”µæ± å®¹é‡'),
            (r'(?:ç»­èˆª)[ï¼š:]\s*(\d+(?:\.\d+)?\s*[å°æ—¶h]+)', 'ç»­èˆªæ—¶é—´'),
        ],
    }

    # è·å–è¯¥å­—æ®µçš„æå–è§„åˆ™
    rules = extraction_rules.get(field, [])

    for pattern, desc in rules:
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            value = match.group(1) if match.groups() else match.group(0)

            # æå–è¯æ®ç‰‡æ®µï¼ˆåŒ¹é…ä½ç½®å‰åå„30å­—ç¬¦ï¼‰
            start, end = match.span()
            snippet_start = max(0, start - 30)
            snippet_end = min(len(text), end + 30)
            evidence = text[snippet_start:snippet_end].replace('\n', ' ').strip()

            return {
                'value': value,
                'evidence_snippet': evidence,
                'confidence': 'explicit',
                'source': 'local',
                'method': 'regex'
            }

    # è§„åˆ™æœªå‘½ä¸­ï¼Œè¿”å› Noneï¼ˆéœ€è¦ LLM æå–ï¼‰
    return {'value': None, 'evidence_snippet': '', 'confidence': None, 'source': 'local'}


def _extract_with_llm(text: str, field: str, category: str) -> Dict:
    """
    [FIX C.2] ä½¿ç”¨ LLM ä»è¯æ®ç‰‡æ®µä¸­æå–å­—æ®µå€¼

    [FIX E] å¼ºçº¦æŸéªŒè¯ï¼š
        - è¾“å‡ºå¿…é¡»å« confidenceï¼ˆinferred/missingï¼‰ä¸ evidence_snippet
        - evidence_snippet ä¸åŒ…å«æ˜ç¡®çº¿ç´¢æ—¶å¿…é¡»è¿”å› missingï¼ˆç¦æ­¢çŒœæµ‹ï¼‰

    Args:
        text: æ–‡ç« å†…å®¹
        field: ç›®æ ‡å­—æ®µå
        category: å“ç±»

    Returns:
        Dict: {value, evidence_snippet, confidence, source, method}
    """
    # æˆªå–åŒ…å«å…³é”®è¯çš„ä¸Šä¸‹æ–‡ï¼ˆ3-8å¥è¯ï¼‰
    field_keywords = {
        'sensor_solution': ['ä¼ æ„Ÿå™¨', 'æ„Ÿå…‰', 'ä¸»æ§', 'PAW', 'PMW', 'Hero'],
        'weight_center': ['é‡é‡', 'å…‹', 'g', 'gÂ±'],
        'polling_rate': ['å›æŠ¥ç‡', 'Hz', 'åˆ·æ–°', '1000', '2000', '4000', '8000'],
        'connection_storage': ['è¿æ¥', 'æ— çº¿', 'è“ç‰™', 'æœ‰çº¿', 'ä¸‰æ¨¡', 'åŒæ¨¡', '2.4G'],
        'switch_details': ['è½´ä½“', 'è½´', 'å¼€å…³', 'ä½³éš†', 'å‡¯å', 'TTC', 'cherry', 'ç£è½´'],
        'product_layout': ['é…åˆ—', 'å¸ƒå±€', 'å°ºå¯¸', 'é”®æ•°', '75%', '80%', '87%', '60%', '96%'],
        'battery_efficiency': ['ç”µæ± ', 'ç»­èˆª', 'mAh', 'å°æ—¶', 'å¤©'],
    }

    keywords = field_keywords.get(field, [field])

    # æŸ¥æ‰¾åŒ…å«å…³é”®è¯çš„å¥å­
    sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\n]', text)
    evidence_sentences = []
    for sentence in sentences:
        if any(kw in sentence for kw in keywords):  # ä¸ä½¿ç”¨ lower() ä¿ç•™ä¸­æ–‡å…³é”®è¯
            evidence_sentences.append(sentence.strip())
            if len(evidence_sentences) >= 3:
                break

    if not evidence_sentences:
        return {'value': None, 'evidence_snippet': '', 'confidence': 'missing', 'source': 'local'}

    evidence_text = 'ã€‚'.join(evidence_sentences[:5])  # æœ€å¤š5å¥

    # æ„é€  LLM æç¤ºï¼ˆå¼ºè°ƒä¸¥æ ¼æå–ï¼‰
    prompt = f"""ä»ä»¥ä¸‹æ–‡ç« ç‰‡æ®µä¸­æå–"{field}"å­—æ®µçš„å€¼ã€‚

ã€é‡è¦çº¦æŸã€‘ï¼š
1. åªä»æä¾›çš„ç‰‡æ®µä¸­æå–ï¼Œå¦‚æœç‰‡æ®µä¸­æ²¡æœ‰æ˜ç¡®ä¿¡æ¯åˆ™è¿”å› null
2. ä¸¥ç¦çŒœæµ‹æˆ–æ¨æ–­ï¼Œä¸ç¡®å®šæ—¶è¿”å› null
3. å¿…é¡»è¿”å›å…·ä½“çš„æ•°å€¼æˆ–å‹å·ï¼Œä¸èƒ½æ˜¯æ¨¡ç³Šæè¿°

å“ç±»: {category}
ç›®æ ‡å­—æ®µ: {field}

æ–‡ç« ç‰‡æ®µ:
{evidence_text}

è¯·ä»¥ JSON æ ¼å¼è¾“å‡ºï¼š
{{
  "value": "æå–çš„å…·ä½“å€¼ï¼ˆå¦‚æœç‰‡æ®µä¸­æ²¡æœ‰æ˜ç¡®ä¿¡æ¯åˆ™è¿”å› nullï¼‰",
  "evidence_snippet": "æ”¯æŒè¯¥å€¼çš„åŸæ–‡ç‰‡æ®µï¼ˆç›´æ¥å¼•ç”¨ï¼‰"
}}
"""

    try:
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {LLM_CONFIG['api_key']}"
        }
        data = {
            "model": LLM_CONFIG["model"],
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.0,  # é™ä½éšæœºæ€§ï¼Œæ›´ä¸¥æ ¼
            "max_tokens": 500
        }
        base_url = LLM_CONFIG["base_url"].rstrip('/')
        url = f"{base_url}/v1/chat/completions"

        response = requests.post(url, headers=headers, json=data, timeout=30)
        response.raise_for_status()
        result = response.json()

        content = result["choices"][0]["message"]["content"]

        # è§£æ JSON å“åº”
        json_match = re.search(r'\{[^}]+\}', content, re.DOTALL)
        if json_match:
            extracted = json.loads(json_match.group(0))
            value = extracted.get('value')
            snippet = extracted.get('evidence_snippet', '')

            # [FIX E] å¼ºçº¦æŸéªŒè¯ï¼šå¿…é¡»æœ‰æ˜ç¡®çš„çº¿ç´¢
            if value and value.lower() not in ['null', 'none', 'æœªçŸ¥', 'æœªæåŠ', 'n/a', '']:
                # éªŒè¯ evidence_snippet æ˜¯å¦åŒ…å«ç›¸å…³å…³é”®è¯
                snippet_lower = snippet.lower()
                has_keyword = any(kw.lower() in snippet_lower for kw in keywords)

                # éªŒè¯å€¼æœ¬èº«æ˜¯å¦åŒ…å«å…·ä½“ä¿¡æ¯ï¼ˆä¸æ˜¯æ¨¡ç³Šæè¿°ï¼‰
                value_lower = str(value).lower()
                is_vague = any(marker in value_lower for marker in [
                    'æœªçŸ¥', 'æœªæåŠ', 'æœªå…¬å¼€', 'æš‚æ— ', 'å¾…å®š', 'tbd', 'ä¸è¯¦',
                    'å¯èƒ½', 'æˆ–è®¸', 'åº”è¯¥', 'ä¼°è®¡'
                ])

                if has_keyword and not is_vague:
                    # é€šè¿‡éªŒè¯ï¼šè¿”å› inferred ç»“æœ
                    return {
                        'value': value,
                        'evidence_snippet': snippet[:200] if snippet else evidence_text[:100],
                        'confidence': 'inferred',
                        'source': 'local',
                        'method': 'llm'
                    }
                else:
                    # æœªé€šè¿‡éªŒè¯ï¼šè¯æ®ä¸è¶³ï¼Œè¿”å› missing
                    print(f"      [LLMéªŒè¯å¤±è´¥] {field}: è¯æ®ä¸è¶³ï¼ˆæ— æ˜ç¡®å…³é”®è¯æˆ–å€¼æ¨¡ç³Šï¼‰")
                    return {'value': None, 'evidence_snippet': '', 'confidence': 'missing', 'source': 'local'}
            else:
                # LLM è¿”å› null æˆ–æ— æ•ˆå€¼
                return {'value': None, 'evidence_snippet': '', 'confidence': 'missing', 'source': 'local'}

    except Exception as e:
        print(f"      [LLMæå–å¤±è´¥] {field}: {str(e)[:50]}")

    return {'value': None, 'evidence_snippet': '', 'confidence': 'missing', 'source': 'local'}


def enrich_missing_fields_local(products: List[Dict], missing_plan: List[Dict]) -> tuple:
    """
    [FIX C] P0 åŒæºè¡¥å…¨ - ä»å·²æŠ“å–æ–‡ç« å†…å®¹ä¸­æå–å­—æ®µå€¼

    [FIX E] æ”¹ä¸ºå¿…ç»æµç¨‹ï¼Œå§‹ç»ˆæ‰§è¡Œ

    Args:
        products: äº§å“åˆ—è¡¨
        missing_plan: ç¼ºå¤±å­—æ®µè®¡åˆ’

    Returns:
        tuple: (enriched_products, stats)
            - enriched_products: è¡¥å…¨åçš„äº§å“åˆ—è¡¨
            - stats: ç»Ÿè®¡ä¿¡æ¯ {total_enriched, fields_by_method}
    """
    # [FIX E] ç§»é™¤å¼€å…³æ£€æŸ¥ï¼Œå§‹ç»ˆæ‰§è¡Œ
    # ä»…åœ¨ search æ¨¡å¼ä¸‹è·³è¿‡ local è¡¥å…¨ï¼ˆä½† search æ¨¡å¼å°šæœªå®ç°ï¼‰
    if SECOND_ROUND_MODE == 'search':
        print("\n[äºŒæ¬¡è¡¥å…¨-åŒæº] è·³è¿‡ï¼ˆsearch æ¨¡å¼ä»…æ‰§è¡Œè·¨æºè¡¥å…¨ï¼ŒåŠŸèƒ½é¢„ç•™ä¸­ï¼‰")
        return products, {'total_enriched': 0, 'fields_by_method': {}}

    print(f"\n[äºŒæ¬¡è¡¥å…¨-åŒæº] å¼€å§‹å¤„ç† {len(missing_plan)} ä¸ªäº§å“çš„ç¼ºå¤±å­—æ®µ...")

    enriched_products = products.copy()
    stats = {
        'total_enriched': 0,
        'fields_by_method': {'regex': 0, 'llm': 0},
        'products_enriched': 0
    }

    max_items = min(len(missing_plan), SECOND_ROUND_MAX_ITEMS)

    for item in missing_plan[:max_items]:
        product_id = item['product_id']
        product = enriched_products[product_id]
        missing_fields = item['missing_fields'][:SECOND_ROUND_MAX_FIELDS_PER_ITEM]

        # è·å–æ–‡ç« å†…å®¹
        content_text = product.get('combined_content', '') or product.get('content_text', '')

        if not content_text:
            continue

        enriched_count = 0
        product_enrichment = product.get('enrichment', {})

        # åˆå§‹åŒ– enrichment ç»“æ„
        if 'evidence' not in product_enrichment:
            product_enrichment['evidence'] = {}
        if 'field_status' not in product_enrichment:
            product_enrichment['field_status'] = {}

        for field in missing_fields:
            # [FIX C.2] è§„åˆ™/æ­£åˆ™ä¼˜å…ˆ
            result = _extract_from_html_or_text(content_text, field, item['category'])

            if result['value']:
                # å›å¡«å­—æ®µå€¼
                if 'specs' not in product:
                    product['specs'] = {}
                product['specs'][field] = result['value']

                # è®°å½•è¯æ®
                product_enrichment['evidence'][field] = {
                    'source': 'local',
                    'snippet': result['evidence_snippet'],
                    'confidence': result['confidence'],
                    'method': result.get('method', 'unknown')
                }
                product_enrichment['field_status'][field] = 'enriched'

                stats['fields_by_method'][result.get('method', 'regex')] = \
                    stats['fields_by_method'].get(result.get('method', 'regex'), 0) + 1

                enriched_count += 1
                print(f"  âœ“ [{product.get('product_name', 'Unknown')[:25]}] {field}: {result['value']}")
            else:
                # [FIX C.2] è§„åˆ™æœªå‘½ä¸­ï¼Œå°è¯• LLM æå–
                llm_result = _extract_with_llm(content_text, field, item['category'])

                if llm_result['value']:
                    product['specs'][field] = llm_result['value']
                    product_enrichment['evidence'][field] = {
                        'source': 'local',
                        'snippet': llm_result['evidence_snippet'],
                        'confidence': llm_result['confidence'],
                        'method': 'llm'
                    }
                    product_enrichment['field_status'][field] = 'inferred'

                    stats['fields_by_method']['llm'] = stats['fields_by_method'].get('llm', 0) + 1

                    enriched_count += 1
                    print(f"  ~ [{product.get('product_name', 'Unknown')[:25]}] {field}: {llm_result['value']} (LLMæ¨æ–­)")

        if enriched_count > 0:
            product['enrichment'] = product_enrichment
            stats['products_enriched'] += 1
            stats['total_enriched'] += enriched_count

    print(f"[äºŒæ¬¡è¡¥å…¨-åŒæº] å®Œæˆ: {stats['products_enriched']} ä¸ªäº§å“è¡¥å…¨äº† {stats['total_enriched']} ä¸ªå­—æ®µ")
    print(f"  - æ­£åˆ™æå–: {stats['fields_by_method'].get('regex', 0)} ä¸ª")
    print(f"  - LLMæ¨æ–­: {stats['fields_by_method'].get('llm', 0)} ä¸ª")

    return enriched_products, stats


def enrich_missing_fields(products: List[Dict]) -> List[Dict]:
    """
    [FIX E] äºŒæ¬¡è¡¥å…¨ä¸»å…¥å£ - å¿…ç»æµç¨‹ï¼ˆä¸å†æ”¯æŒå¼€å…³å…³é—­ï¼‰

    äºŒæ¬¡è¡¥å…¨å§‹ç»ˆæ‰§è¡Œï¼Œlocal æ¨¡å¼ä¸ºé»˜è®¤å¿…è·‘æ¨¡å¼ã€‚
    search/both ä½œä¸ºå¢å¼ºæ¨¡å¼å åŠ ã€‚

    Args:
        products: äº§å“åˆ—è¡¨

    Returns:
        List[Dict]: è¡¥å…¨åçš„äº§å“åˆ—è¡¨
    """
    # [FIX E] å…¼å®¹æ€§æ£€æŸ¥ï¼šæ£€æµ‹ç”¨æˆ·æ˜¯å¦è®¾ç½®äº†å·²åºŸå¼ƒçš„å…³é—­å¼€å…³
    if _HAS_LEGACY_DISABLE_FLAG:
        print(f"\n[WARNING] æ£€æµ‹åˆ°å·²åºŸå¼ƒçš„é…ç½®é¡¹ï¼šSECOND_ROUND_ENABLED=false")
        print(f"[WARNING] äºŒæ¬¡è¡¥å…¨ç°ä¸ºå¿…ç»æµç¨‹ï¼Œè¯¥é…ç½®ä¸å†ç”Ÿæ•ˆ")
        print(f"[WARNING] å»ºè®®ä» .env ä¸­åˆ é™¤ SECOND_ROUND_ENABLED é…ç½®é¡¹")
        print(f"{'-'*60}")

    print(f"\n{'='*60}")
    print(f"äºŒæ¬¡è¡¥å…¨ï¼ˆå¿…ç»æµç¨‹ï¼‰- æ¨¡å¼: {SECOND_ROUND_MODE}")
    print(f"{'='*60}")

    # [FIX B] æ£€æµ‹ç¼ºå¤±å­—æ®µ
    missing_plan = detect_missing_fields(products)

    if not missing_plan:
        print("[äºŒæ¬¡è¡¥å…¨] æœªå‘ç°éœ€è¦è¡¥å…¨çš„ç¼ºå¤±å­—æ®µï¼ˆ0 items enrichedï¼‰")
        print("[äºŒæ¬¡è¡¥å…¨] æ‰€æœ‰å…³é”®å­—æ®µå·²å®Œæ•´")
        return products

    print(f"[äºŒæ¬¡è¡¥å…¨] å‘ç° {len(missing_plan)} ä¸ªäº§å“å­˜åœ¨å…³é”®å­—æ®µç¼ºå¤±")

    # [FIX C] P0 åŒæºè¡¥å…¨ï¼ˆå¿…è·‘æ¨¡å¼ï¼‰
    if SECOND_ROUND_MODE in ['local', 'both']:
        products, local_stats = enrich_missing_fields_local(products, missing_plan)

    # [FIX D] P1 è·¨æºè¡¥å…¨ï¼ˆé¢„ç•™æ¥å£ï¼Œéœ€è¦ MCP/æœç´¢æœåŠ¡ï¼‰
    if SECOND_ROUND_MODE in ['search', 'both']:
        print(f"\n[äºŒæ¬¡è¡¥å…¨-è·¨æº] åŠŸèƒ½é¢„ç•™ï¼ˆéœ€è¦ MCP/æœç´¢æœåŠ¡æ”¯æŒï¼‰")
        # TODO: å®ç° enrich_missing_fields_search()
        pass

    return products


def print_enrichment_summary(products: List[Dict], products_before: List[Dict] = None) -> Dict:
    """
    [FIX E] æ‰“å°äºŒæ¬¡è¡¥å…¨ç»Ÿè®¡æ‘˜è¦

    Args:
        products: è¡¥å…¨åçš„äº§å“åˆ—è¡¨
        products_before: è¡¥å…¨å‰çš„äº§å“åˆ—è¡¨ï¼ˆç”¨äºè®¡ç®—è¦†ç›–ç‡å˜åŒ–ï¼‰

    Returns:
        Dict: ç»Ÿè®¡ä¿¡æ¯å­—å…¸
    """
    total_products = len(products)

    # ç»Ÿè®¡è¡¥å…¨å­—æ®µçŠ¶æ€
    stats = {
        'explicit': 0,      # åŸå§‹æ˜ç¡®å€¼
        'enriched': 0,      # è§„åˆ™è¡¥å…¨
        'inferred': 0,      # LLM æ¨æ–­
        'still_missing': 0, # ä»ç„¶ç¼ºå¤±
        'total_fields': 0,
    }

    # è§¦å‘è¡¥å…¨çš„äº§å“æ•°
    triggered_products = 0

    # å…³é”®å­—æ®µåˆ—è¡¨ï¼ˆç”¨äºè¦†ç›–ç‡è®¡ç®—ï¼‰
    key_fields = {
        'mouse': MOUSE_KEY_FIELDS_PRIORITY + MOUSE_CRITICAL_FIELDS,
        'keyboard': KEYBOARD_KEY_FIELDS_PRIORITY + KEYBOARD_CRITICAL_FIELDS,
    }
    # å»é‡
    for cat in key_fields:
        key_fields[cat] = list(set(key_fields[cat]))

    # æŒ‰å“ç±»ç»Ÿè®¡
    category_stats = {
        'é¼ æ ‡': {'explicit': 0, 'enriched': 0, 'inferred': 0, 'still_missing': 0, 'total_fields': 0},
        'é”®ç›˜': {'explicit': 0, 'enriched': 0, 'inferred': 0, 'still_missing': 0, 'total_fields': 0},
    }

    for product in products:
        category = product.get('category', '')
        if category not in ['é¼ æ ‡', 'é”®ç›˜']:
            continue

        specs = product.get('specs', {})
        enrichment = product.get('enrichment', {})
        field_status = enrichment.get('field_status', {})

        has_enrichment = bool(field_status)
        if has_enrichment:
            triggered_products += 1

        # ç»Ÿè®¡å…³é”®å­—æ®µçŠ¶æ€
        cat_key_fields = key_fields.get('mouse' if category == 'é¼ æ ‡' else 'keyboard', [])

        for field in cat_key_fields:
            value = specs.get(field, '')
            value_str = str(value).lower().strip() if value else ''

            # åˆ¤å®šå­—æ®µçŠ¶æ€
            status = field_status.get(field, '')

            if status == 'enriched':
                stats['enriched'] += 1
                if category in category_stats:
                    category_stats[category]['enriched'] += 1
            elif status == 'inferred':
                stats['inferred'] += 1
                if category in category_stats:
                    category_stats[category]['inferred'] += 1
            elif value_str and not any(marker in value_str for marker in [
                'æœªæåŠ', 'åŸæ–‡æœªæåŠ', 'æœªæä¾›', 'æœªå…¬å¼€', 'tbd', 'å¾…å®æµ‹', 'é¢„ä¼°', 'æ¨æ–­',
                'æå–å¤±è´¥', 'æ— æ³•åˆ¤æ–­', 'unknown', 'none', 'null'
            ]):
                stats['explicit'] += 1
                if category in category_stats:
                    category_stats[category]['explicit'] += 1
            else:
                stats['still_missing'] += 1
                if category in category_stats:
                    category_stats[category]['still_missing'] += 1

            stats['total_fields'] += 1
            if category in category_stats:
                category_stats[category]['total_fields'] += 1

    # è®¡ç®—è¦†ç›–ç‡ï¼ˆè¡¥å…¨å‰åï¼‰
    coverage_stats = {}

    def calc_coverage(products_list):
        """è®¡ç®—å…³é”®å­—æ®µè¦†ç›–ç‡"""
        if not products_list:
            return {}

        coverage = {}
        for category, fields_key in [('é¼ æ ‡', 'mouse'), ('é”®ç›˜', 'keyboard')]:
            cat_products = [p for p in products_list if p.get('category') == category]
            if not cat_products:
                coverage[category] = {'coverage': 0, 'total': 0, 'known': 0}
                continue

            # ä½¿ç”¨è¯¥å“ç±»çš„å…³é”®å­—æ®µ
            critical_fields = MOUSE_CRITICAL_FIELDS if category == 'é¼ æ ‡' else KEYBOARD_CRITICAL_FIELDS
            total = len(cat_products) * len(critical_fields)
            known = 0

            for product in cat_products:
                specs = product.get('specs', {})
                enrichment = product.get('enrichment', {})
                field_status = enrichment.get('field_status', {})

                for field in critical_fields:
                    value = specs.get(field, '')
                    value_str = str(value).lower().strip() if value else ''

                    # ç»Ÿè®¡æœ‰æ•ˆï¼šæ˜ç¡®å€¼ + è¡¥å…¨å€¼ï¼ˆå¯é€‰ inferredï¼‰
                    is_valid = False

                    if value_str and not any(marker in value_str for marker in [
                        'æœªæåŠ', 'åŸæ–‡æœªæåŠ', 'æœªæä¾›', 'æœªå…¬å¼€', 'tbd', 'å¾…å®æµ‹', 'é¢„ä¼°', 'æ¨æ–­',
                        'æå–å¤±è´¥', 'æ— æ³•åˆ¤æ–­'
                    ]):
                        is_valid = True

                    # è¡¥å…¨çš„å€¼
                    if field in field_status:
                        if field_status[field] == 'enriched':
                            is_valid = True
                        elif field_status[field] == 'inferred' and COUNT_INFERRED_IN_COVERAGE:
                            is_valid = True

                    if is_valid:
                        known += 1

            coverage[category] = {
                'coverage': round(known / total * 100, 1) if total > 0 else 0,
                'total': total,
                'known': known
            }

        return coverage

    # è¡¥å…¨åè¦†ç›–ç‡
    coverage_after = calc_coverage(products)

    # è¡¥å…¨å‰è¦†ç›–ç‡ï¼ˆå¦‚æœæä¾›äº†åŸå§‹æ•°æ®ï¼‰
    coverage_before = {}
    if products_before:
        coverage_before = calc_coverage(products_before)

    # æ‰“å°ç»Ÿè®¡æ‘˜è¦
    print(f"\n{'='*60}")
    print("äºŒæ¬¡è¡¥å…¨ç»Ÿè®¡æ‘˜è¦")
    print(f"{'='*60}")

    print(f"\n[äº§å“ç»Ÿè®¡]")
    print(f"  æ€»äº§å“æ•°: {total_products}")
    print(f"  è§¦å‘è¡¥å…¨çš„äº§å“æ•°: {triggered_products}")
    print(f"  è¡¥å…¨ç‡: {triggered_products / total_products * 100:.1f}%")

    print(f"\n[å­—æ®µçŠ¶æ€ç»Ÿè®¡]")
    print(f"  explicit (åŸå§‹æ˜ç¡®å€¼):  {stats['explicit']}")
    print(f"  enriched (è§„åˆ™è¡¥å…¨):     {stats['enriched']}")
    print(f"  inferred (LLMæ¨æ–­):     {stats['inferred']}")
    print(f"  still_missing (ä»ç¼ºå¤±):  {stats['still_missing']}")
    print(f"  æ€»å­—æ®µæ•°: {stats['total_fields']}")

    # æŒ‰å“ç±»ç»Ÿè®¡
    for category, cat_stat in category_stats.items():
        if cat_stat['total_fields'] > 0:
            print(f"\n[{category}]")
            print(f"  explicit:  {cat_stat['explicit']}")
            print(f"  enriched:  {cat_stat['enriched']}")
            print(f"  inferred:  {cat_stat['inferred']}")
            print(f"  missing:   {cat_stat['still_missing']}")
            print(f"  æ€»å­—æ®µ:    {cat_stat['total_fields']}")

    # è¦†ç›–ç‡å¯¹æ¯”
    print(f"\n[å…³é”®å­—æ®µè¦†ç›–ç‡]")
    print(f"  (inferred {'è®¡å…¥' if COUNT_INFERRED_IN_COVERAGE else 'ä¸è®¡å…¥'} coverage)")

    for category in ['é¼ æ ‡', 'é”®ç›˜']:
        if category in coverage_after:
            after = coverage_after[category]
            if category in coverage_before:
                before = coverage_before[category]
                delta = after['coverage'] - before['coverage']
                delta_str = f"+{delta:.1f}%" if delta >= 0 else f"{delta:.1f}%"
                print(f"  {category}: {before['coverage']:.1f}% â†’ {after['coverage']:.1f}% ({delta_str})")
                print(f"    (known: {before['known']}/{before['total']} â†’ {after['known']}/{after['total']})")
            else:
                print(f"  {category}: {after['coverage']:.1f}% ({after['known']}/{after['total']})")

    print(f"{'='*60}\n")

    return {
        'products': {
            'total': total_products,
            'triggered': triggered_products,
        },
        'fields': stats,
        'category_fields': category_stats,
        'coverage': {
            'before': coverage_before,
            'after': coverage_after,
        },
        'config': {
            'count_inferred': COUNT_INFERRED_IN_COVERAGE,
        }
    }


def validate_enrichment_summary(json_path: str = None) -> Dict:
    """
    [FIX E] ä» processed_products.json è¯»å–å¹¶æ‰“å° enrichment summary

    ç”¨äº validate-only æ¨¡å¼ä¸‹éªŒæ”¶äºŒæ¬¡è¡¥å…¨ç»“æœ

    Args:
        json_path: processed_products.json è·¯å¾„ï¼ˆé»˜è®¤ä½¿ç”¨ PROCESSED_JSONï¼‰

    Returns:
        Dict: ç»Ÿè®¡ä¿¡æ¯å­—å…¸
    """
    import json

    if json_path is None:
        json_path = PROCESSED_JSON

    json_path = Path(json_path)

    if not json_path.exists():
        print(f"\n[ERROR] æ–‡ä»¶ä¸å­˜åœ¨: {json_path}")
        print("è¯·å…ˆç”ŸæˆæŠ¥å‘Šï¼Œæˆ–æŒ‡å®šæ­£ç¡®çš„ JSON è·¯å¾„")
        return {}

    print(f"\n[æ ¡éªŒ] è¯»å– enrichment æ•°æ®: {json_path}")

    with open(json_path, 'r', encoding='utf-8') as f:
        products = json.load(f)

    return print_enrichment_summary(products)


# é»˜è®¤ç§‘æŠ€æ„Ÿå ä½å›¾ï¼ˆåœ¨çº¿ URLï¼‰
DEFAULT_IMAGE_URL = "https://images.unsplash.com/photo-1550009158-9ebf69173e03?w=800&h=600&fit=crop"

# è¾“å‡ºæ–‡ä»¶é…ç½®
OUTPUT_DIR = Path("output")
PROCESSED_JSON = OUTPUT_DIR / "processed_products.json"
HTML_REPORT = OUTPUT_DIR / "monthly_report_2026_01.html"

# ==================== æ¨¡æ¿é…ç½® ====================
TEMPLATE_MODE = "pm_deep"  # é»˜è®¤æ¨¡æ¿: pm_deep (PMæ·±åº¦åˆ†æç‰ˆ)
AVAILABLE_TEMPLATES = {
    "pm_deep": "PMæ·±åº¦åˆ†æç‰ˆï¼ˆå®Œæ•´ä¸‰æ å¸ƒå±€ + nav-bar + æœç´¢ï¼‰",
    "simple": "ç®€åŒ–ç‰ˆï¼ˆä»…åŸºæœ¬ä¿¡æ¯ï¼‰"
}

# ==================== çˆ¬è™«æ•°æ®è·å–å‡½æ•° ====================

def fetch_data(year: int, month: int, output_dir: Path = OUTPUT_DIR) -> str:
    """
    è¿è¡Œçˆ¬è™«é‡‡é›†æ•°æ®

    Args:
        year: ç›®æ ‡å¹´ä»½
        month: ç›®æ ‡æœˆä»½
        output_dir: è¾“å‡ºç›®å½•

    Returns:
        str: è¾“å‡ºçš„ JSON æ–‡ä»¶è·¯å¾„

    Raises:
        SystemExit: å¦‚æœçˆ¬å–å¤±è´¥æˆ–æ²¡æœ‰æ•°æ®
    """
    import json

    target_json = output_dir / f'report_data_{year}_{month:02d}.json'

    # å¤‡ä»½æ—§æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if target_json.exists():
        backup_path = output_dir / f'report_data_{year}_{month:02d}.json.bak'
        shutil.copy2(target_json, backup_path)
        print(f"[BACKUP] å·²å¤‡ä»½æ—§æ–‡ä»¶: {backup_path}")

    print(f"\n{'='*60}")
    print(f"å¼€å§‹çˆ¬å–æ•°æ®: {year}-{month:02d}")
    print(f"{'='*60}\n")

    # æ–¹å¼1ï¼šå°è¯•ä½œä¸ºæ¨¡å—å¯¼å…¥ spiderï¼ˆæ›´ä¼˜é›…ï¼‰
    try:
        import spider

        # ä¸´æ—¶ä¿®æ”¹ config çš„å¹´æœˆ
        import config
        original_year = config.TARGET_YEAR
        original_month = config.TARGET_MONTH

        # è¿è¡Œçˆ¬è™«
        all_articles = spider.run_spider_all(target_year=year, target_month=month, max_pages=20)

        # æ¢å¤åŸå§‹é…ç½®
        config.TARGET_YEAR = original_year
        config.TARGET_MONTH = original_month

        # éªŒè¯æ•°æ®
        if not all_articles:
            print(f"\n{'='*60}")
            print(f"[ERROR] çˆ¬è™«æœªé‡‡é›†åˆ°ä»»ä½•æ•°æ®ï¼")
            print(f"[ERROR] è¯·æ£€æŸ¥ï¼š")
            print(f"  1. ç›®æ ‡æœˆä»½ {year}-{month:02d} æ˜¯å¦æœ‰æ–°å“å‘å¸ƒ")
            print(f"  2. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
            print(f"  3. ç›®æ ‡ç½‘ç«™æ˜¯å¦å¯è®¿é—®")
            print(f"{'='*60}\n")
            raise SystemExit(1)

        # å¯¼å‡ºæ•°æ®
        exporter = spider.DataExporter()
        exporter.export_to_json(all_articles, filename=f'report_data_{year}_{month:02d}.json')
        exporter.export_to_excel(all_articles, filename=f'report_data_{year}_{month:02d}.xlsx')

        print(f"\n{'='*60}")
        print(f"âœ“ çˆ¬å–å®Œæˆï¼å…±é‡‡é›† {len(all_articles)} æ¡æ•°æ®")
        print(f"âœ“ æ•°æ®å·²ä¿å­˜: {target_json}")
        print(f"{'='*60}\n")

        return str(target_json)

    except ImportError as e:
        # æ–¹å¼2ï¼šä½œä¸ºå­è¿›ç¨‹è°ƒç”¨ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
        print(f"[WARN] æ— æ³•å¯¼å…¥ spider æ¨¡å—ï¼Œä½¿ç”¨å­è¿›ç¨‹è°ƒç”¨: {e}")

        # è®¾ç½®ç¯å¢ƒå˜é‡ä¼ é€’å¹´æœˆ
        env = os.environ.copy()
        env['TARGET_YEAR'] = str(year)
        env['TARGET_MONTH'] = str(month)

        # è¿è¡Œ spider.py
        result = subprocess.run(
            [sys.executable, 'spider.py'],
            env=env,
            capture_output=True,
            text=True
        )

        # è¾“å‡ºçˆ¬è™«æ—¥å¿—
        if result.stdout:
            print(result.stdout)
        if result.stderr:
            print(result.stderr, file=sys.stderr)

        # æ£€æŸ¥æ˜¯å¦ç”Ÿæˆæ–‡ä»¶
        if not target_json.exists():
            print(f"\n{'='*60}")
            print(f"[ERROR] çˆ¬è™«æ‰§è¡Œå¤±è´¥ï¼Œæœªç”Ÿæˆæ•°æ®æ–‡ä»¶ï¼")
            print(f"{'='*60}\n")
            raise SystemExit(1)

        # éªŒè¯æ•°æ®
        with open(target_json, 'r', encoding='utf-8') as f:
            data = json.load(f)

        if not data or len(data) == 0:
            print(f"\n{'='*60}")
            print(f"[ERROR] çˆ¬è™«é‡‡é›†åˆ° 0 æ¡æ•°æ®ï¼")
            print(f"[ERROR] è¯·æ£€æŸ¥ç›®æ ‡æœˆä»½ {year}-{month:02d} æ˜¯å¦æœ‰æ–°å“å‘å¸ƒ")
            print(f"{'='*60}\n")
            raise SystemExit(1)

        print(f"\n{'='*60}")
        print(f"âœ“ çˆ¬å–å®Œæˆï¼å…±é‡‡é›† {len(data)} æ¡æ•°æ®")
        print(f"{'='*60}\n")

        return str(target_json)


# ==================== ä»»åŠ¡ä¸€ï¼šæ•°æ®é¢„å¤„ç†ä¸æ¸…æ´— ====================

class DataCleaner:
    """æ•°æ®æ¸…æ´—å™¨ - Phase 4 å¢å¼ºç‰ˆ"""

    def __init__(self, file_path: str):
        # è‡ªåŠ¨æ£€æµ‹æ–‡ä»¶æ ¼å¼å¹¶è¯»å–
        if file_path.endswith('.json'):
            self.df = pd.read_json(file_path)
        elif file_path.endswith(('.xlsx', '.xls')):
            self.df = pd.read_excel(file_path, engine='openpyxl' if file_path.endswith('.xlsx') else 'xlrd')
        else:
            # é»˜è®¤å°è¯• Excel
            self.df = pd.read_excel(file_path, engine='openpyxl')
        print(f"[OK] åŠ è½½åŸå§‹æ•°æ®: {len(self.df)} æ¡è®°å½•")

    def filter_by_keywords(self) -> pd.DataFrame:
        """å…³é”®è¯ç­›é€‰ï¼ˆç™½åå•ï¼‰"""
        def contains_keyword(text: str) -> bool:
            if pd.isna(text):
                return False
            text = str(text).lower()
            return any(kw in text for kw in KEYWORDS)

        # ç­›é€‰æ ‡é¢˜æˆ–æ­£æ–‡åŒ…å«å…³é”®è¯çš„è®°å½•
        mask = self.df['title'].apply(contains_keyword) | \
               self.df['content_text'].apply(contains_keyword)

        filtered_df = self.df[mask].copy()
        print(f"[OK] å…³é”®è¯ç­›é€‰å: {len(filtered_df)} æ¡è®°å½•")

        return filtered_df

    def filter_by_blacklist(self, df: pd.DataFrame) -> pd.DataFrame:
        """é»‘åå•è¿‡æ»¤ - è¿‡æ»¤æ‰é¼ æ ‡å«ã€çº¿æç­‰é…ä»¶"""
        def contains_blacklist(text: str) -> bool:
            if pd.isna(text):
                return False
            text = str(text).lower()
            return any(kw in text for kw in BLACKLIST)

        # è¿‡æ»¤æ ‡é¢˜åŒ…å«é»‘åå•å…³é”®è¯çš„è®°å½•
        mask = ~df['title'].apply(contains_blacklist)

        filtered_df = df[mask].copy()
        dropped_count = len(df) - len(filtered_df)

        if dropped_count > 0:
            print(f"[OK] é»‘åå•è¿‡æ»¤: å‰”é™¤ {dropped_count} æ¡é…ä»¶è®°å½•")

        return filtered_df

    def smart_deduplicate(self, df: pd.DataFrame) -> List[Dict]:
        """æ™ºèƒ½å»é‡å¹¶åˆå¹¶"""
        products = []

        # æŒ‰å‘å¸ƒæ—¶é—´æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
        df = df.sort_values('publish_date', ascending=False)

        used_indices = set()

        for i, row in df.iterrows():
            if i in used_indices:
                continue

            # å½“å‰äº§å“
            current_title = row['title']
            sources = [row['source']]
            records = [row.to_dict()]

            current_product = {
                'product_name': current_title,
                'records': records,
                'images': self._parse_images(row['images']),
                'sources': sources
            }

            # æŸ¥æ‰¾ç›¸ä¼¼äº§å“
            for j, compare_row in df.iterrows():
                if j <= i or j in used_indices:
                    continue

                similarity = SequenceMatcher(
                    None,
                    current_title,
                    compare_row['title']
                ).ratio()

                # ç›¸ä¼¼åº¦é˜ˆå€¼ 0.6
                if similarity > 0.6:
                    # åˆå¹¶è®°å½•
                    current_product['records'].append(compare_row.to_dict())
                    current_product['images'].extend(
                        self._parse_images(compare_row['images'])
                    )
                    if compare_row['source'] not in current_product['sources']:
                        current_product['sources'].append(compare_row['source'])

                    used_indices.add(j)

            # æå–ç¬¬ä¸€å¼ å›¾ç‰‡ï¼ˆæ™ºèƒ½é€‰æ‹©æœ€ä½³å›¾ç‰‡ï¼‰
            first_image = self._select_best_image(current_product, row)

            # åªä¿å­˜ç¬¬ä¸€å¼ å›¾ç‰‡
            current_product['images'] = [first_image] if first_image else []

            # åˆå¹¶æ‰€æœ‰æ­£æ–‡å†…å®¹
            combined_content = '\n\n---\n\n'.join([
                f"æ¥æº: {r['source']}\næ ‡é¢˜: {r['title']}\n{r['content_text']}"
                for r in current_product['records']
            ])
            current_product['combined_content'] = combined_content

            products.append(current_product)
            used_indices.add(i)

        print(f"[OK] æ™ºèƒ½å»é‡å: {len(products)} æ¬¾äº§å“")

        return products

    @staticmethod
    def _parse_images(images_str: str) -> List[str]:
        """è§£æå›¾ç‰‡å­—ç¬¦ä¸²"""
        if pd.isna(images_str):
            return []

        # å¤„ç†åˆ—è¡¨æ ¼å¼çš„å­—ç¬¦ä¸²
        images_str = str(images_str).strip()
        if not images_str or images_str == '[]':
            return []

        try:
            # å°è¯•è§£æä¸º Python åˆ—è¡¨
            images = eval(images_str)
            if isinstance(images, list):
                return images
        except:
            pass

        return []

    @staticmethod
    def _clean_image_paths(images: List[str], sources: List[str]) -> List[str]:
        """æ¸…æ´—å›¾ç‰‡è·¯å¾„ï¼Œæ ¹æ®æ¥æºè¡¥å…¨åŸŸå"""
        cleaned = []

        # åˆ¤æ–­æ¥æº
        has_inwaishe = 'inå¤–è®¾' in sources
        has_wstx = 'å¤–è®¾å¤©ä¸‹' in sources

        for img in images:
            if not img or not isinstance(img, str):
                continue

            img = img.strip()

            # è·³è¿‡ data URL
            if img.startswith('data:'):
                continue

            # å·²ç»æ˜¯å®Œæ•´ URL
            if img.startswith('http://') or img.startswith('https://'):
                cleaned.append(img)
                continue

            # inå¤–è®¾ï¼šdata/attachment å¼€å¤´
            if img.startswith('data/attachment'):
                img = f'http://www.inwaishe.com/{img}'
                cleaned.append(img)
                continue

            # å¤–è®¾å¤©ä¸‹ï¼šç›¸å¯¹è·¯å¾„
            if img.startswith('/'):
                # å¦‚æœæœ‰å¤–è®¾å¤©ä¸‹çš„æ¥æºï¼Œä¼˜å…ˆä½¿ç”¨ wstx.com
                if has_wstx:
                    img = f'https://www.wstx.com{img}'
                else:
                    img = f'http://www.inwaishe.com{img}'
                cleaned.append(img)
                continue

            # å…¶ä»–æƒ…å†µå°è¯•ä½œä¸ºç›¸å¯¹è·¯å¾„å¤„ç†
            if has_wstx:
                cleaned.append(f'https://www.wstx.com/{img}')
            elif has_inwaishe:
                cleaned.append(f'http://www.inwaishe.com/{img}')

        return cleaned

    @staticmethod
    def _select_best_image(product: Dict, current_row: pd.Series) -> Optional[str]:
        """
        æ™ºèƒ½é€‰æ‹©æœ€ä½³äº§å“å›¾ç‰‡

        ä¼˜å…ˆçº§ï¼š
        1. ä¼˜å…ˆé€‰æ‹©åŒ…å«"äº§å“å®æ‹"ã€"æ¸²æŸ“å›¾"ç­‰å…³é”®è¯çš„å›¾ç‰‡ï¼ˆä»content_textåˆ¤æ–­ï¼‰
        2. é¿å…é€‰æ‹©logoã€bannerç­‰éäº§å“å›¾
        3. ä¼˜å…ˆé€‰æ‹©å½“å‰è®°å½•çš„å›¾ç‰‡ï¼Œå…¶æ¬¡æ˜¯ç›¸ä¼¼è®°å½•çš„å›¾ç‰‡
        """
        all_images = []

        # æ”¶é›†å½“å‰è®°å½•çš„å›¾ç‰‡
        current_imgs = DataCleaner._parse_images(current_row['images'])
        for idx, img in enumerate(current_imgs):
            all_images.append({
                'url': img,
                'is_current': True,
                'index': idx
            })

        # æ”¶é›†å…¶ä»–ç›¸ä¼¼è®°å½•çš„å›¾ç‰‡
        for record in product.get('records', []):
            if isinstance(record, dict):
                record_imgs = DataCleaner._parse_images(record.get('images', []))
                for idx, img in enumerate(record_imgs):
                    all_images.append({
                        'url': img,
                        'is_current': False,
                        'index': idx
                    })

        # æ¸…æ´—å›¾ç‰‡è·¯å¾„
        sources = product.get('sources', [])
        for img_dict in all_images:
            cleaned = DataCleaner._clean_image_paths([img_dict['url']], sources)
            if cleaned:
                img_dict['cleaned_url'] = cleaned[0]
            else:
                img_dict['cleaned_url'] = None

        # è¿‡æ»¤æ‰æ— æ•ˆå›¾ç‰‡
        valid_images = [img for img in all_images if img.get('cleaned_url')]

        if not valid_images:
            return None

        # ä¼˜å…ˆçº§1: ä¼˜å…ˆé€‰æ‹©å½“å‰è®°å½•çš„å›¾ç‰‡
        current_images = [img for img in valid_images if img['is_current']]
        if current_images:
            return current_images[0]['cleaned_url']

        # ä¼˜å…ˆçº§2: è¿”å›ç¬¬ä¸€ä¸ªæœ‰æ•ˆå›¾ç‰‡
        return valid_images[0]['cleaned_url']


# ==================== ä»»åŠ¡äºŒï¼šLLM PMè§†è§’æ·±åº¦åˆ†æ ====================

# å†…ç½‘æœç´¢APIé…ç½®
SEARCH_API_CONFIG = {
    "base_url": "http://192.168.0.250:7891",
    "api_key": "cr_efee6bd8725c8ab63fe98cb355d0c8569ef10fb89f7a386a84954a2feeeeee42",  # å†…ç½‘APIè®¤è¯token
    "timeout": 10
}


class ParameterCompleter:
    """å‚æ•°è‡ªåŠ¨è¡¥å…¨å™¨ - é€šè¿‡æœç´¢è¡¥å…¨ç¼ºå¤±çš„äº§å“å‚æ•°"""

    def __init__(self, search_config: Dict = None, search_func=None, llm_config: Dict = None):
        """
        åˆå§‹åŒ–å‚æ•°è¡¥å…¨å™¨

        Args:
            search_config: æœç´¢APIé…ç½®ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰
            search_func: è‡ªå®šä¹‰æœç´¢å‡½æ•°ï¼Œç­¾åä¸º (query: str) -> Optional[str]
                        å¦‚æœä¸º Noneï¼Œåˆ™ä½¿ç”¨å†…éƒ¨çš„ MCP æœç´¢æ–¹å¼
            llm_config: LLMé…ç½®ï¼Œç”¨äºä»æœç´¢ç»“æœä¸­æå–å‚æ•°
        """
        self.search_config = search_config or SEARCH_API_CONFIG
        self.search_enabled = True  # å¯ä»¥é€šè¿‡é…ç½®å¼€å…³æœç´¢åŠŸèƒ½
        self.custom_search_func = search_func  # å¤–éƒ¨ä¼ å…¥çš„æœç´¢å‡½æ•°
        self.llm_config = llm_config or LLM_CONFIG  # ä½¿ç”¨å…¨å±€ LLM é…ç½®

        # å®šä¹‰éœ€è¦æ£€æŸ¥çš„å…³é”®å­—æ®µ
        self.mice_critical_fields = ['weight', 'sensor', 'polling_rate']
        self.keyboard_critical_fields = ['structure', 'connection', 'switch']

        # å­—æ®µä¸­æ–‡åæ˜ å°„ï¼ˆç”¨äº LLM æç¤ºï¼‰
        self.field_names_cn = {
            # é¼ æ ‡å­—æ®µ
            'weight': 'é‡é‡',
            'sensor': 'ä¼ æ„Ÿå™¨å‹å·',
            'polling_rate': 'å›æŠ¥ç‡',
            'dimensions': 'å°ºå¯¸',
            'dpi': 'æœ€é«˜DPI',
            'connection': 'è¿æ¥æ–¹å¼',
            'buttons': 'æŒ‰é”®æ•°é‡',
            'switch': 'å¾®åŠ¨å¼€å…³',
            'battery': 'ç”µæ± ç»­èˆª',
            # é”®ç›˜å­—æ®µ
            'layout': 'é…åˆ—',
            'structure': 'ç»“æ„',
            'keycap': 'é”®å¸½æè´¨',
            'hot_swappable': 'çƒ­æ’æ‹”',
            'switch': 'è½´ä½“ç±»å‹',
        }

    def check_completeness(self, product: Dict) -> Dict[str, list]:
        """
        æ£€æŸ¥äº§å“å‚æ•°å®Œæ•´æ€§

        Returns:
            Dict with 'missing' (ç¼ºå¤±å­—æ®µåˆ—è¡¨) and 'search_queries' (éœ€è¦æ‰§è¡Œçš„æœç´¢æŸ¥è¯¢)
        """
        category = product.get('category', '')
        specs = product.get('specs', {})

        missing_fields = []
        search_queries = []

        if category == 'é¼ æ ‡':
            critical_fields = self.mice_critical_fields
            field_names = {
                'weight': 'é‡é‡',
                'sensor': 'ä¼ æ„Ÿå™¨å‹å·',
                'polling_rate': 'å›æŠ¥ç‡'
            }
        elif category == 'é”®ç›˜':
            critical_fields = self.keyboard_critical_fields
            field_names = {
                'structure': 'ç»“æ„',
                'connection': 'è¿æ¥æ–¹å¼',
                'switch': 'è½´ä½“'
            }
        else:
            return {'missing': [], 'search_queries': []}

        # æ£€æŸ¥æ¯ä¸ªå…³é”®å­—æ®µ
        for field in critical_fields:
            value = specs.get(field, '')
            if not value or str(value).lower() in ['unknown', 'null', '', 'æœªæåŠ', 'æœªçŸ¥']:
                missing_fields.append(field)
                # æ„é€ æœç´¢æŸ¥è¯¢
                query = f"{product.get('product_name', '')} {field_names[field]} å‚æ•°"
                search_queries.append({
                    'field': field,
                    'field_name': field_names[field],
                    'query': query
                })

        return {
            'missing': missing_fields,
            'search_queries': search_queries
        }

    def search_and_complete(self, product: Dict) -> Dict:
        """
        æœç´¢å¹¶è¡¥å…¨ç¼ºå¤±çš„å‚æ•°

        Args:
            product: äº§å“æ•°æ®å­—å…¸

        Returns:
            æ›´æ–°åçš„äº§å“å­—å…¸ï¼ˆè¡¥å…¨äº†å‚æ•°ï¼‰
        """
        if not self.search_enabled:
            return product

        completeness = self.check_completeness(product)

        if not completeness['missing']:
            return product  # æ— éœ€è¡¥å…¨

        print(f"      [å‚æ•°è¡¥å…¨] æ£€æµ‹åˆ° {len(completeness['missing'])} ä¸ªç¼ºå¤±å­—æ®µï¼Œå¼€å§‹æœç´¢...")

        # è¡¥å…¨æ¯ä¸ªç¼ºå¤±çš„å­—æ®µ
        specs = product.get('specs', {}).copy()

        for search_item in completeness['search_queries']:
            field = search_item['field']
            query = search_item['query']

            try:
                # ä¼˜å…ˆä½¿ç”¨è‡ªå®šä¹‰æœç´¢å‡½æ•°ï¼ˆå¦‚ MCP å·¥å…·ï¼‰
                if self.custom_search_func:
                    search_result = self.custom_search_func(query)
                else:
                    # å›é€€åˆ°åŸæœ‰çš„ API è°ƒç”¨æ–¹å¼
                    search_result = self._call_search_api_fallback(query)

                if search_result:
                    # ä»æœç´¢ç»“æœä¸­æå–å‚æ•°å€¼
                    extracted_value = self._extract_param_from_search(
                        search_result,
                        field,
                        product.get('category', '')
                    )

                    if extracted_value:
                        old_value = specs.get(field, '')
                        specs[field] = extracted_value
                        print(f"      [å‚æ•°è¡¥å…¨] [OK] {search_item['field_name']}: {old_value} -> {extracted_value} (æœ)")
                    else:
                        print(f"      [å‚æ•°è¡¥å…¨] [X] {search_item['field_name']}: æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯")

            except Exception as e:
                print(f"      [å‚æ•°è¡¥å…¨] [X] æœç´¢å¤±è´¥ ({search_item['field_name']}): {str(e)[:50]}")

        # æ›´æ–°äº§å“æ•°æ®
        product['specs'] = specs
        return product

    def _call_search_api(self, query: str) -> Optional[str]:
        """
        ä½¿ç”¨ MCP web-search-prime å·¥å…·è¿›è¡Œæœç´¢

        Args:
            query: æœç´¢æŸ¥è¯¢

        Returns:
            æœç´¢ç»“æœæ‘˜è¦æ–‡æœ¬ï¼ˆåˆå¹¶å‰3ä¸ªç»“æœçš„contentå­—æ®µï¼‰
        """
        try:
            # ç›´æ¥ä½¿ç”¨ MCP å·¥å…·ï¼ˆé€šè¿‡ç¯å¢ƒå˜é‡æˆ–å…¨å±€è®¿é—®ï¼‰
            # æ³¨æ„ï¼šè¿™ä¸ªæ–¹æ³•ä¼šåœ¨å®é™…è¿è¡Œæ—¶è¢«è°ƒç”¨ï¼ŒMCPå·¥å…·å·²é¢„é…ç½®
            import subprocess
            import json

            # æ„é€  claude å‘½ä»¤è¡Œè°ƒç”¨
            # ç”±äºæˆ‘ä»¬åœ¨ claude code ç¯å¢ƒä¸­ï¼Œç›´æ¥é€šè¿‡è°ƒç”¨å‡½æ•°çš„æ–¹å¼
            # è¿™é‡Œä½¿ç”¨ä¸€ä¸ªç®€åŒ–çš„æ–¹æ³•ï¼šé€šè¿‡ subprocess è°ƒç”¨ claude mcp å‘½ä»¤
            # ä½†æ›´ç›´æ¥çš„æ–¹å¼æ˜¯ï¼šè®©è°ƒç”¨è€…ç›´æ¥ä½¿ç”¨ MCP å·¥å…·

            # å®é™…ä¸Šï¼Œæœ€å¥½çš„æ–¹å¼æ˜¯ç›´æ¥è¿”å›æŸ¥è¯¢å­—ç¬¦ä¸²ï¼Œ
            # è®©è°ƒç”¨è€…åœ¨å¤–éƒ¨ä½¿ç”¨ MCP å·¥å…·
            print(f"        [æœç´¢API] å‡†å¤‡æœç´¢: {query}")

            # ç”±äºæ— æ³•ç›´æ¥åœ¨ Python ä»£ç ä¸­è°ƒç”¨ MCP å·¥å…·ï¼Œ
            # æˆ‘ä»¬è¿”å›ä¸€ä¸ªç‰¹æ®Šæ ‡è®°ï¼Œè®©ä¸Šå±‚å‡½æ•°å¤„ç†
            return f"MCP_SEARCH_REQUIRED:{query}"

        except Exception as e:
            print(f"        [æœç´¢API] åˆå§‹åŒ–å¤±è´¥: {str(e)[:100]}")
            return None

    def _extract_param_from_search(self, search_text: str, field: str, category: str) -> Optional[str]:
        """
        ä»æœç´¢ç»“æœä¸­æå–å‚æ•°å€¼ï¼ˆä½¿ç”¨ LLMï¼‰

        Args:
            search_text: æœç´¢ç»“æœæ–‡æœ¬ï¼ˆJSONå­—ç¬¦ä¸²æˆ–çº¯æ–‡æœ¬ï¼‰
            field: å­—æ®µåï¼ˆå¦‚ 'weight', 'sensor'ï¼‰
            category: äº§å“ç±»åˆ«ï¼ˆå¦‚ 'é¼ æ ‡', 'é”®ç›˜'ï¼‰

        Returns:
            æå–çš„å‚æ•°å€¼
        """
        if not search_text:
            return None

        # è§£ææœç´¢ç»“æœï¼ˆå¦‚æœæ˜¯JSONæ ¼å¼ï¼‰
        extracted_content = self._parse_search_result(search_text)

        if not extracted_content:
            return None

        # ä½¿ç”¨ LLM æå–å‚æ•°
        field_name_cn = self.field_names_cn.get(field, field)
        extracted_value = self._extract_with_llm(extracted_content, field_name_cn, category)

        return extracted_value

    def _parse_search_result(self, search_text: str) -> str:
        """
        è§£ææœç´¢ç»“æœï¼Œæå–çº¯æ–‡æœ¬å†…å®¹

        Args:
            search_text: MCPè¿”å›çš„JSONå­—ç¬¦ä¸²

        Returns:
            åˆå¹¶åçš„çº¯æ–‡æœ¬å†…å®¹
        """
        import json

        # å°è¯•è§£æä¸ºJSON
        try:
            results = json.loads(search_text)
            if isinstance(results, list) and len(results) > 0:
                # æå–æ‰€æœ‰ç»“æœçš„ content å­—æ®µ
                content_texts = []
                for result in results[:3]:  # åªå–å‰3ä¸ªç»“æœ
                    content = result.get('content', '')
                    if content:
                        content_texts.append(content)

                if content_texts:
                    return '\n\n'.join(content_texts)
        except json.JSONDecodeError:
            # ä¸æ˜¯JSONæ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨åŸæ–‡æœ¬
            pass

        return search_text

    def _extract_with_llm(self, content: str, field_name_cn: str, category: str) -> Optional[str]:
        """
        ä½¿ç”¨ LLM ä»æ–‡æœ¬ä¸­æå–å‚æ•°å€¼

        Args:
            content: æœç´¢ç»“æœçš„çº¯æ–‡æœ¬å†…å®¹
            field_name_cn: å­—æ®µä¸­æ–‡åï¼ˆå¦‚ 'é‡é‡', 'ä¼ æ„Ÿå™¨å‹å·'ï¼‰
            category: äº§å“ç±»åˆ«

        Returns:
            æå–çš„å‚æ•°å€¼
        """
        import requests

        # æ„é€  LLM æç¤º
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¤–è®¾å‚æ•°æå–åŠ©æ‰‹ã€‚

è¯·ä»ä»¥ä¸‹äº§å“æœç´¢ç»“æœä¸­æå–ã€{field_name_cn}ã€‘çš„å€¼ã€‚

äº§å“ç±»åˆ«ï¼š{category}

æœç´¢ç»“æœï¼š
{content}

è¦æ±‚ï¼š
1. åªè¾“å‡ºå‚æ•°å€¼ï¼Œä¸è¦ä»»ä½•å…¶ä»–æ–‡å­—
2. å¦‚æœæœç´¢ç»“æœä¸­æ²¡æœ‰æåˆ°{field_name_cn}ï¼Œè¾“å‡º "NOT_FOUND"
3. æå–ç¤ºä¾‹ï¼š
   - é‡é‡ï¼š50gã€çº¦50å…‹ã€50å…‹å·¦å³ â†’ æå– "50g"
   - ä¼ æ„Ÿå™¨ï¼šPAW3395ä¼ æ„Ÿå™¨ã€æ­è½½PAW3395 â†’ æå– "PAW3395"
   - å›æŠ¥ç‡ï¼š8Kå›æŠ¥ç‡ã€æ”¯æŒ8000Hz â†’ æå– "8000Hz"
   - ç»“æ„ï¼šGasketç»“æ„ã€é‡‡ç”¨Gasketè®¾è®¡ â†’ æå– "Gasket"
   - è½´ä½“ï¼šTTCé‡‘èŒ¶è½´ã€æ­è½½ä½³è¾¾éš† â†’ æå– "TTCé‡‘èŒ¶è½´"

è¯·æå–{field_name_cn}çš„å€¼ï¼š"""

        try:
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {self.llm_config.get('api_key', '')}"
            }

            data = {
                "model": self.llm_config.get("model", ""),
                "messages": [
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¤–è®¾å‚æ•°æå–åŠ©æ‰‹ï¼Œæ“…é•¿ä»äº§å“æè¿°ä¸­æå–å‡†ç¡®çš„å‚æ•°å€¼ã€‚åªè¾“å‡ºå‚æ•°å€¼ï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"
                    },
                    {"role": "user", "content": prompt}
                ],
                "temperature": 0.1,  # é™ä½æ¸©åº¦ï¼Œæé«˜å‡†ç¡®æ€§
                "max_tokens": 100,
                "stream": False
            }

            base_url = self.llm_config.get("base_url", "").rstrip('/')
            url = f"{base_url}/v1/chat/completions"

            response = requests.post(url, headers=headers, json=data, timeout=30)
            response.raise_for_status()

            result = response.json()
            extracted_text = result["choices"][0]["message"]["content"].strip()

            # æ£€æŸ¥æ˜¯å¦æœªæ‰¾åˆ°
            if 'NOT_FOUND' in extracted_text or 'æœªæåŠ' in extracted_text or 'æœªæ‰¾åˆ°' in extracted_text:
                return None

            # æ¸…ç†æå–çš„å€¼ï¼ˆç§»é™¤å¤šä½™çš„å¼•å·ã€ç©ºæ ¼ç­‰ï¼‰
            extracted_text = extracted_text.strip('"\'').strip()

            # é™åˆ¶é•¿åº¦
            if len(extracted_text) > 100:
                extracted_text = extracted_text[:100]

            return extracted_text

        except Exception as e:
            print(f"        [LLMæå–] å¤±è´¥: {str(e)[:50]}")
            # LLM å¤±è´¥æ—¶ï¼Œå›é€€åˆ°æ­£åˆ™è¡¨è¾¾å¼
            return self._extract_with_regex(content, field_name_cn)

    def _extract_with_regex(self, content: str, field_name_cn: str) -> Optional[str]:
        """
        æ­£åˆ™è¡¨è¾¾å¼æå–ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰

        Args:
            content: æ–‡æœ¬å†…å®¹
            field_name_cn: å­—æ®µä¸­æ–‡å

        Returns:
            æå–çš„å‚æ•°å€¼
        """
        # ç®€åŒ–çš„æ­£åˆ™æ¨¡å¼ä½œä¸ºå¤‡ç”¨
        if 'é‡é‡' in field_name_cn or 'weight' in field_name_cn.lower():
            match = re.search(r'(\d+(?:\.\d+)?)\s*[gå…‹]', content, re.IGNORECASE)
            if match:
                return f"{match.group(1)}g"

        elif 'ä¼ æ„Ÿå™¨' in field_name_cn or 'sensor' in field_name_cn.lower():
            match = re.search(r'(PAW\d+[A-Z]*|Hero\s*\d*[A-Z]*|AIM\d+)', content, re.IGNORECASE)
            if match:
                return match.group(1)

        elif 'å›æŠ¥ç‡' in field_name_cn or 'polling' in field_name_cn.lower():
            match = re.search(r'(\d+)\s*[kK]?[hH][zZ]', content, re.IGNORECASE)
            if match:
                return f"{match.group(1)}Hz"

        return None

    def extract_from_article(self, product: Dict) -> Dict:
        """
        ä»åŸæ–‡ç« å†…å®¹ä¸­æå–å‚æ•°ï¼ˆç¬¬ä¸€æ­¥ï¼‰

        Args:
            product: äº§å“æ•°æ®å­—å…¸ï¼Œå¿…é¡»åŒ…å« 'content_text' å­—æ®µ

        Returns:
            æ›´æ–°åçš„äº§å“å­—å…¸ï¼ˆåŒ…å«ä»æ–‡ç« æå–çš„å‚æ•°ï¼‰
        """
        article_content = product.get('content_text', '')

        if not article_content:
            return product

        print(f"      [æ–‡ç« æå–] ä»åŸæ–‡ç« ä¸­æå–å‚æ•°...")

        # åˆå§‹åŒ– specsï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        if 'specs' not in product:
            product['specs'] = {}

        # ä½¿ç”¨ LLM ä»æ–‡ç« ä¸­æå–æ‰€æœ‰ç›¸å…³å‚æ•°
        extracted_params = self._extract_all_params_with_llm(article_content, product.get('category', ''))

        # å›å¡«å‚æ•°
        filled_count = 0
        for field, value in extracted_params.items():
            if value and value != 'æœªçŸ¥':
                old_value = product['specs'].get(field, '')
                if not old_value or old_value == 'æœªçŸ¥':
                    product['specs'][field] = value
                    filled_count += 1
                    field_name_cn = self.field_names_cn.get(field, field)
                    print(f"      [æ–‡ç« æå–] [OK] {field_name_cn}: {value}")

        if filled_count > 0:
            print(f"      [æ–‡ç« æå–] æˆåŠŸæå– {filled_count} ä¸ªå‚æ•°")
        else:
            print(f"      [æ–‡ç« æå–] æœªæ‰¾åˆ°å‚æ•°ä¿¡æ¯")

        return product

    def _extract_all_params_with_llm(self, content: str, category: str) -> Dict[str, str]:
        """
        ä½¿ç”¨ LLM ä»æ–‡æœ¬ä¸­æå–æ‰€æœ‰ç›¸å…³å‚æ•°

        Args:
            content: æ–‡æœ¬å†…å®¹
            category: äº§å“ç±»åˆ«

        Returns:
            å‚æ•°å­—å…¸ {field: value}
        """
        import requests

        # æ ¹æ®ç±»åˆ«å®šä¹‰è¦æå–çš„å­—æ®µ
        if category == 'é¼ æ ‡':
            fields_definition = """
            - weight (é‡é‡): å•ä½ç”¨gï¼Œå¦‚"50g"
            - sensor (ä¼ æ„Ÿå™¨å‹å·): å¦‚"PAW3395"ã€"Hero 25K"
            - polling_rate (å›æŠ¥ç‡): å•ä½ç”¨Hzï¼Œå¦‚"1000Hz"ã€"8000Hz"
            - dpi (æœ€é«˜DPI): å¦‚"26000"
            - connection (è¿æ¥æ–¹å¼): å¦‚"ä¸‰æ¨¡"ã€"2.4G+è“ç‰™+æœ‰çº¿"
            - buttons (æŒ‰é”®æ•°é‡): å¦‚"5é”®"ã€"6é”®"
            - battery (ç”µæ± ç»­èˆª): å¦‚"100å°æ—¶"
            """
        elif category == 'é”®ç›˜':
            fields_definition = """
            - layout (é…åˆ—): å¦‚"75é…åˆ—"ã€"98é…åˆ—"ã€"å…¨å°ºå¯¸"
            - structure (ç»“æ„): å¦‚"Gasket"ã€"PCå®šä½æ¿"
            - connection (è¿æ¥æ–¹å¼): å¦‚"ä¸‰æ¨¡"ã€"2.4G+è“ç‰™+æœ‰çº¿"
            - switch (è½´ä½“ç±»å‹): å¦‚"TTCé‡‘èŒ¶è½´"ã€"ä½³è¾¾éš†Gé»„Pro"
            - keycap (é”®å¸½æè´¨): å¦‚"PBT"ã€"ABS"
            - hot_swappable (çƒ­æ’æ‹”): å¦‚"æ”¯æŒ"ã€"ä¸æ”¯æŒ"
            - polling_rate (å›æŠ¥ç‡): å¦‚"1000Hz"
            """
        else:
            return {}

        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¤–è®¾å‚æ•°æå–åŠ©æ‰‹ã€‚

è¯·ä»ä»¥ä¸‹äº§å“æ–‡ç« ä¸­æå–æ‰€æœ‰å¯ç”¨çš„å‚æ•°ä¿¡æ¯ã€‚

äº§å“ç±»åˆ«ï¼š{category}

éœ€è¦æå–çš„å­—æ®µï¼š
{fields_definition}

æ–‡ç« å†…å®¹ï¼š
{content[:2000]}

è¦æ±‚ï¼š
1. ä»”ç»†é˜…è¯»æ–‡ç« ï¼Œæå–æ‰€æœ‰æåˆ°çš„å‚æ•°
2. åªè¾“å‡ºJSONæ ¼å¼ï¼Œä¸è¦å…¶ä»–æ–‡å­—
3. å¦‚æœæŸä¸ªå‚æ•°åœ¨æ–‡ç« ä¸­æ²¡æœ‰æåˆ°ï¼Œè®¾ä¸º null
4. è¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼š
{{
  "weight": "50g",
  "sensor": "PAW3395",
  "polling_rate": "1000Hz",
  "connection": "ä¸‰æ¨¡"
}}

è¯·è¾“å‡ºJSONï¼š"""

        try:
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {self.llm_config.get('api_key', '')}"
            }

            data = {
                "model": self.llm_config.get("model", ""),
                "messages": [
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¤–è®¾å‚æ•°æå–åŠ©æ‰‹ã€‚åªè¾“å‡ºJSONæ ¼å¼çš„å‚æ•°æ•°æ®ï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"
                    },
                    {"role": "user", "content": prompt}
                ],
                "temperature": 0.1,
                "max_tokens": 500,
                "stream": False
            }

            base_url = self.llm_config.get("base_url", "").rstrip('/')
            url = f"{base_url}/v1/chat/completions"

            response = requests.post(url, headers=headers, json=data, timeout=30)
            response.raise_for_status()

            result = response.json()
            extracted_text = result["choices"][0]["message"]["content"].strip()

            # è§£æ JSON
            import json
            # æ¸…ç†å¯èƒ½çš„ markdown ä»£ç å—æ ‡è®°
            if extracted_text.startswith('```'):
                extracted_text = extracted_text.split('```')[1]
                if extracted_text.startswith('json'):
                    extracted_text = extracted_text[4:]

            extracted_params = json.loads(extracted_text)

            # è¿‡æ»¤æ‰ null å€¼
            return {k: v for k, v in extracted_params.items() if v and v != 'æœªçŸ¥' and v != 'æœªæåŠ'}

        except Exception as e:
            print(f"        [LLMæ–‡ç« æå–] å¤±è´¥: {str(e)[:50]}")
            return {}

    def complete_parameters(self, product: Dict, search_func=None) -> Dict:
        """
        å®Œæ•´çš„å‚æ•°è¡¥å…¨æµç¨‹

        æµç¨‹ï¼š
        1. ä»åŸæ–‡ç« å†…å®¹ä¸­æå–å‚æ•°
        2. æ£€æŸ¥ç¼ºå¤±å­—æ®µ
        3. å¯¹ç¼ºå¤±å­—æ®µè¿›è¡Œ MCP æœç´¢
        4. ç”¨ LLM ä»æœç´¢ç»“æœä¸­æå–å‚æ•°
        5. å›å¡«æ•°æ®
        6. è¡¥å……é¢å¤–å‘ç°çš„å‚æ•°

        Args:
            product: äº§å“æ•°æ®å­—å…¸
            search_func: MCP æœç´¢å‡½æ•° (query: str) -> str

        Returns:
            æ›´æ–°åçš„äº§å“å­—å…¸
        """
        # æ­¥éª¤1: ä»åŸæ–‡ç« ä¸­æå–å‚æ•°
        print(f"    [å‚æ•°è¡¥å…¨] å¼€å§‹å¤„ç†: {product.get('product_name', 'Unknown')[:40]}")

        product = self.extract_from_article(product)

        # æ­¥éª¤2: æ£€æŸ¥ç¼ºå¤±å­—æ®µ
        completeness = self.check_completeness(product)

        if not completeness['missing']:
            print(f"    [å‚æ•°è¡¥å…¨] æ‰€æœ‰å‚æ•°å®Œæ•´ï¼Œæ— éœ€æœç´¢")
            return product

        print(f"    [å‚æ•°è¡¥å…¨] æ£€æµ‹åˆ° {len(completeness['missing'])} ä¸ªç¼ºå¤±å­—æ®µ")

        # æ­¥éª¤3-5: æ‰¹é‡ MCP æœç´¢ + LLM æå–
        if search_func or self.custom_search_func:
            search_function = search_func or self.custom_search_func

            for search_item in completeness['search_queries']:
                field = search_item['field']
                query = search_item['query']

                try:
                    # MCP æœç´¢
                    print(f"      [æœç´¢] {search_item['field_name']}: {query}")
                    search_result = search_function(query)

                    if search_result:
                        # LLM æå–ï¼ˆåŒæ—¶æå–ç›®æ ‡å‚æ•°å’Œé¢å¤–å‚æ•°ï¼‰
                        extracted = self._extract_with_extra_params(
                            search_result,
                            field,
                            product.get('category', '')
                        )

                        if extracted.get('target_value'):
                            # å›å¡«ç›®æ ‡å‚æ•°
                            old_value = product['specs'].get(field, '')
                            product['specs'][field] = extracted['target_value']
                            print(f"      [è¡¥å…¨] [OK] {search_item['field_name']}: {extracted['target_value']} (MCP+LLM)")

                        # è¡¥å……é¢å¤–å‘ç°çš„å‚æ•°
                        if extracted.get('extra_params'):
                            for extra_field, extra_value in extracted['extra_params'].items():
                                if extra_field not in product['specs'] or not product['specs'][extra_field]:
                                    field_name_cn = self.field_names_cn.get(extra_field, extra_field)
                                    product['specs'][extra_field] = extra_value
                                    print(f"      [è¡¥å……] [+] {field_name_cn}: {extra_value} (é¢å¤–å‘ç°)")
                    else:
                        print(f"      [æœç´¢] [X] {search_item['field_name']}: æœç´¢æ— ç»“æœ")

                except Exception as e:
                    print(f"      [æœç´¢] [X] å¤±è´¥: {str(e)[:50]}")
        else:
            print(f"    [å‚æ•°è¡¥å…¨] æœªæä¾›æœç´¢å‡½æ•°ï¼Œè·³è¿‡ MCP æœç´¢")

        # æ­¥éª¤6: æ ‡è®°æœªçŸ¥å‚æ•°
        for field in completeness['missing']:
            if not product['specs'].get(field):
                product['specs'][field] = 'æœªçŸ¥'

        return product

    def _extract_with_extra_params(self, search_result: str, target_field: str, category: str) -> Dict:
        """
        ä»æœç´¢ç»“æœä¸­æå–ç›®æ ‡å‚æ•°ï¼Œå¹¶åŒæ—¶æå–å…¶ä»–å‘ç°çš„å‚æ•°

        Args:
            search_result: MCP æœç´¢ç»“æœï¼ˆJSONå­—ç¬¦ä¸²ï¼‰
            target_field: ç›®æ ‡å­—æ®µå
            category: äº§å“ç±»åˆ«

        Returns:
            {
                'target_value': 'ç›®æ ‡å­—æ®µçš„å€¼',
                'extra_params': {'å…¶ä»–å­—æ®µ': 'å€¼'}  # é¢å¤–å‘ç°çš„å‚æ•°
            }
        """
        # è§£ææœç´¢ç»“æœ
        content = self._parse_search_result(search_result)

        if not content:
            return {'target_value': None, 'extra_params': {}}

        # å®šä¹‰è¦æå–çš„æ‰€æœ‰å­—æ®µ
        if category == 'é¼ æ ‡':
            all_fields = {
                'weight': 'é‡é‡',
                'sensor': 'ä¼ æ„Ÿå™¨å‹å·',
                'polling_rate': 'å›æŠ¥ç‡',
                'dpi': 'æœ€é«˜DPI',
                'connection': 'è¿æ¥æ–¹å¼',
                'buttons': 'æŒ‰é”®æ•°é‡',
                'battery': 'ç”µæ± ç»­èˆª'
            }
        elif category == 'é”®ç›˜':
            all_fields = {
                'layout': 'é…åˆ—',
                'structure': 'ç»“æ„',
                'connection': 'è¿æ¥æ–¹å¼',
                'switch': 'è½´ä½“ç±»å‹',
                'keycap': 'é”®å¸½æè´¨',
                'hot_swappable': 'çƒ­æ’æ‹”',
                'polling_rate': 'å›æŠ¥ç‡'
            }
        else:
            return {'target_value': None, 'extra_params': {}}

        # ä½¿ç”¨ LLM æå–æ‰€æœ‰å‚æ•°
        target_field_cn = self.field_names_cn.get(target_field, target_field)
        all_extracted = self._extract_all_fields_from_search(content, all_fields, category)

        # åˆ†ç¦»ç›®æ ‡å­—æ®µå’Œé¢å¤–å­—æ®µ
        target_value = all_extracted.get(target_field)
        extra_params = {k: v for k, v in all_extracted.items() if k != target_field and v and v != 'æœªçŸ¥'}

        return {
            'target_value': target_value,
            'extra_params': extra_params
        }

    def _extract_all_fields_from_search(self, content: str, fields: Dict[str, str], category: str) -> Dict[str, str]:
        """
        ä»æœç´¢ç»“æœä¸­æå–æ‰€æœ‰æŒ‡å®šå­—æ®µ

        Args:
            content: æœç´¢ç»“æœæ–‡æœ¬
            fields: å­—æ®µå­—å…¸ {field: field_name_cn}
            category: äº§å“ç±»åˆ«

        Returns:
            æå–çš„å‚æ•°å­—å…¸
        """
        import requests

        # æ„é€ å­—æ®µè¯´æ˜
        fields_desc = "\n".join([f"  - {field} ({fields[field]}): å‚æ•°å€¼" for field in fields])

        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¤–è®¾å‚æ•°æå–åŠ©æ‰‹ã€‚

è¯·ä»ä»¥ä¸‹äº§å“æœç´¢ç»“æœä¸­æå–æ‰€æœ‰å¯ç”¨çš„å‚æ•°ã€‚

äº§å“ç±»åˆ«ï¼š{category}

éœ€è¦æå–çš„å­—æ®µï¼š
{fields_desc}

æœç´¢ç»“æœï¼š
{content}

è¦æ±‚ï¼š
1. åªè¾“å‡ºJSONæ ¼å¼
2. å¦‚æœæŸä¸ªå‚æ•°åœ¨æœç´¢ç»“æœä¸­æ²¡æœ‰æåˆ°ï¼Œè®¾ä¸º null
3. æå–ç¤ºä¾‹ï¼š
   - é‡é‡ï¼š50gã€çº¦50å…‹ â†’ {{"weight": "50g"}}
   - ä¼ æ„Ÿå™¨ï¼šPAW3395ä¼ æ„Ÿå™¨ â†’ {{"sensor": "PAW3395"}}
   - å›æŠ¥ç‡ï¼š8Kå›æŠ¥ç‡ â†’ {{"polling_rate": "8000Hz"}}

è¯·è¾“å‡ºJSONï¼š"""

        try:
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {self.llm_config.get('api_key', '')}"
            }

            data = {
                "model": self.llm_config.get("model", ""),
                "messages": [
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¤–è®¾å‚æ•°æå–åŠ©æ‰‹ã€‚åªè¾“å‡ºJSONæ ¼å¼çš„å‚æ•°æ•°æ®ã€‚"
                    },
                    {"role": "user", "content": prompt}
                ],
                "temperature": 0.1,
                "max_tokens": 500,
                "stream": False
            }

            base_url = self.llm_config.get("base_url", "").rstrip('/')
            url = f"{base_url}/v1/chat/completions"

            response = requests.post(url, headers=headers, json=data, timeout=30)
            response.raise_for_status()

            result = response.json()
            extracted_text = result["choices"][0]["message"]["content"].strip()

            # è§£æ JSON
            import json
            if extracted_text.startswith('```'):
                extracted_text = extracted_text.split('```')[1]
                if extracted_text.startswith('json'):
                    extracted_text = extracted_text[4:]

            extracted_params = json.loads(extracted_text)

            return {k: v for k, v in extracted_params.items() if v and v != 'æœªçŸ¥' and v != 'æœªæåŠ'}

        except Exception as e:
            print(f"        [LLMæ‰¹é‡æå–] å¤±è´¥: {str(e)[:50]}")
            # å›é€€ï¼šåªæå–ç›®æ ‡å­—æ®µ
            return {}

    def _call_search_api_fallback(self, query: str) -> Optional[str]:
        """
        å›é€€æ–¹æ¡ˆï¼šé€šè¿‡ requests è°ƒç”¨å†…ç½‘æœç´¢ API

        Args:
            query: æœç´¢æŸ¥è¯¢

        Returns:
            æœç´¢ç»“æœæ‘˜è¦æ–‡æœ¬
        """
        import requests
        import json

        url = f"{self.search_config['base_url']}/mcp_web_search"

        headers = {
            "Content-Type": "application/json",
            "Accept": "application/json, text/event-stream"
        }

        data = {
            "jsonrpc": "2.0",
            "id": 1,
            "method": "tools/call",
            "params": {
                "name": "webSearchPrime",
                "arguments": {
                    "search_query": query,
                    "content_size": "medium"
                }
            }
        }

        if self.search_config.get('api_key'):
            data["params"]["arguments"]["api_key"] = self.search_config['api_key']
            data["params"]["arguments"]["authorization"] = self.search_config['api_key']

        try:
            response = requests.post(url, headers=headers, json=data, timeout=self.search_config.get('timeout', 10))
            response.raise_for_status()

            content_type = response.headers.get('content-type', '')

            if 'text/event-stream' in content_type:
                lines = response.text.split('\n')
                all_results = []
                for line in lines:
                    line = line.strip()
                    if line.startswith('data:'):
                        json_str = line[5:].strip()
                        if json_str and json_str != '[DONE]':
                            try:
                                data_obj = json.loads(json_str)
                                if 'result' in data_obj and 'content' in data_obj['result']:
                                    for item in data_obj['result']['content']:
                                        if isinstance(item, dict) and 'text' in item:
                                            all_results.append(item['text'])
                            except json.JSONDecodeError:
                                continue

                if all_results:
                    return '\n\n'.join(all_results[:3])
                return None

            return None

        except Exception as e:
            print(f"        [æœç´¢API-Fallback] è°ƒç”¨å¤±è´¥: {str(e)[:100]}")
            return None


class ParameterCompleterV2:
    """
    å‚æ•°è¡¥å…¨å™¨ V2 - æ”¯æŒ Top 20 Schema å’Œèšåˆæœç´¢

    æ ¸å¿ƒæ”¹è¿›ï¼š
    1. ä½¿ç”¨ Top 20 æ ‡å‡†åŒ– Schema
    2. èšåˆæœç´¢ï¼ˆ1æ¬¡æœç´¢è·å–æ‰€æœ‰ç¼ºå¤±å‚æ•°ï¼Œè€ŒéNæ¬¡ï¼‰
    3. æ•°æ®æºè¿½è¸ª
    """

    def __init__(self, llm_config: Dict = None, search_func=None):
        """
        åˆå§‹åŒ–å‚æ•°è¡¥å…¨å™¨

        Args:
            llm_config: LLM é…ç½®
            search_func: MCP æœç´¢å‡½æ•° (query: str) -> str
        """
        self.llm_config = llm_config or LLM_CONFIG
        self.search_func = search_func
        self.search_enabled = bool(search_func)  # æ˜¯å¦å¯ç”¨æœç´¢åŠŸèƒ½

    def complete_parameters(self, product: Dict) -> Dict:
        """
        å®Œæ•´çš„å‚æ•°è¡¥å…¨æµç¨‹

        æµç¨‹ï¼š
        1. ä»åŸæ–‡ç« æå– Top 20 å‚æ•°
        2. æ£€æŸ¥ç¼ºå¤±å­—æ®µ
        3. èšåˆæœç´¢ï¼ˆ1æ¬¡æœç´¢è·å–æ‰€æœ‰ç¼ºå¤±å‚æ•°ï¼‰
        4. LLM æå–è¡¥å…¨
        5. è®°å½•æ•°æ®æ¥æº

        Args:
            product: äº§å“æ•°æ®ï¼Œå¿…é¡»åŒ…å« category å’Œ content_text

        Returns:
            æ›´æ–°åçš„äº§å“æ•°æ®ï¼ŒåŒ…å« specs å’Œ data_sources
        """
        category = product.get('category', '')
        article_content = product.get('content_text', '')

        # é€‰æ‹©å¯¹åº”çš„ Schema
        if 'é¼ æ ‡' in category or category == 'mouse' or category == 'é¼ æ ‡':
            schema = MOUSE_SCHEMA
        elif 'é”®ç›˜' in category or category == 'keyboard' or category == 'é”®ç›˜':
            schema = KEYBOARD_SCHEMA
        else:
            return product

        # åˆå§‹åŒ– specs å’Œ data_sources
        if 'specs' not in product:
            product['specs'] = {}
        if 'data_sources' not in product:
            product['data_sources'] = {}

        # æ­¥éª¤1: ä»åŸæ–‡ç« æå–å‚æ•°
        article_params = self._extract_from_article(article_content, schema)
        for field, value in article_params.items():
            if value and value != 'æœªçŸ¥':
                product['specs'][field] = value
                product['data_sources'][field] = 'article'

        # æ­¥éª¤2: æ£€æŸ¥ç¼ºå¤±å­—æ®µ
        missing_fields = [f for f in schema.keys() if not product['specs'].get(f)]

        if not missing_fields:
            return product

        # æ­¥éª¤3: èšåˆæœç´¢ + LLM æå–
        if self.search_func:
            search_params = self._aggregate_search_and_extract(
                product,
                missing_fields,
                schema
            )

            for field, value in search_params.items():
                if value and value != 'æœªçŸ¥':
                    product['specs'][field] = value
                    product['data_sources'][field] = 'search'
        else:
            # æ ‡è®°ç¼ºå¤±å­—æ®µä¸ºæœªçŸ¥
            for field in missing_fields:
                if not product['specs'].get(field):
                    product['specs'][field] = None
                    product['data_sources'][field] = 'unknown'

        return product

    def _extract_from_article(self, content: str, schema: Dict) -> Dict:
        """ä»æ–‡ç« å†…å®¹ä¸­æå–å‚æ•°ï¼ˆå¢å¼ºç‰ˆï¼šçŸ¥è¯†åº“è¡¥å…¨ + å…³é”®å‚æ•°ä¼˜å…ˆï¼‰"""
        if not content:
            return {}

        import requests
        import json

        # æ„é€ å­—æ®µè¯´æ˜
        fields_desc = "\n".join([f"  - {field} ({schema[field]})" for field in schema])

        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¤–è®¾å‚æ•°æå–åŠ©æ‰‹ï¼Œæ‹¥æœ‰ä¸°å¯Œçš„å¤–è®¾äº§å“çŸ¥è¯†åº“ã€‚

è¯·ä»ä»¥ä¸‹äº§å“æ–‡ç« ä¸­æå–æ‰€æœ‰å¯ç”¨çš„å‚æ•°ä¿¡æ¯ã€‚

éœ€è¦æå–çš„å­—æ®µï¼ˆTop 15 æ ‡å‡†åŒ– Schemaï¼‰ï¼š
{fields_desc}

æ–‡ç« å†…å®¹ï¼š
{content[:3000]}

**é‡è¦è¦æ±‚ï¼ˆP0 ä¼˜å…ˆçº§ï¼‰**ï¼š

1. **çŸ¥è¯†åº“è¡¥å…¨ï¼ˆCriticalï¼‰**ï¼š
   - å¦‚æœæ–‡ç« æœªæ˜ç¡®æåŠæŸäº›å‚æ•°ï¼Œä½†ä½ å¯ä»¥æ ¹æ®äº§å“å‹å·/å“ç‰Œæ¨æ–­å‡ºå¸¸è§é…ç½®ï¼Œè¯·åˆ©ç”¨ä½ çš„çŸ¥è¯†åº“è¿›è¡Œè¡¥å…¨
   - ä¾‹å¦‚ï¼šç½—æŠ€G304ç³»åˆ—é€šå¸¸ç”¨Hero 25Kä¼ æ„Ÿå™¨ï¼Œé›·è›‡é»‘å¯¡å¦‡V4é€šå¸¸ç”¨Greenæœºæ¢°è½´
   - æ¨æ–­çš„å‚æ•°è¯·æ ‡æ³¨ "ï¼ˆæ¨æ–­ï¼‰" æˆ– "ï¼ˆå¸¸è§„é…ç½®ï¼‰"

2. **ä¸¥ç¦è¿”å› "æœªçŸ¥" æˆ– null**ï¼š
   - å¯¹äºæœªæåŠçš„å‚æ•°ï¼Œä¼˜å…ˆä½¿ç”¨çŸ¥è¯†åº“æ¨æ–­
   - å®åœ¨æ— æ³•æ¨æ–­çš„ï¼Œæ ‡æ³¨ "å¾…å®æµ‹" æˆ– "æœªæåŠ"
   - ç»å¯¹ä¸è¦å¡« "æœªçŸ¥" æˆ–ç•™ç©º

3. **å…³é”®å‚æ•°é«˜æƒé‡æå–**ï¼š

   **é¼ æ ‡ - å¿…é¡»ä¼˜å…ˆæå–**ï¼š
   - MCU/ä¸»æ§èŠ¯ç‰‡ï¼šå…³é”®è¯åŒ…æ‹¬ Nordicã€åšé€šã€ç‘æ˜±ã€ä¸»æ§ã€èŠ¯ç‰‡ã€MCUã€nRF
   - ä¼ æ„Ÿå™¨ï¼šHeroã€PAW3395ã€PAW3950ã€ä¼ æ„Ÿå™¨å‹å·
   - é‡é‡ï¼šxxgã€å…‹ã€è½»ç›ˆ

   **é”®ç›˜ - å¿…é¡»ä¼˜å…ˆæå–**ï¼š
   - å‰é«˜/ä¸‹æ²¿é«˜åº¦ï¼šå…³é”®è¯ "å‰é«˜"ã€"ä¸‹æ²¿"ã€"é«˜åº¦"ã€"mm"
   - å®æµ‹å»¶è¿Ÿï¼šå…³é”®è¯ "å»¶è¿Ÿ"ã€"ms"ã€"RT"ã€"å›æŠ¥ç‡"
   - ç£è½´ç‰¹æ®Šå‚æ•°ï¼šæ­»åŒºï¼ˆ0.xx mmï¼‰ã€ç²¾åº¦ã€è§¦å‘

4. **å¤šç‰ˆæœ¬å‚æ•°å¤„ç†**ï¼š
   - å¦‚æœäº§å“æœ‰å¤šä¸ªç‰ˆæœ¬ï¼ˆæ ‡å‡†ç‰ˆ/Proç‰ˆ/MCç‰ˆ/Maxç‰ˆï¼‰ï¼Œè¯·åˆå¹¶ä¸ºæ˜“è¯»æ ¼å¼
   - ä¾‹å¦‚ï¼šä¸è¦è¾“å‡º {{'MCç‰ˆ': 'PAW3311', 'MAXç‰ˆ': 'PAW3395'}}
   - æ­£ç¡®è¾“å‡ºï¼šMCç‰ˆ: PAW3311 / MAXç‰ˆ: PAW3395

5. **è¾“å‡ºæ ¼å¼**ï¼š
   - åªè¾“å‡ºJSONæ ¼å¼
   - æ•°å€¼å•ä½ä¿æŒåŸæ–‡ï¼ˆå¦‚ "50g", "1000Hz"ï¼‰
   - ä¸è¦è¾“å‡ºä»»ä½•è§£é‡Šæ–‡å­—

è¾“å‡ºJSONç¤ºä¾‹ï¼š
{{
  "mold_lineage": "ç»å…¸G304æ¨¡å…·ï¼Œå°æ‰‹å¯¹ç§°è®¾è®¡",
  "weight_center": "57gï¼Œé‡å¿ƒå±…ä¸­",
  "sensor_solution": "Hero 25Kå…‰å­¦ä¼ æ„Ÿå™¨",
  "mcu_chip": "Nordic nRF52840ï¼ˆæ¨æ–­ï¼‰",
  "polling_rate": "1000Hz"
}}

è¯·è¾“å‡ºJSONï¼š"""

        try:
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {self.llm_config.get('api_key', '')}"
            }

            data = {
                "model": self.llm_config.get("model", ""),
                "messages": [
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¤–è®¾å‚æ•°æå–åŠ©æ‰‹ï¼Œæ‹¥æœ‰ä¸°å¯Œçš„å¤–è®¾äº§å“çŸ¥è¯†åº“ã€‚å¯¹äºæœªæåŠçš„å‚æ•°ï¼Œåˆ©ç”¨çŸ¥è¯†åº“è¿›è¡Œåˆç†æ¨æ–­ï¼Œæ ‡æ³¨ï¼ˆæ¨æ–­ï¼‰ã€‚ä¸¥ç¦è¿”å›nullæˆ–æœªçŸ¥ã€‚"
                    },
                    {"role": "user", "content": prompt}
                ],
                "temperature": 0.2,  # ç¨å¾®æé«˜æ¸©åº¦ä»¥å…è®¸çŸ¥è¯†åº“æ¨æ–­
                "max_tokens": 1500,  # å¢åŠ tokené•¿åº¦ä»¥æ”¯æŒæ›´è¯¦ç»†çš„è¾“å‡º
                "stream": False
            }

            base_url = self.llm_config.get("base_url", "").rstrip('/')
            url = f"{base_url}/v1/chat/completions"

            response = requests.post(url, headers=headers, json=data, timeout=30)
            response.raise_for_status()

            result = response.json()
            extracted_text = result["choices"][0]["message"]["content"].strip()

            # è§£æ JSON
            if extracted_text.startswith('```'):
                extracted_text = extracted_text.split('```')[1]
                if extracted_text.startswith('json'):
                    extracted_text = extracted_text[4:]

            extracted_params = json.loads(extracted_text)

            return {k: v for k, v in extracted_params.items() if v and v not in ['æœªçŸ¥', 'unknown', 'null', None]}

        except Exception as e:
            # é™é»˜å¤±è´¥
            return {}

    def _aggregate_search_and_extract(
        self,
        product: Dict,
        missing_fields: list,
        schema: Dict
    ) -> Dict:
        """
        èšåˆæœç´¢å¹¶æå–æ‰€æœ‰ç¼ºå¤±å‚æ•°

        å…³é”®ä¼˜åŒ–ï¼šåªæ‰§è¡Œ 1 æ¬¡æœç´¢ï¼Œè€Œä¸æ˜¯ N æ¬¡
        """
        import requests
        import json

        product_name = product.get('product_name', '')
        category = product.get('category', '')

        # æ„é€ èšåˆæœç´¢æŸ¥è¯¢
        if 'é¼ æ ‡' in category:
            search_query = f'"{product_name}" è¯¦ç»†å‚æ•°è§„æ ¼ é‡é‡ ä¼ æ„Ÿå™¨ DPI å›æŠ¥ç‡ è¿æ¥æ–¹å¼'
        else:
            search_query = f'"{product_name}" è¯¦ç»†å‚æ•°è§„æ ¼ é…åˆ— ç»“æ„ è½´ä½“ è¿æ¥æ–¹å¼'

        # æ‰§è¡Œæœç´¢
        search_result = self.search_func(search_query)

        if not search_result:
            return {}

        # è§£ææœç´¢ç»“æœ
        content = self._parse_search_result(search_result)

        if not content:
            return {}

        # LLM ä¸€æ¬¡æ€§æå–æ‰€æœ‰ç¼ºå¤±å­—æ®µ
        missing_fields_desc = "\n".join([f"  - {field} ({schema[field]})" for field in missing_fields])

        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¤–è®¾å‚æ•°æå–åŠ©æ‰‹ã€‚

è¯·ä»ä»¥ä¸‹äº§å“æœç´¢ç»“æœä¸­æå–æ‰€æœ‰å¯ç”¨çš„å‚æ•°ã€‚

äº§å“åç§°ï¼š{product_name}

éœ€è¦æå–çš„å­—æ®µï¼ˆåªæå–è¿™äº›å­—æ®µï¼‰ï¼š
{missing_fields_desc}

æœç´¢ç»“æœï¼š
{content}

è¦æ±‚ï¼š
1. åªè¾“å‡ºJSONæ ¼å¼
2. å¦‚æœæŸä¸ªå‚æ•°æ²¡æœ‰æåˆ°ï¼Œè®¾ä¸º null
3. è¾“å‡ºæ ¼å¼ç¤ºä¾‹ï¼š
{{
  "weight": "50g",
  "sensor_model": "PAW3395"
}}

è¯·è¾“å‡ºJSONï¼š"""

        try:
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {self.llm_config.get('api_key', '')}"
            }

            data = {
                "model": self.llm_config.get("model", ""),
                "messages": [
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¤–è®¾å‚æ•°æå–åŠ©æ‰‹ã€‚åªè¾“å‡ºJSONæ ¼å¼çš„å‚æ•°æ•°æ®ã€‚"
                    },
                    {"role": "user", "content": prompt}
                ],
                "temperature": 0.1,
                "max_tokens": 1000,
                "stream": False
            }

            base_url = self.llm_config.get("base_url", "").rstrip('/')
            url = f"{base_url}/v1/chat/completions"

            response = requests.post(url, headers=headers, json=data, timeout=30)
            response.raise_for_status()

            result = response.json()
            extracted_text = result["choices"][0]["message"]["content"].strip()

            # è§£æ JSON
            if extracted_text.startswith('```'):
                extracted_text = extracted_text.split('```')[1]
                if extracted_text.startswith('json'):
                    extracted_text = extracted_text[4:]

            extracted_params = json.loads(extracted_text)

            return {k: v for k, v in extracted_params.items() if v and v != 'æœªçŸ¥'}

        except Exception as e:
            # é™é»˜å¤±è´¥
            return {}

    def _parse_search_result(self, search_text: str) -> str:
        """è§£ææœç´¢ç»“æœï¼Œæå–çº¯æ–‡æœ¬å†…å®¹"""
        import json

        try:
            results = json.loads(search_text)
            if isinstance(results, list) and len(results) > 0:
                content_texts = []
                for result in results[:3]:
                    content = result.get('content', '')
                    if content:
                        content_texts.append(content)

                if content_texts:
                    return '\n\n'.join(content_texts)
        except json.JSONDecodeError:
            pass

        return search_text


class LLMExtractor:
    """LLM æ™ºèƒ½æå–å™¨ - PM è§†è§’åˆ†æ"""

    def __init__(self, config: Dict):
        self.config = config
        self.api_key = config.get("api_key", "")

        # å¼ºåˆ¶ä½¿ç”¨APIæ¨¡å¼
        invalid_keys = ["", "sk-your-key-here", "your-api-key", "your-api-key-here"]
        # æ³¨æ„ï¼šsk-xxx æ˜¯å…¬å¸å†…éƒ¨çš„æœ‰æ•ˆKeyï¼Œä¸åœ¨æ— æ•ˆåˆ—è¡¨ä¸­

        if not self.api_key or self.api_key in invalid_keys:
            raise ValueError(
                f"æœªé…ç½®æˆ–ä½¿ç”¨äº†æ— æ•ˆçš„ API Keyï¼ˆå½“å‰: {repr(self.api_key)}ï¼‰ï¼\n"
                f"è¯·é…ç½®æœ‰æ•ˆçš„API Keyåé‡è¯•ã€‚\n"
                f"ä¿®æ”¹ä½ç½®: etl_pipeline.py ç¬¬22è¡Œ"
            )

        self.use_mock = False
        print(f"[INFO] ä½¿ç”¨çœŸå®APIæ¨¡å¼ï¼ˆAPI Key: {self.api_key[:15]}...)")

        # å“ç‰Œæƒé‡é…ç½®ï¼ˆç”¨äºæ’åºï¼‰
        self.brand_weights = {
            'ç½—æŠ€': 100, 'logitech': 100,
            'é›·è›‡': 95, 'razer': 95,
            'rog': 90, 'åç¡•': 85,
            'èµ›ç¿': 85, 'steelseries': 85,
            'æµ·ç›—èˆ¹': 80, 'corsair': 80,
            'å“å¨': 80, 'zowie': 80,
            'vgn': 70, 'vek': 70,
            'atk': 65, 'ç‹¼è››': 60,
            'é›·æŸ': 55, 'rapoo': 55,
            'è‹±è²å…‹': 50,
            'é­”ç‚¼': 45,
            'é»‘ç§‘': 40
        }

    def extract_price_from_content(self, content: str) -> Optional[str]:
        """
        ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ä»æ­£æ–‡å†…å®¹ä¸­æš´åŠ›æå–ä»·æ ¼

        æ”¯æŒçš„æ¨¡å¼ï¼š
        - å”®ä»·çº¦XXXå…ƒ
        - é¦–å‘ä»·XXX
        - åˆ°æ‰‹XXXå…ƒ
        - å®šä»·XXXå…ƒ
        """
        if not content:
            return None

        # å¤šç§ä»·æ ¼åŒ¹é…æ¨¡å¼
        price_patterns = [
            r'(?:å”®ä»·|ä»·æ ¼|é¦–å‘|å®šä»·|åˆ°æ‰‹|çº¦|çº¦\s*Â¥|Â¥|\$)\s*(\d{2,4})\s*(?:å…ƒ|åœ†|rmb)?',
            r'(\d{2,4})\s*(?:å…ƒ|åœ†|rmb)\s*(?:å”®ä»·|ä»·æ ¼|é¦–å‘|å®šä»·)?',
            r'(?:å”®ä»·|ä»·æ ¼|é¦–å‘|å®šä»·).*?(\d{2,4})\s*(?:å…ƒ|åœ†)?',
        ]

        for pattern in price_patterns:
            match = re.search(pattern, content, re.IGNORECASE)
            if match:
                price = match.group(1)
                # è¿‡æ»¤æ‰æ˜æ˜¾ä¸æ˜¯ä»·æ ¼çš„æ•°å­—ï¼ˆå¦‚æ—¥æœŸã€å‹å·ï¼‰
                if 29 <= int(price) <= 2999:  # åˆç†çš„å¤–è®¾ä»·æ ¼èŒƒå›´
                    return f"{price}å…ƒï¼ˆé¢„ä¼°ï¼‰"

        return None

    def calculate_product_priority(self, product: Dict) -> float:
        """
        è®¡ç®—äº§å“ä¼˜å…ˆçº§åˆ†æ•°ï¼ˆç”¨äºæ’åºï¼‰

        è€ƒè™‘å› ç´ ï¼š
        1. å“ç‰Œæƒé‡ï¼ˆç½—æŠ€/é›·è›‡/ROGç­‰ä¸€çº¿å“ç‰Œä¼˜å…ˆï¼‰
        2. æ–‡ç« é•¿åº¦ï¼ˆé•¿æ–‡ç« =æ·±åº¦è¯„æµ‹=æ›´å€¼å¾—å…³æ³¨ï¼‰
        3. å›¾ç‰‡æ•°é‡ï¼ˆå¤šå›¾=æ›´å®Œæ•´çš„äº§å“å±•ç¤ºï¼‰

        Returns:
            ä¼˜å…ˆçº§åˆ†æ•°ï¼ˆè¶Šé«˜è¶Šé å‰ï¼‰
        """
        score = 0.0

        # 1. å“ç‰Œæƒé‡ï¼ˆ0-100åˆ†ï¼‰
        product_name = product.get('product_name', '').lower()
        brand_weight = 0

        for brand, weight in self.brand_weights.items():
            if brand in product_name:
                brand_weight = max(brand_weight, weight)

        score += brand_weight

        # 2. æ–‡ç« é•¿åº¦æƒé‡ï¼ˆ0-30åˆ†ï¼‰
        # æ–‡ç« è¶Šé•¿ï¼Œè¯´æ˜ä¿¡æ¯è¶Šå®Œæ•´
        content = product.get('combined_content', '')
        article_length = len(content)
        length_score = min(30, article_length / 500)  # æ¯500å­—ç¬¦åŠ 1åˆ†ï¼Œæœ€é«˜30åˆ†
        score += length_score

        # 3. å›¾ç‰‡æ•°é‡æƒé‡ï¼ˆ0-10åˆ†ï¼‰
        images = product.get('images', [])
        image_count = len(images) if isinstance(images, list) else 0
        image_score = min(10, image_count * 2)  # æ¯å¼ å›¾2åˆ†ï¼Œæœ€é«˜10åˆ†
        score += image_score

        return score

    def extract_product_info(self, product: Dict) -> Dict:
        """æå–äº§å“ä¿¡æ¯ - PM è§†è§’æ·±åº¦åˆ†æï¼ˆå¼ºåˆ¶ä½¿ç”¨APIï¼‰"""
        # å¼ºåˆ¶ä½¿ç”¨çœŸå®çš„ LLM è°ƒç”¨
        context = product['combined_content'][:10000]  # å¢åŠ é•¿åº¦é™åˆ¶ä»¥æ”¯æŒ PM åˆ†æ

        # æå–ä¸»å›¾
        main_image = product.get('images', [''])[0] if product.get('images') else ''

        prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±çš„å¤–è®¾äº§å“ç»ç†å’Œç¡¬ä»¶è¯„æµ‹å¸ˆï¼Œæ“…é•¿ä»äº§å“æ–°é—»ç¨¿ä¸­æå–å…³é”®ä¿¡æ¯å¹¶è¿›è¡Œæ·±åº¦ç«å“åˆ†æã€æ‰¹åˆ¤æ€§è¯„ä¼°ã€‚

è¯·é˜…è¯»ä»¥ä¸‹äº§å“æ–‡æ¡£ï¼Œæå–æ ¸å¿ƒå‚æ•°å¹¶è¿›è¡Œæ·±åº¦åˆ†æã€‚

æ–‡æœ¬å†…å®¹ï¼š
{context}

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¿”å›ï¼ˆä¸è¦æœ‰ä»»ä½•å…¶ä»–æ–‡å­—ï¼‰ï¼š

{{
  "product_name": "æ ‡å‡†åŒ–äº§å“å…¨å",
  "category": "é¼ æ ‡" æˆ– "é”®ç›˜" æˆ– "å…¶ä»–",
  "main_image": "{main_image}",
  "release_price": "å‘å¸ƒä»·æ ¼ï¼ˆå¦‚æœ‰ï¼‰",
  "innovation_tags": ["åˆ›æ–°æ ‡ç­¾1", "åˆ›æ–°æ ‡ç­¾2"],
  "specs": {{
    // é¼ æ ‡ Top 15 Schema å­—æ®µ
    "product_pricing": "äº§å“ä¸å®šä»·",
    "mold_lineage": "æ¨¡å…·è¡€ç»Ÿ",
    "weight_center": "é‡é‡ä¸é‡å¿ƒ",
    "sensor_solution": "ä¼ æ„Ÿå™¨æ–¹æ¡ˆ",
    "mcu_chip": "ä¸»æ§èŠ¯ç‰‡",
    "polling_rate": "å›æŠ¥ç‡é…ç½®",
    "end_to_end_latency": "å…¨é“¾è·¯å»¶è¿Ÿ",
    "switch_features": "å¾®åŠ¨ç‰¹æ€§",
    "scroll_encoder": "æ»šè½®ç¼–ç å™¨",
    "coating_process": "æ¶‚å±‚å·¥è‰º",
    "high_refresh_battery": "é«˜åˆ·ç»­èˆª",
    "structure_quality": "ç»“æ„åšå·¥",
    "feet_config": "è„šè´´é…ç½®",
    "wireless_interference": "æ— çº¿æŠ—å¹²æ‰°",
    "driver_experience": "é©±åŠ¨ä½“éªŒ"

    // é”®ç›˜ Top 15 Schema å­—æ®µ
    "product_layout": "äº§å“ä¸é…åˆ—",
    "structure_form": "ç»“æ„å½¢å¼",
    "tech_route": "æŠ€æœ¯è·¯çº¿",
    "rt_params": "RTå‚æ•°",
    "sound_dampening": "å£°éŸ³åŒ…å¡«å……",
    "switch_details": "è½´ä½“è¯¦è§£",
    "measured_latency": "å®æµ‹å»¶è¿Ÿ",
    "keycap_craftsmanship": "é”®å¸½å·¥è‰º",
    "bigkey_tuning": "å¤§é”®è°ƒæ ¡",
    "pcb_features": "PCBç‰¹æ€§",
    "case_craftsmanship": "å¤–å£³å·¥è‰º",
    "front_height": "å‰é«˜æ•°æ®",
    "battery_efficiency": "ç”µæ± æ•ˆç‡",
    "connection_storage": "è¿æ¥ä¸æ”¶çº³",
    "software_support": "è½¯ä½“æ”¯æŒ"
  }},
  "analysis": {{
    "market_position": "ä¸€å¥è¯äº§å“å®šä½ï¼ˆå«ä»·æ ¼æ®µå’Œç›®æ ‡å¸‚åœºï¼‰",
    "competitors": "ä¸»è¦ç«å“å¯¹æ¯”ï¼ˆå¿…é¡»æåŠ2-3ä¸ªå…·ä½“å‹å·ï¼ŒåŒ…æ‹¬ç›¸åŒä»·ä½/è§„æ ¼çš„ç«å“ï¼‰",
    "target_audience": "ç›®æ ‡ç”¨æˆ·ç¾¤ä½“ï¼ˆå…·ä½“åˆ°æ¡å§¿/æ‰‹å‹/ä½¿ç”¨åœºæ™¯ï¼‰",
    "selling_point": "æ ¸å¿ƒå–ç‚¹ï¼ˆæ˜ç¡®å·®å¼‚åŒ–ä¼˜åŠ¿ï¼Œä¸ç«å“çš„å…·ä½“åŒºåˆ«ï¼‰",
    "verdict": {{
      "pros": ["ä¼˜ç‚¹1", "ä¼˜ç‚¹2", "ä¼˜ç‚¹3"],
      "cons": ["ç¼ºç‚¹1", "ç¼ºç‚¹2", "ç¼ºç‚¹3ï¼ˆå¿…é¡»æŒ‡å‡ºè‡³å°‘1ä¸ªç¼ºç‚¹ï¼Œå¦‚æº¢ä»·è¿‡é«˜ã€ç»­èˆªå°¿å´©ã€è´¨æ„Ÿå»‰ä»·ç­‰ï¼‰"]
    }},
    "pm_summary": "è´­ä¹°å»ºè®®ï¼ˆ30å­—ä»¥å†…ï¼Œç›´ç™½çŠ€åˆ©ï¼Œç»“åˆç«å“ç»™å‡ºæ˜ç¡®å»ºè®®ï¼‰"
  }}
}}

**æ·±åº¦åˆ†æè¦æ±‚ï¼ˆP0 ä¼˜å…ˆçº§ï¼‰**ï¼š

1. **ç«å“å¯¹æ¯”ï¼ˆCriticalï¼‰**ï¼š
   - å¿…é¡»æåŠ2-3ä¸ªå…·ä½“ç«å“å‹å·ï¼Œè€Œéæ³›æ³›è€Œè°ˆ
   - å¯¹æ¯”ç»´åº¦ï¼šä»·æ ¼ã€æ ¸å¿ƒå‚æ•°ï¼ˆä¼ æ„Ÿå™¨/è½´ä½“ï¼‰ã€é‡é‡ã€ç»­èˆªã€åšå·¥è´¨æ„Ÿ
   - æ˜ç¡®æŒ‡å‡ºæœ¬å“åœ¨ç«å“ä¸­çš„ä½ç½®ï¼šé¢†å…ˆ/æŒå¹³/è½å

2. **ç›®æ ‡ç”¨æˆ·ï¼ˆæ‹’ç»å¥—è·¯åŒ–ï¼‰**ï¼š
   - **ç¦æ­¢**æ³›æ³›è€Œè°ˆï¼š"é€‚åˆè¿½æ±‚è½»é‡åŒ–çš„ç©å®¶"
   - **è¦æ±‚**å…·ä½“åˆ°ï¼šæ¡å§¿ã€æ‰‹å‹ã€ä½¿ç”¨åœºæ™¯ã€é¢„ç®—æ®µ
   - ç¤ºä¾‹ï¼š
     * Bad: "é€‚åˆè¿½æ±‚æ€§èƒ½çš„æ¸¸æˆç©å®¶"
     * Good: "ç›´æ¥å¯¹æ ‡é›·è›‡æ¯’è°V3ï¼Œä½†ä»·æ ¼ä»…ä¸ºä¸€åŠï¼Œé€‚åˆé¢„ç®—ä¸è¶³ä½†æƒ³è¦æ¨¡å…·å¹³æ›¿çš„æŠ“æ¡ç©å®¶"
     * Good: "é€‚åˆå°æ‰‹æŠ“æ¡/æŒ‡æ¡ç©å®¶ï¼Œé‡é‡æ§åˆ¶åœ¨50gä»¥å†…ï¼Œé•¿æ—¶é—´FPSæ¸¸æˆä¸ç´¯"

3. **æ ¸å¿ƒå–ç‚¹ï¼ˆæ˜ç¡®å·®å¼‚åŒ–ï¼‰**ï¼š
   - ä¸è¦åªç½—åˆ—å‚æ•°ï¼Œè¦è¯´æ˜"ä¸ºä»€ä¹ˆ"å€¼å¾—ä¹°
   - æ˜ç¡®ä¸ç«å“çš„å·®å¼‚åŒ–ä¼˜åŠ¿
   - ç¤ºä¾‹ï¼š
     * Bad: "å–ç‚¹æ˜¯è½»é‡åŒ–å’Œé«˜æ€§èƒ½"
     * Good: "åŒä»·ä½å”¯ä¸€æ­è½½PAW3950çš„é¼ æ ‡ï¼Œæ¯”ç«å“VGNèœ»èœ“è½»10gï¼Œä½†ç»­èˆªæå‡40%"

4. **åˆ›æ–°æ ‡ç­¾è¯†åˆ«**ï¼š
   ä»ä»¥ä¸‹æ ‡ç­¾ä¸­é€‰æ‹©é€‚ç”¨çš„ï¼ˆä¹Ÿå¯è‡ªå®šä¹‰ï¼‰ï¼š
   - #å·ç‹ä»·æ ¼ï¼ˆåŒè§„æ ¼æœ€ä½ä»·ï¼‰
   - #é¦–å‘æ–°æŠ€æœ¯ï¼ˆé¦–æ¬¡æ­è½½æ–°ä¼ æ„Ÿå™¨/æ–°è½´ä½“ï¼‰
   - #IPè”åï¼ˆä¸åŠ¨æ¼«/æ¸¸æˆè”åï¼‰
   - #ç‰¹æ®Šé…åˆ—ï¼ˆå¦‚98é…åˆ—ã€65%é…åˆ—ï¼‰
   - #è¶…è½»é‡åŒ–ï¼ˆ<50gé¼ æ ‡ï¼‰
   - #é•¿ç»­èˆªï¼ˆ>100å°æ—¶ï¼‰
   - #æ——èˆ°åšå·¥ï¼ˆé‡‘å±æè´¨ã€ç²¾ç»†CNCï¼‰

5. **ç¼ºç‚¹æ‰¹åˆ¤ï¼ˆå¿…é¡»çŠ€åˆ©ï¼‰**ï¼š
   - å¿…é¡»æŒ‡å‡ºè‡³å°‘1-3ä¸ªç¼ºç‚¹
   - å¸¸è§ç¼ºç‚¹ï¼š
     * ç”µæ± å®¹é‡å°ï¼ˆå¦‚300mAhï¼‰â†’ "ç»­èˆªå¯èƒ½å°¿å´©ï¼Œé‡åº¦ç©å®¶éœ€æ¯æ—¥å……ç”µ"
     * ä»·æ ¼é«˜äºç«å“ â†’ "æº¢ä»·è¿‡é«˜ç¼ºä¹è¯šæ„ï¼ŒåŒé…ç½®ç«å“ä¾¿å®œ100å…ƒ"
     * åšå·¥ä¸€èˆ¬ â†’ "å¡‘æ–™æ„Ÿå¼ºï¼Œè´¨æ„Ÿå»‰ä»·ï¼Œä¸å¦‚ä¸Šä»£äº§å“"
     * åŠŸèƒ½ç¼ºå¤± â†’ "ç¼ºå°‘8Kå›æŠ¥ç‡ï¼Œå®ç”¨æ€§æ‰“æŠ˜"
     * MCUæœªçŸ¥ â†’ "ä¸»æ§æ–¹æ¡ˆå­˜ç–‘ï¼Œéœ€å…³æ³¨å®æµ‹ç¨³å®šæ€§"

6. **è´­ä¹°å»ºè®®ï¼ˆPM Summaryï¼‰**ï¼š
   - 30å­—ä»¥å†…ï¼Œç›´ç™½çŠ€åˆ©
   - å¿…é¡»ç»™å‡ºæ˜ç¡®çš„è´­ä¹°å»ºè®®ï¼šå€¼å¾—ä¹°/è§‚æœ›/ä¸æ¨è
   - ç»“åˆç«å“ç»™å‡ºå…·ä½“ç†ç”±
   - ç¤ºä¾‹ï¼š
     * "299å…ƒä¹°Hero 25K+58gè½»é‡åŒ–ï¼Œé—­çœ¼å…¥"
     * "ç­‰é™ä»·ï¼ŒåŒä»·ä½VGNèœ»èœ“é…ç½®æ›´é«˜"

7. **å‚æ•°æå–**ï¼š
   - å°½å¯èƒ½å¤šåœ°æå–æ‰€æœ‰å‚æ•°ï¼Œä¸è¦ç•™ç©º
   - å°ºå¯¸æ ¼å¼ï¼šé•¿xå®½xé«˜ï¼ˆå¦‚ï¼š120x65x40mmï¼‰
   - ä»·æ ¼æ ¼å¼ï¼šæ•°å­—+å•ä½ï¼ˆå¦‚ï¼š299å…ƒï¼‰
   - ç‰¹æ®ŠåŠŸèƒ½å¤šä¸ªç”¨é¡¿å·åˆ†éš”
"""

        result = self._call_llm(prompt)
        extracted_data = self._parse_json_response(result)

        # [DEBUG] æ‰“å°åŸå§‹å“åº”å’Œæ•°æ®æµ
        print(f"      [DEBUG-LLM] åŸå§‹å“åº”é•¿åº¦: {len(result)} å­—ç¬¦")
        print(f"      [DEBUG-LLM] è§£æåçš„é¡¶çº§å­—æ®µ: {list(extracted_data.keys())}")
        if 'specs' in extracted_data:
            print(f"      [DEBUG-LLM] specså­å­—æ®µ: {list(extracted_data['specs'].keys())}")
            print(f"      [DEBUG-LLM] specséç©ºå­—æ®µ: {[k for k,v in extracted_data['specs'].items() if v and v.strip()]}")

        # ç¡®ä¿ main_image å­—æ®µå­˜åœ¨
        if 'main_image' not in extracted_data or not extracted_data['main_image']:
            extracted_data['main_image'] = main_image

        # ä»·æ ¼å›é€€æœºåˆ¶ï¼šå¦‚æœLLMæœªæå–åˆ°ä»·æ ¼ï¼Œä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–
        if not extracted_data.get('release_price') or extracted_data['release_price'] == 'ä»·æ ¼æœªå…¬å¼€':
            estimated_price = self.extract_price_from_content(context)
            if estimated_price:
                extracted_data['release_price'] = estimated_price
                print(f"      [ä»·æ ¼æå–] æ­£åˆ™æå–åˆ°é¢„ä¼°ä»·æ ¼: {estimated_price}")

        # ä»·æ ¼æ ‡å‡†åŒ–ï¼šå¤„ç†å¤–å¸è½¬æ¢å’Œæ ¼å¼ç»Ÿä¸€
        if extracted_data.get('release_price'):
            original_price = extracted_data['release_price']
            standardized_price = HTMLReportGenerator._standardize_price(original_price)
            if standardized_price != original_price:
                extracted_data['release_price'] = standardized_price
                print(f"      [ä»·æ ¼æ ‡å‡†åŒ–] {original_price} -> {standardized_price}")

        # ç¡®ä¿ innovation_tags å­—æ®µå­˜åœ¨ï¼ˆå¦‚æœLLMæœªè¿”å›ï¼‰
        if 'innovation_tags' not in extracted_data:
            extracted_data['innovation_tags'] = []

        # [FIX 7] innovation_tags å½’ä¸€åŒ–ï¼šå» #ã€å…¨åŠè§’ç»Ÿä¸€ã€å»é‡
        if extracted_data.get('innovation_tags'):
            normalized_tags = normalize_innovation_tags(extracted_data['innovation_tags'])
            if normalized_tags != extracted_data['innovation_tags']:
                print(f"      [æ ‡ç­¾å½’ä¸€åŒ–] {extracted_data['innovation_tags']} -> {normalized_tags}")
            extracted_data['innovation_tags'] = normalized_tags

        return extracted_data

    def _call_llm(self, prompt: str) -> str:
        """è°ƒç”¨ LLM APIï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰"""
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }

        data = {
            "model": self.config["model"],
            "messages": [
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä½èµ„æ·±çš„å¤–è®¾äº§å“ç»ç†ï¼Œæ“…é•¿ä»äº§å“æ–°é—»ç¨¿ä¸­æå–å…³é”®ä¿¡æ¯å¹¶è¿›è¡Œæ·±åº¦å¸‚åœºåˆ†æã€ç«å“å¯¹æ¯”ã€ä¼˜ç¼ºç‚¹è¯„ä¼°ã€‚"
                },
                {"role": "user", "content": prompt}
            ],
            "temperature": 0.3,
            "max_tokens": 3000,
            "stream": False
        }

        # æ„å»ºå®Œæ•´çš„ API URL
        base_url = self.config["base_url"].rstrip('/')
        url = f"{base_url}/v1/chat/completions"

        # é‡è¯•æœºåˆ¶ï¼šæœ€å¤šé‡è¯•3æ¬¡ï¼Œä½¿ç”¨æŒ‡æ•°é€€é¿
        max_retries = 3
        base_delay = 2  # åˆå§‹å»¶è¿Ÿ2ç§’

        for attempt in range(max_retries):
            try:
                response = requests.post(url, headers=headers, json=data, timeout=120)
                response.raise_for_status()
                result = response.json()
                return result["choices"][0]["message"]["content"]

            except requests.exceptions.HTTPError as e:
                # 429 Too Many Requests æˆ– 5xx æœåŠ¡å™¨é”™è¯¯
                if e.response.status_code == 429 or e.response.status_code >= 500:
                    if attempt < max_retries - 1:
                        delay = base_delay * (2 ** attempt)  # æŒ‡æ•°é€€é¿: 2s, 4s, 8s
                        print(f"      [APIé”™è¯¯] {e.response.status_code}ï¼Œ{delay}ç§’åé‡è¯• ({attempt + 1}/{max_retries})...")
                        time.sleep(delay)
                        continue
                    else:
                        raise Exception(f"APIè°ƒç”¨å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°: {e}")
                else:
                    # å…¶ä»–HTTPé”™è¯¯ä¸é‡è¯•
                    raise Exception(f"APIè°ƒç”¨å¤±è´¥: {e}")

            except (requests.exceptions.Timeout, requests.exceptions.ConnectionError) as e:
                # è¶…æ—¶æˆ–è¿æ¥é”™è¯¯
                if attempt < max_retries - 1:
                    delay = base_delay * (2 ** attempt)
                    print(f"      [ç½‘ç»œé”™è¯¯] {type(e).__name__}ï¼Œ{delay}ç§’åé‡è¯• ({attempt + 1}/{max_retries})...")
                    time.sleep(delay)
                    continue
                else:
                    raise Exception(f"ç½‘ç»œè¿æ¥å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°: {e}")

            except Exception as e:
                # å…¶ä»–å¼‚å¸¸ä¸é‡è¯•
                raise Exception(f"æœªçŸ¥é”™è¯¯: {e}")

    @staticmethod
    def _parse_json_response(response: str) -> Dict:
        """è§£æ JSON å“åº”"""
        # å°è¯•ç›´æ¥è§£æ
        try:
            return json.loads(response)
        except:
            pass

        # å°è¯•æå– JSON ä»£ç å—
        json_match = re.search(r'```json\s*(.*?)\s*```', response, re.DOTALL)
        if json_match:
            try:
                return json.loads(json_match.group(1))
            except:
                pass

        # å°è¯•æå–å¤§æ‹¬å·å†…å®¹
        json_match = re.search(r'\{.*\}', response, re.DOTALL)
        if json_match:
            try:
                return json.loads(json_match.group(0))
            except:
                pass

        raise ValueError("æ— æ³•è§£æ LLM è¿”å›çš„ JSON")


# ==================== äº§å“åˆå¹¶å·¥å…· ====================

class ProductMerger:
    """äº§å“çº§åˆ«å»é‡ä¸åˆå¹¶å·¥å…·"""

    @staticmethod
    def normalize_product_name(name: str) -> str:
        """æ ‡å‡†åŒ–äº§å“åç§°ï¼Œç”¨äºå»é‡æ¯”è¾ƒï¼ˆæ”¹è¿›ç‰ˆï¼‰"""
        if not isinstance(name, str):
            return ""

        # ç§»é™¤æ‰€æœ‰ç©ºæ ¼ï¼ˆå¤„ç† "G304 X" vs "G304X"ï¼‰
        normalized = re.sub(r'\s+', '', name)
        # ç»Ÿä¸€å¤§å°å†™
        normalized = normalized.lower()
        # ç§»é™¤å¸¸è§å“ç‰Œåç¼€
        normalized = re.sub(r'(lightspeed|wireless|gaming|rgb|pro|ultra|max|heroc|ç‰ˆ|æ— çº¿|æœ‰çº¿)', '', normalized)
        # ç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼ˆä¿ç•™å­—æ¯ã€æ•°å­—ã€ä¸­æ–‡ï¼‰
        normalized = re.sub(r'[^a-z0-9\u4e00-\u9fff]', '', normalized)
        return normalized

    @staticmethod
    def calculate_similarity(name1: str, name2: str) -> float:
        """è®¡ç®—ä¸¤ä¸ªäº§å“åç§°çš„ç›¸ä¼¼åº¦"""
        norm1 = ProductMerger.normalize_product_name(name1)
        norm2 = ProductMerger.normalize_product_name(name2)

        if not norm1 or not norm2:
            return 0.0

        return SequenceMatcher(None, norm1, norm2).ratio()

    @classmethod
    def merge_products(cls, products: List[Dict]) -> List[Dict]:
        """åˆå¹¶é‡å¤çš„äº§å“"""
        if not products:
            return []

        # æŒ‰ç±»åˆ«åˆ†ç»„
        by_category = {}
        for p in products:
            cat = p.get('category', 'å…¶ä»–')
            if cat not in by_category:
                by_category[cat] = []
            by_category[cat].append(p)

        merged = []

        for category, cat_products in by_category.items():
            # å¯¹æ¯ä¸ªç±»åˆ«è¿›è¡Œåˆå¹¶
            merged.extend(cls._merge_category_products(cat_products))

        return merged

    @classmethod
    def _merge_category_products(cls, products: List[Dict]) -> List[Dict]:
        """åˆå¹¶åŒä¸€ç±»åˆ«çš„äº§å“"""
        if len(products) <= 1:
            return products

        merged = []
        used_indices = set()

        for i, product1 in enumerate(products):
            if i in used_indices:
                continue

            # å½“å‰äº§å“ä½œä¸ºåŸºç¡€
            base_product = product1.copy()
            matching_indices = [i]

            # æŸ¥æ‰¾ç›¸ä¼¼äº§å“
            for j, product2 in enumerate(products):
                if j <= i or j in used_indices:
                    continue

                similarity = cls.calculate_similarity(
                    base_product.get('product_name', ''),
                    product2.get('product_name', '')
                )

                # ç›¸ä¼¼åº¦é˜ˆå€¼ 0.7ï¼ˆè¾ƒé«˜çš„é˜ˆå€¼ç¡®ä¿æ˜¯åŒä¸€äº§å“ï¼‰
                if similarity >= 0.7:
                    matching_indices.append(j)

            # åˆå¹¶æ‰€æœ‰åŒ¹é…çš„äº§å“
            for idx in matching_indices:
                if idx != i:
                    base_product = cls._merge_two_products(base_product, products[idx])
                used_indices.add(idx)

            merged.append(base_product)

        return merged

    @staticmethod
    def _merge_two_products(base: Dict, other: Dict) -> Dict:
        """åˆå¹¶ä¸¤ä¸ªäº§å“æ•°æ®"""
        # åˆå¹¶ _raw ä¸­çš„è®°å½•
        base_raw = base.get('_raw', {})
        other_raw = other.get('_raw', {})

        merged_raw = {
            'product_name': base_raw.get('product_name', base.get('product_name', '')),
            'records': [],
            'images': [],
            'sources': [],
            'combined_content': ''
        }

        # åˆå¹¶ records
        base_records = base_raw.get('records', [])
        other_records = other_raw.get('records', [])

        all_records = base_records + other_records

        # å»é‡ recordsï¼ˆæŒ‰ URLï¼‰
        seen_urls = set()
        unique_records = []
        for record in all_records:
            url = record.get('url', '')
            if url and url not in seen_urls:
                seen_urls.add(url)
                unique_records.append(record)

        merged_raw['records'] = unique_records

        # åˆå¹¶å›¾ç‰‡
        base_images = base_raw.get('images', [])
        other_images = other_raw.get('images', [])
        all_images = list(set(base_images + other_images))
        merged_raw['images'] = all_images

        # åˆå¹¶æ¥æº
        base_sources = base_raw.get('sources', [])
        other_sources = other_raw.get('sources', [])
        all_sources = list(set(base_sources + other_sources))
        merged_raw['sources'] = all_sources

        # æ›´æ–° base äº§å“
        base['_raw'] = merged_raw

        # ä¼˜å…ˆä½¿ç”¨æœ‰ specs çš„äº§å“
        if other.get('specs') and any(other.get('specs', {}).values()):
            base['specs'] = other.get('specs', {})

        # åˆå¹¶ä»·æ ¼ï¼ˆä¼˜å…ˆä½¿ç”¨æœ‰ä»·æ ¼çš„ï¼‰
        if other.get('release_price') and other['release_price'] != 'ä»·æ ¼æœªå…¬å¼€':
            if not base.get('release_price') or base['release_price'] == 'ä»·æ ¼æœªå…¬å¼€':
                base['release_price'] = other['release_price']

        # ä¼˜å…ˆä½¿ç”¨æœ‰å›¾ç‰‡çš„
        if other.get('main_image') and not base.get('main_image'):
            base['main_image'] = other['main_image']

        # åˆå¹¶ analysisï¼ˆä¼˜å…ˆä½¿ç”¨æœ‰å†…å®¹çš„ï¼‰
        base_analysis = base.get('analysis', {})
        other_analysis = other.get('analysis', {})

        if other_analysis and any(other_analysis.values()):
            # å¦‚æœ base åˆ†æä¸ºç©ºï¼Œä½¿ç”¨ other çš„
            if not any(base_analysis.values()):
                base['analysis'] = other_analysis

        return base


# ==================== å¸‚åœºè¶‹åŠ¿åˆ†æå™¨ ====================

class MarketAnalyzer:
    """å¸‚åœºè¶‹åŠ¿åˆ†æå™¨ - ä¸ºPMæä¾›å®è§‚å†³ç­–è¾…åŠ©"""

    def __init__(self, products: List[Dict]):
        self.products = products
        self.mice = [p for p in products if p.get('category') == 'é¼ æ ‡']
        self.keyboards = [p for p in products if p.get('category') == 'é”®ç›˜']

    def analyze_tech_trends(self) -> str:
        """åˆ†ææŠ€æœ¯è¶‹åŠ¿"""
        trends = []

        # 1. åˆ†æé¼ æ ‡ä¼ æ„Ÿå™¨è¶‹åŠ¿
        if self.mice:
            sensor_count = {}
            for mouse in self.mice:
                sensor = mouse.get('specs', {}).get('sensor', '')
                if '3395' in sensor:
                    sensor_count['PAW3395'] = sensor_count.get('PAW3395', 0) + 1
                elif '3950' in sensor:
                    sensor_count['PAW3950'] = sensor_count.get('PAW3950', 0) + 1
                elif 'Hero' in sensor:
                    sensor_count['Heroç³»åˆ—'] = sensor_count.get('Heroç³»åˆ—', 0) + 1

            if sensor_count:
                top_sensor = max(sensor_count, key=sensor_count.get)
                count = sensor_count[top_sensor]
                pct = count * 100 // len(self.mice)
                trends.append(f"ğŸ–±ï¸ é¼ æ ‡å¸‚åœºï¼š{top_sensor}ä¼ æ„Ÿå™¨å ä¸»å¯¼ï¼ˆ{count}æ¬¾ï¼Œ{pct}%ï¼‰ï¼Œ")

        # 2. åˆ†æé”®ç›˜è½´ä½“è¶‹åŠ¿
        if self.keyboards:
            switch_count = {'ç£è½´': 0, 'æœºæ¢°è½´': 0, 'é™ç”µå®¹': 0}
            for keyboard in self.keyboards:
                switch = keyboard.get('specs', {}).get('switch', '')
                if 'ç£è½´' in switch:
                    switch_count['ç£è½´'] += 1
                elif 'è½´' in switch:
                    switch_count['æœºæ¢°è½´'] += 1

            if any(switch_count.values()):
                top_switch = max(switch_count, key=switch_count.get)
                count = switch_count[top_switch]
                if count > 0:
                    pct = count * 100 // len(self.keyboards)
                    trends.append(f"âŒ¨ï¸ é”®ç›˜å¸‚åœºï¼š{top_switch}å‘ˆäº•å–·æ€åŠ¿ï¼ˆ{count}æ¬¾ï¼Œ{pct}%ï¼‰ï¼Œ")

        # 3. åˆ†æä»·æ ¼è¶‹åŠ¿
        price_ranges = {'0-199': 0, '200-499': 0, '500-999': 0, '1000+': 0}
        for product in self.products:
            price = product.get('specs', {}).get('price', '') or product.get('release_price', '')
            price_match = re.search(r'(\d+)', str(price))
            if price_match:
                price_num = int(price_match.group(1))
                if price_num < 200:
                    price_ranges['0-199'] += 1
                elif price_num < 500:
                    price_ranges['200-499'] += 1
                elif price_num < 1000:
                    price_ranges['500-999'] += 1
                else:
                    price_ranges['1000+'] += 1

        top_range = max(price_ranges, key=price_ranges.get)
        if price_ranges[top_range] > 0:
            trends.append(f"ğŸ’° ä»·æ ¼æ®µï¼š{top_range}å…ƒåŒºé—´ç«äº‰æœ€æ¿€çƒˆï¼ˆ{price_ranges[top_range]}æ¬¾ï¼‰ï¼Œ")

        # 4. åˆ†æåˆ›æ–°æ ‡ç­¾è¶‹åŠ¿
        innovation_tags = {}
        for product in self.products:
            for tag in product.get('innovation_tags', []):
                innovation_tags[tag] = innovation_tags.get(tag, 0) + 1

        if innovation_tags:
            top_tag = max(innovation_tags, key=innovation_tags.get)
            count = innovation_tags[top_tag]
            trends.append(f"ğŸ·ï¸ åˆ›æ–°æ ‡ç­¾ï¼š{top_tag}æœ€ä¸ºæµè¡Œï¼ˆ{count}æ¬¾ï¼‰ã€‚")

        return ' '.join(trends) if trends else "æœ¬æœˆæ–°å“æ•°é‡è¾ƒå°‘ï¼Œæš‚æ— æ˜æ˜¾è¶‹åŠ¿ã€‚"

    def analyze_pricing_insights(self) -> str:
        """åˆ†æä»·æ ¼è¡Œæƒ…"""
        insights = []

        # è®¡ç®—é¼ æ ‡å¹³å‡ä»·æ ¼
        mouse_prices = []
        for mouse in self.mice:
            price = mouse.get('specs', {}).get('price', '') or mouse.get('release_price', '')
            price_match = re.search(r'(\d+)', str(price))
            if price_match:
                mouse_prices.append(int(price_match.group(1)))

        # è®¡ç®—é”®ç›˜å¹³å‡ä»·æ ¼
        keyboard_prices = []
        for keyboard in self.keyboards:
            price = keyboard.get('specs', {}).get('price', '') or keyboard.get('release_price', '')
            price_match = re.search(r'(\d+)', str(price))
            if price_match:
                keyboard_prices.append(int(price_match.group(1)))

        if mouse_prices:
            avg_mouse = sum(mouse_prices) // len(mouse_prices)
            insights.append(f"é¼ æ ‡å¸‚åœºå‡ä»·çº¦{avg_mouse}å…ƒ")

            # æ£€æŸ¥ä»·æ ¼ä¸¤æåˆ†åŒ–
            if min(mouse_prices) < avg_mouse * 0.3 and max(mouse_prices) > avg_mouse * 2:
                insights.append("å‘ˆç°ä¸¤æåˆ†åŒ–æ€åŠ¿ï¼ˆç™¾å…ƒçº§å·é…ç½®ä¸åƒå…ƒçº§å·IPå¹¶å­˜ï¼‰")
            else:
                insights.append("ä»·æ ¼åˆ†å¸ƒç›¸å¯¹å‡è¡¡")

        if keyboard_prices:
            avg_keyboard = sum(keyboard_prices) // len(keyboard_prices)
            insights.append(f"é”®ç›˜å¸‚åœºå‡ä»·çº¦{avg_keyboard}å…ƒ")

            # æ£€æŸ¥ä»·æ ¼è¶‹åŠ¿
            magnetic_keyboards = [k for k in self.keyboards if 'ç£è½´' in k.get('specs', {}).get('switch', '')]
            if magnetic_keyboards:
                mag_prices = []
                for k in magnetic_keyboards:
                    price = k.get('specs', {}).get('price', '') or k.get('release_price', '')
                    price_match = re.search(r'(\d+)', str(price))
                    if price_match:
                        mag_prices.append(int(price_match.group(1)))
                if mag_prices and min(mag_prices) < 400:
                    insights.append("ç£è½´é”®ç›˜ä»·æ ¼å·²ä¸‹æ¢è‡³300å…ƒåŒºé—´ï¼Œå·ç‹ä¹‹æˆ˜åŠ å‰§")

        # Trim å¹¶ç¡®ä¿å¥å­å®Œæ•´
        result = ' '.join(insights) if insights else "æš‚æ— è¶³å¤Ÿä»·æ ¼æ•°æ®"
        return result.strip() + ('ã€‚' if not result.endswith(('ã€‚', 'ï¼', 'ï¼Ÿ')) else '')

    def generate_pm_takeaways(self) -> str:
        """ç”ŸæˆPMæˆ˜ç•¥å¯ç¤º"""
        takeaways = []

        # ä¼ æ„Ÿå™¨å¯ç¤º
        sensor_3395_count = sum(1 for m in self.mice if '3395' in m.get('specs', {}).get('sensor_solution', ''))
        sensor_3950_count = sum(1 for m in self.mice if '3950' in m.get('specs', {}).get('sensor_solution', ''))

        if sensor_3395_count > 0:
            if sensor_3950_count > sensor_3395_count:
                takeaways.append("ğŸ¯ PAW3950ä¼ æ„Ÿå™¨æ­£åœ¨å¿«é€Ÿæ™®åŠï¼Œå»ºè®®æ–°å“ä¼˜å…ˆé‡‡ç”¨3950ä»¥ä¿æŒç«äº‰åŠ›")
            else:
                takeaways.append("ğŸ¯ PAW3395ä¼ æ„Ÿå™¨ä»æ˜¯ä¸»æµï¼Œä½†çº¢åˆ©æœŸå·²è¿‡ï¼Œéœ€å¯»æ‰¾æ–°å·®å¼‚ç‚¹ï¼ˆå¦‚æ¶‚å±‚ã€æ¨¡å…·ã€8Kå›æŠ¥ç‡ï¼‰")

        # ç£è½´é”®ç›˜å¯ç¤º
        magnetic_count = sum(1 for k in self.keyboards if 'ç£è½´' in k.get('specs', {}).get('switch_type', ''))
        if magnetic_count > len(self.keyboards) * 0.3:
            takeaways.append("ğŸ¯ ç£è½´é”®ç›˜å·²æˆä¸»æµï¼Œå»ºè®®è·Ÿè¿›ç£è½´äº§å“çº¿æˆ–å¯»æ‰¾å·®å¼‚åŒ–å®šä½")

        # ä»·æ ¼å®šä½å¯ç¤º
        budget_products = sum(1 for p in self.products if 'å·ç‹' in ' '.join(p.get('innovation_tags', [])))
        if budget_products > len(self.products) * 0.3:
            takeaways.append("ğŸ¯ æ€§ä»·æ¯”å¸‚åœºç«äº‰ç™½çƒ­åŒ–ï¼Œå»ºè®®è€ƒè™‘é«˜ç«¯åŒ–è·¯çº¿æˆ–ç»†åˆ†å¸‚åœºå®šä½")

        # æŠ€æœ¯ç‰¹æ€§å¯ç¤º
        high_polling_count = sum(1 for m in self.mice if '8k' in m.get('specs', {}).get('polling_rate', '').lower())
        if high_polling_count > len(self.mice) * 0.3:
            takeaways.append("ğŸ¯ 8Kå›æŠ¥ç‡é€æ¸æˆä¸ºæ ‡é…ï¼Œå»ºè®®åœ¨è¥é”€ä¸­å¼ºåŒ–'ä½å»¶è¿Ÿ'å–ç‚¹")

        if not takeaways:
            takeaways.append("ğŸ¯ å»ºè®®æŒç»­å…³æ³¨å¸‚åœºåŠ¨æ€ï¼Œç§¯ç´¯æ›´å¤šæ•°æ®åå†åˆ¶å®šæˆ˜ç•¥")

        # æ‹¼æ¥å¹¶ç¡®ä¿ç»“å°¾æœ‰æ ‡ç‚¹
        result = ' '.join(takeaways)
        return result + ('ã€‚' if not result.endswith(('ã€‚', 'ï¼', 'ï¼Ÿ')) else '')

    def get_chart_data(self) -> Dict:
        """è·å–å›¾è¡¨æ•°æ®"""
        # 1. å“ç±»å æ¯” - åŠ¨æ€ç”Ÿæˆï¼ŒåªåŒ…å«æ•°é‡>0çš„åˆ†ç±»
        # [FIX] ä½¿ç”¨ç»Ÿä¸€æ•°æ®æºï¼šç›´æ¥ä½¿ç”¨ self.mice/keyboards/others çš„é•¿åº¦
        category_labels = []
        category_data_list = []

        if len(self.mice) > 0:
            category_labels.append('é¼ æ ‡')
            category_data_list.append(len(self.mice))
        if len(self.keyboards) > 0:
            category_labels.append('é”®ç›˜')
            category_data_list.append(len(self.keyboards))
        if len(self.others) > 0:
            category_labels.append('å…¶ä»–')
            category_data_list.append(len(self.others))

        # æ–­è¨€éªŒè¯ï¼šç¡®ä¿æ•°æ®ä¸€è‡´
        assert sum(category_data_list) == len(self.products), \
            f"ç»Ÿè®¡å£å¾„ä¸ä¸€è‡´ï¼å›¾è¡¨æ•°æ®æ€»å’Œ({sum(category_data_list)}) != äº§å“æ€»æ•°({len(self.products)})"

        category_data = {
            'labels': category_labels,
            'data': category_data_list
        }

        # 2. ä¼ æ„Ÿå™¨åˆ†å¸ƒ - [FIX B] åˆ†æ¡¶é€»è¾‘é‡æ„ï¼Œæ˜ç¡®ç¼ºå¤±å€¼ taxonomy
        sensor_dist = {}
        print(f"\n[DEBUG-CHART] å¼€å§‹ç»Ÿè®¡ä¼ æ„Ÿå™¨åˆ†å¸ƒï¼Œå…± {len(self.mice)} ä¸ªé¼ æ ‡")

        # [FIX B.1] ç»Ÿä¸€ç¼ºå¤±å€¼ taxonomy + æ˜ç¡®åˆ†æ¡¶
        # ç¼ºå¤±å€¼ä¼˜å…ˆçº§ï¼šæœªå…¬å¼€ > æœªæåŠ > å¾…å®æµ‹ > é¢„ä¼°
        # åªæœ‰"æ˜ç¡®å‹å·"æ‰è®¡å…¥è¦†ç›–ç‡
        temp_sensor_dist = {
            'PAW3395': 0, 'PAW3950': 0, 'Heroç³»åˆ—': 0, 'PMW3335': 0, 'PAW3335': 0, 'å…¶ä»–æ˜ç¡®å‹å·': 0,
            'æœªå…¬å¼€': 0, 'æœªæåŠ': 0, 'å¾…å®æµ‹': 0, 'é¢„ä¼°': 0
        }

        for idx, mouse in enumerate(self.mice):
            sensor = mouse.get('specs', {}).get('sensor_solution', '')
            sensor_lower = sensor.lower() if sensor else ''

            # [DEBUG] æ‰“å°å‰3ä¸ªé¼ æ ‡çš„å­—æ®µè®¿é—®æƒ…å†µ
            if idx < 3:
                print(f"  [DEBUG-CHART] é¼ æ ‡{idx+1}: {mouse.get('product_name', 'Unknown')[:30]}")
                print(f"    - sensor_solutionå­—æ®µå€¼: '{sensor}'")

            # [FIX B.2] ç¼ºå¤±å€¼åˆ¤å®šï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰
            if not sensor or sensor.strip() == '':
                temp_sensor_dist['æœªæåŠ'] += 1
            elif any(marker in sensor_lower for marker in ['æœªå…¬å¼€', 'å‚å•†æœªå…¬å¼€', 'tbd', 'å¾…å…¬å¸ƒ']):
                temp_sensor_dist['æœªå…¬å¼€'] += 1
            elif any(marker in sensor_lower for marker in ['æœªæåŠ', 'åŸæ–‡æœªæåŠ', 'æœªæä¾›']):
                temp_sensor_dist['æœªæåŠ'] += 1
            elif any(marker in sensor_lower for marker in ['å¾…å®æµ‹', 'å¾…å®˜æ–¹å®æµ‹', 'å®æµ‹ä¸­']):
                temp_sensor_dist['å¾…å®æµ‹'] += 1
            elif any(marker in sensor_lower for marker in ['é¢„ä¼°', 'æ¨æ–­', 'æ¨æµ‹', 'å¯èƒ½']):
                temp_sensor_dist['é¢„ä¼°'] += 1
            # [FIX B.3] æ˜ç¡®å‹å·åˆ¤å®šï¼ˆåªç»Ÿè®¡å…·ä½“å‹å·ï¼‰
            elif '3395' in sensor:
                temp_sensor_dist['PAW3395'] += 1
            elif '3950' in sensor:
                temp_sensor_dist['PAW3950'] += 1
            elif 'hero' in sensor_lower and any(kw in sensor_lower for kw in ['25k', '26k', '27k', 'hero']):
                temp_sensor_dist['Heroç³»åˆ—'] += 1
            elif any(model in sensor for model in ['PMW3335', 'PAW3335', '3389', '3392']):
                if 'PMW3335' in sensor or '3335' in sensor:
                    temp_sensor_dist['PMW3335'] += 1
                elif 'PAW3335' in sensor:
                    temp_sensor_dist['PAW3335'] += 1
                else:
                    temp_sensor_dist['å…¶ä»–æ˜ç¡®å‹å·'] += 1
            elif any(marker in sensor_lower for marker in ['å…‰å­¦', 'æ¿€å…‰', 'è“ç‰™', 'æ— çº¿', 'æœ‰çº¿']):
                # é€šç”¨ä¼ æ„Ÿå™¨ç±»å‹ï¼Œä¹Ÿç®—"æ˜ç¡®å‹å·"
                temp_sensor_dist['å…¶ä»–æ˜ç¡®å‹å·'] += 1
            else:
                # æ— æ³•å½’ç±»çš„æè¿°æ€§å†…å®¹
                temp_sensor_dist['æœªæåŠ'] += 1

        # åªä¿ç•™æ•°é‡>0çš„æ¡¶
        for key, value in temp_sensor_dist.items():
            if value > 0:
                sensor_dist[key] = value

        print(f"[DEBUG-CHART] ä¼ æ„Ÿå™¨åˆ†å¸ƒç»“æœ: {sensor_dist}")

        # 3. ä»·æ ¼åŒºé—´åˆ†å¸ƒ (ä¿®æ­£: ä½¿ç”¨ bucket_value() ç»Ÿä¸€å£å¾„)
        price_ranges = {'0-199å…ƒ': 0, '200-499å…ƒ': 0, '500-999å…ƒ': 0, '1000å…ƒ+': 0, 'æœªå…¬å¼€': 0, 'å¾…å®æµ‹': 0}
        print(f"\n[DEBUG-CHART] å¼€å§‹ç»Ÿè®¡ä»·æ ¼åŒºé—´åˆ†å¸ƒï¼Œå…± {len(self.products)} ä¸ªäº§å“")

        for idx, product in enumerate(self.products):
            # ä¼˜å…ˆä» specs.product_pricing è·å–ï¼Œç„¶åå°è¯• release_price
            price = (
                product.get('specs', {}).get('product_pricing', '') or
                product.get('release_price', '')
            )

            # [DEBUG] æ‰“å°å‰3ä¸ªäº§å“çš„å­—æ®µè®¿é—®æƒ…å†µ
            if idx < 3:
                print(f"  [DEBUG-CHART] äº§å“{idx+1}: {product.get('product_name', 'Unknown')[:30]}")
                print(f"    - product_pricing: '{product.get('specs', {}).get('product_pricing', '')}'")
                print(f"    - release_price: '{product.get('release_price', '')}'")
                print(f"    - æœ€ç»ˆä»·æ ¼å€¼: '{price}'")

            # [FIX 2.1] ä½¿ç”¨ bucket_value() è·å–åˆ†æ¡¶å€¼
            bucket_val = bucket_value(price)

            if bucket_val is None:
                # ç©ºå€¼/æœªæåŠ/æå–å¤±è´¥ â†’ ä¸è®¡å…¥å›¾è¡¨
                continue

            # æ£€æŸ¥æ˜¯å¦ä¸ºæ˜ç¡®çš„"æœªå…¬å¼€"æ ‡è®°
            if any(marker in bucket_val for marker in PRICE_UNDISCLOSED_MARKERS):
                price_ranges['æœªå…¬å¼€'] += 1
            elif 'å¾…å®æµ‹' in bucket_val or 'æ¦‚å¿µ' in bucket_val:
                price_ranges['å¾…å®æµ‹'] += 1
            else:
                # å°è¯•è§£ææ•°å­—è¿›è¡Œåˆ†æ¡¶
                price_match = re.search(r'(\d+)', str(bucket_val))
                if price_match:
                    price_num = int(price_match.group(1))
                    if price_num < 200:
                        price_ranges['0-199å…ƒ'] += 1
                    elif price_num < 500:
                        price_ranges['200-499å…ƒ'] += 1
                    elif price_num < 1000:
                        price_ranges['500-999å…ƒ'] += 1
                    else:
                        price_ranges['1000å…ƒ+'] += 1
                else:
                    # æ— æ³•è§£æä½†æœ‰å†…å®¹ â†’ å½’å…¥"æœªå…¬å¼€"
                    price_ranges['æœªå…¬å¼€'] += 1

        print(f"[DEBUG-CHART] ä»·æ ¼åŒºé—´åˆ†å¸ƒç»“æœ: {price_ranges}")

        # 4. è®¡ç®—è¦†ç›–ç‡ç»Ÿè®¡ - [FIX B.4] è¦†ç›–ç‡åªç»Ÿè®¡"æ˜ç¡®å‹å·"
        # å®šä¹‰è¾…åŠ©å‡½æ•°ï¼šåˆ¤æ–­ä¼ æ„Ÿå™¨æ˜¯å¦ä¸º"æ˜ç¡®å‹å·"
        def _is_explicit_sensor_model(sensor_value: str) -> bool:
            """åˆ¤æ–­ä¼ æ„Ÿå™¨å€¼æ˜¯å¦ä¸ºæ˜ç¡®å‹å·ï¼ˆç”¨äºè¦†ç›–ç‡è®¡ç®—ï¼‰"""
            if not sensor_value or not isinstance(sensor_value, str):
                return False
            sensor_lower = sensor_value.lower().strip()

            # æ’é™¤ç¼ºå¤±å€¼
            if any(marker in sensor_lower for marker in [
                'æœªå…¬å¼€', 'æœªæåŠ', 'å¾…å®æµ‹', 'é¢„ä¼°', 'æ¨æ–­', 'æ¨æµ‹', 'å¯èƒ½',
                'tbd', 'unknown', 'none', 'null'
            ]):
                return False

            # åˆ¤æ–­æ˜¯å¦åŒ…å«æ˜ç¡®å‹å·å…³é”®è¯æˆ–å‹å·
            explicit_keywords = [
                '3395', '3950', 'hero', 'pmw3335', 'paw3335', '3389', '3392',
                'å…‰å­¦', 'æ¿€å…‰', 'è“ç‰™', 'æ— çº¿', 'æœ‰çº¿', 'pixart', 'åŸç›¸'
            ]
            return any(kw in sensor_lower for kw in explicit_keywords)

        total_mice = len(self.mice)
        # [FIX B.4] ä¼ æ„Ÿå™¨è¦†ç›–ç‡åˆ†å­ï¼šåªç»Ÿè®¡"æ˜ç¡®å‹å·"
        sensor_known = sum(1 for m in self.mice if _is_explicit_sensor_model(m.get('specs', {}).get('sensor_solution', '')))
        sensor_coverage = sensor_known / total_mice if total_mice > 0 else 0

        total_products = len(self.products)
        # ä»·æ ¼è¦†ç›–ç‡ï¼šä½¿ç”¨ is_coverage_value() ç»Ÿè®¡æœ‰æ•ˆå€¼
        price_known = sum(1 for p in self.products if is_coverage_value(
            p.get('specs', {}).get('product_pricing', '') or p.get('release_price', '')
        ))
        price_coverage = price_known / total_products if total_products > 0 else 0

        coverage_stats = {
            'sensor': {
                'total': total_mice,
                'known': sensor_known,  # æ˜ç¡®å‹å·æ•°é‡
                'coverage': sensor_coverage
            },
            'price': {
                'total': total_products,
                'known': price_known,
                'coverage': price_coverage
            }
        }

        return {
            'category': category_data,
            'sensor': sensor_dist,
            'price_range': price_ranges,
            'coverage': coverage_stats
        }


# ==================== ä»»åŠ¡ä¸‰ï¼šæ·±è‰²æå®¢é£ HTML æŠ¥å‘Šç”Ÿæˆ ====================

class HTMLReportGenerator:
    """HTML æŠ¥å‘Šç”Ÿæˆå™¨ - æ·±è‰²æå®¢é£æ ¼ Phase 4 ä¼˜åŒ–ç‰ˆ"""

    def __init__(self, products: List[Dict]):
        # å…ˆåˆå¹¶é‡å¤äº§å“
        self.products = ProductMerger.merge_products(products)

        self.mice = [p for p in self.products if p.get('category') == 'é¼ æ ‡']
        self.keyboards = [p for p in self.products if p.get('category') == 'é”®ç›˜']
        self.others = [p for p in self.products if p.get('category') not in ['é¼ æ ‡', 'é”®ç›˜']]

        # åˆå§‹åŒ–å¸‚åœºåˆ†æå™¨
        self.market_analyzer = MarketAnalyzer(self.products)

        # æ‰“å°åˆå¹¶ç»Ÿè®¡
        original_count = len(products)
        merged_count = len(self.products)
        if original_count > merged_count:
            print(f"[OK] äº§å“åˆå¹¶: {original_count} -> {merged_count} (-{original_count - merged_count} é‡å¤)")

    def generate(self, output_path: Path):
        """ç”Ÿæˆ HTML æŠ¥å‘Š"""
        # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œå…ˆå¤‡ä»½
        if output_path.exists():
            backup_path = output_path.with_suffix('.html.bak')
            import shutil
            shutil.copy2(output_path, backup_path)
            print(f"[BACKUP] å·²å¤‡ä»½æ—§æ–‡ä»¶: {backup_path}")

        # ç”Ÿæˆ HTML
        html = self._build_html()

        # ä½¿ç”¨è¦†ç›–æ¨¡å¼å†™å…¥ï¼ˆ'w'ï¼‰
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(html)

        # è·å–ç»å¯¹è·¯å¾„å’Œç”Ÿæˆæ—¶é—´
        from datetime import datetime
        abs_path = output_path.resolve()
        gen_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

        print(f"\n{'='*60}")
        print(f"[OK] HTML æŠ¥å‘Šå·²ç”Ÿæˆ")
        print(f"  ç”Ÿæˆæ—¶é—´: {gen_time}")
        print(f"  æ–‡ä»¶è·¯å¾„: {abs_path}")
        print(f"  è¯·æ‰“å¼€è¯¥è·¯å¾„æ–‡ä»¶æŸ¥çœ‹æŠ¥å‘Šï¼ˆé¿å…æ‰“å¼€æ—§ç‰ˆæœ¬ï¼‰")
        print(f"{'='*60}\n")

        # æ•°æ®è´¨é‡è­¦å‘Š
        chart_data = self.market_analyzer.get_chart_data()
        coverage = chart_data['coverage']

        sensor_unknown_ratio = coverage['sensor']['coverage']
        price_unknown_ratio = coverage['price']['coverage']

        warnings = []
        if sensor_unknown_ratio == 0:
            warnings.append("âš ï¸  ä¼ æ„Ÿå™¨æ•°æ®è¦†ç›–ç‡ä¸º 0%ï¼Œæ‰€æœ‰é¼ æ ‡äº§å“çš„ä¼ æ„Ÿå™¨ä¿¡æ¯ç¼ºå¤±")
        elif (coverage['sensor']['total'] - coverage['sensor']['known']) / coverage['sensor']['total'] > 0.8:
            warnings.append(f"âš ï¸  ä¼ æ„Ÿå™¨æ•°æ®è´¨é‡å·®ï¼šæœªçŸ¥å æ¯” >80% ({coverage['sensor']['known']}/{coverage['sensor']['total']})")

        if price_unknown_ratio == 0:
            warnings.append("âš ï¸  ä»·æ ¼æ•°æ®è¦†ç›–ç‡ä¸º 0%ï¼Œæ‰€æœ‰äº§å“çš„ä»·æ ¼ä¿¡æ¯ç¼ºå¤±")
        elif (coverage['price']['total'] - coverage['price']['known']) / coverage['price']['total'] > 0.8:
            warnings.append(f"âš ï¸  ä»·æ ¼æ•°æ®è´¨é‡å·®ï¼šæœªå…¬å¼€å æ¯” >80% ({coverage['price']['known']}/{coverage['price']['total']})")

        if warnings:
            print("\n" + "="*60)
            print("[WARNING] æ•°æ®è´¨é‡è­¦å‘Š:")
            for warning in warnings:
                print(f"  {warning}")
            print("="*60)
            print("å»ºè®®ï¼šè¯·æ£€æŸ¥è¾“å…¥æ•°æ®è´¨é‡ï¼Œç¡®ä¿å…³é”®å­—æ®µï¼ˆsensor_solutionã€product_pricingï¼‰æ­£ç¡®æå–\n")

    def _build_html(self) -> str:
        """æ„å»ºå®Œæ•´çš„ HTML"""
        return f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{TARGET_YEAR}å¹´{TARGET_MONTH}æœˆå¤–è®¾æ–°å“ç›‘æ§æŠ¥å‘Š - PMæ·±åº¦åˆ†æç‰ˆ</title>
    <script src="assets/js/chart.umd.min.js" onerror="this.onerror=null; this.src='https://cdn.jsdelivr.net/npm/chart.js@4.4.0/dist/chart.umd.min.js'; console.warn('[WARNING] æœ¬åœ° Chart.js æœªæ‰¾åˆ°ï¼Œä½¿ç”¨ CDN ç‰ˆæœ¬ã€‚è¿è¡Œ scripts/download_assets.sh ä¸‹è½½æœ¬åœ°ç‰ˆæœ¬ä»¥æé«˜åŠ è½½é€Ÿåº¦ã€‚');"></script>
    <style>
        * {{
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }}

        body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
            color: #e0e0e0;
            padding: 20px;
            line-height: 1.6;
            min-height: 100vh;
        }}

        .container {{
            max-width: 1400px;
            margin: 0 auto;
            padding-bottom: 80px;
        }}

        /* å¯¼èˆªæ  */
        .nav-bar {{
            position: sticky;
            top: 0;
            background: rgba(26, 26, 46, 0.95);
            backdrop-filter: blur(10px);
            padding: 15px 20px;
            border-radius: 12px;
            margin-bottom: 30px;
            z-index: 100;
            display: flex;
            justify-content: space-between;
            align-items: center;
            flex-wrap: wrap;
            gap: 15px;
            border: 1px solid rgba(255, 255, 255, 0.1);
        }}

        .nav-buttons {{
            display: flex;
            gap: 10px;
            flex-wrap: wrap;
        }}

        .nav-btn {{
            padding: 10px 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border: none;
            border-radius: 8px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s;
            text-decoration: none;
        }}

        .nav-btn:hover {{
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(102, 126, 234, 0.4);
        }}

        /* æœç´¢æ¡† */
        .search-box {{
            position: relative;
            flex: 1;
            max-width: 400px;
        }}

        .search-input {{
            width: 100%;
            padding: 12px 45px 12px 20px;
            background: rgba(255, 255, 255, 0.1);
            border: 1px solid rgba(102, 126, 234, 0.3);
            border-radius: 25px;
            color: white;
            font-size: 0.95em;
            transition: all 0.3s;
        }}

        .search-input:focus {{
            outline: none;
            background: rgba(255, 255, 255, 0.15);
            border-color: #667eea;
            box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.2);
        }}

        .search-input::placeholder {{
            color: #a0aec0;
        }}

        .search-icon {{
            position: absolute;
            right: 15px;
            top: 50%;
            transform: translateY(-50%);
            color: #a0aec0;
            font-size: 1.2em;
        }}

        .header {{
            text-align: center;
            padding: 40px 20px;
            background: rgba(37, 47, 78, 0.6);
            border-radius: 16px;
            margin-bottom: 40px;
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255, 255, 255, 0.1);
        }}

        .header h1 {{
            font-size: 2.5em;
            margin-bottom: 10px;
            font-weight: 700;
            color: #ffffff;
            text-shadow: 0 2px 10px rgba(102, 126, 234, 0.5);
        }}

        .header .subtitle {{
            font-size: 1.2em;
            color: #a0aec0;
            font-weight: 300;
            margin-bottom: 20px;
        }}

        .stats {{
            display: flex;
            justify-content: center;
            gap: 30px;
            flex-wrap: wrap;
        }}

        .stat-item {{
            background: rgba(102, 126, 234, 0.2);
            padding: 20px 30px;
            border-radius: 12px;
            border: 1px solid rgba(102, 126, 234, 0.3);
            text-align: center;
        }}

        .stat-number {{
            font-size: 2.5em;
            font-weight: 700;
            color: #667eea;
        }}

        .stat-label {{
            font-size: 0.9em;
            color: #a0aec0;
            margin-top: 5px;
        }}

        /* Executive Summary Styles */
        .executive-summary {{
            background: linear-gradient(135deg, rgba(102, 126, 234, 0.15) 0%, rgba(118, 75, 162, 0.15) 100%);
            border-radius: 16px;
            padding: 30px;
            margin-bottom: 40px;
            border: 1px solid rgba(102, 126, 234, 0.3);
            box-shadow: 0 8px 32px rgba(102, 126, 234, 0.2);
        }}

        .summary-title {{
            font-size: 1.8em;
            font-weight: 700;
            color: #ffffff;
            margin-bottom: 25px;
            text-align: center;
            border-bottom: 2px solid rgba(102, 126, 234, 0.5);
            padding-bottom: 15px;
        }}

        .summary-grid {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 25px;
            margin-bottom: 30px;
        }}

        .summary-card {{
            background: rgba(0, 0, 0, 0.3);
            border-radius: 12px;
            padding: 20px;
            border: 1px solid rgba(255, 255, 255, 0.1);
            transition: all 0.3s;
        }}

        .summary-card:hover {{
            transform: translateY(-5px);
            box-shadow: 0 8px 24px rgba(102, 126, 234, 0.3);
            border-color: rgba(102, 126, 234, 0.5);
        }}

        .summary-card-header {{
            display: flex;
            align-items: center;
            gap: 10px;
            margin-bottom: 15px;
        }}

        .summary-card-icon {{
            font-size: 1.5em;
        }}

        .summary-card-title {{
            font-size: 1.2em;
            font-weight: 600;
            color: #667eea;
        }}

        .summary-card-content {{
            color: #e0e0e0;
            line-height: 1.6;
            font-size: 0.95em;
        }}

        /* Charts Section Styles */
        .charts-section {{
            background: rgba(37, 47, 78, 0.6);
            border-radius: 16px;
            padding: 30px;
            margin-bottom: 40px;
            border: 1px solid rgba(255, 255, 255, 0.1);
        }}

        .charts-grid {{
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(350px, 1fr));
            gap: 30px;
            margin-top: 25px;
        }}

        .chart-container {{
            background: rgba(0, 0, 0, 0.2);
            border-radius: 12px;
            padding: 20px;
            border: 1px solid rgba(255, 255, 255, 0.1);
        }}

        .chart-title {{
            font-size: 1.1em;
            font-weight: 600;
            color: #667eea;
            margin-bottom: 15px;
            text-align: center;
        }}

        .chart-canvas {{
            max-height: 250px;
        }}

        /* Key Specs Badge Styles */
        .key-specs {{
            display: flex;
            flex-wrap: wrap;
            gap: 8px;
            margin-top: 12px;
        }}

        .key-spec-badge {{
            display: inline-flex;
            align-items: center;
            gap: 5px;
            background: rgba(102, 126, 234, 0.2);
            border: 1px solid rgba(102, 126, 234, 0.4);
            border-radius: 6px;
            padding: 6px 12px;
            font-size: 0.85em;
            font-weight: 600;
            color: #ffffff;
        }}

        .key-spec-badge .spec-icon {{
            font-size: 1.1em;
        }}

        .key-spec-badge .spec-value {{
            color: #667eea;
        }}

        /* [FIX B.4] ç¼ºå¤±å€¼æ ·å¼ - åŒºåˆ†ä¸åŒçŠ¶æ€ */
        .key-spec-badge.spec-missing {{
            background: rgba(107, 114, 128, 0.2);
            border: 1px solid rgba(107, 114, 128, 0.4);
        }}
        .key-spec-badge.spec-missing .spec-value {{
            color: #9ca3af;
        }}

        .key-spec-badge.spec-undisclosed {{
            background: rgba(139, 92, 246, 0.2);
            border: 1px solid rgba(139, 92, 246, 0.4);
        }}
        .key-spec-badge.spec-undisclosed .spec-value {{
            color: #a78bfa;
        }}

        .key-spec-badge.spec-pending {{
            background: rgba(251, 191, 36, 0.2);
            border: 1px solid rgba(251, 191, 36, 0.4);
        }}
        .key-spec-badge.spec-pending .spec-value {{
            color: #fbbf24;
        }}

        .key-spec-badge.spec-estimated {{
            background: rgba(249, 115, 22, 0.2);
            border: 1px solid rgba(249, 115, 22, 0.4);
        }}
        .key-spec-badge.spec-estimated .spec-value {{
            color: #fb923c;
        }}

        /* [FIX E] äºŒæ¬¡è¡¥å…¨æ ·å¼ - åŒºåˆ†è¡¥å…¨/æ¨æ–­ */
        .key-spec-badge.spec-enriched {{
            background: rgba(16, 185, 129, 0.2);
            border: 1px solid rgba(16, 185, 129, 0.4);
            position: relative;
        }}
        .key-spec-badge.spec-enriched .spec-value {{
            color: #34d399;
        }}
        .key-spec-badge.spec-enriched::after {{
            content: 'âœ“è¡¥å…¨';
            font-size: 0.7em;
            margin-left: 6px;
            padding: 2px 6px;
            background: rgba(16, 185, 129, 0.3);
            border-radius: 3px;
            color: #34d399;
        }}

        .key-spec-badge.spec-inferred {{
            background: rgba(251, 146, 60, 0.2);
            border: 1px solid rgba(251, 146, 60, 0.4);
            position: relative;
        }}
        .key-spec-badge.spec-inferred .spec-value {{
            color: #fb923c;
        }}
        .key-spec-badge.spec-inferred::after {{
            content: 'æ¨æ–­';
            font-size: 0.7em;
            margin-left: 6px;
            padding: 2px 6px;
            background: rgba(251, 146, 60, 0.3);
            border-radius: 3px;
            color: #fb923c;
        }}

        /* è¯æ®ç‰‡æ®µ tooltip */
        .evidence-tooltip {{
            position: relative;
            cursor: help;
        }}
        .evidence-tooltip:hover::before {{
            content: attr(data-evidence);
            position: absolute;
            bottom: 100%;
            left: 50%;
            transform: translateX(-50%);
            background: rgba(30, 41, 59, 0.95);
            border: 1px solid rgba(102, 126, 234, 0.5);
            border-radius: 8px;
            padding: 10px 14px;
            font-size: 0.85em;
            color: #e0e0e0;
            white-space: pre-wrap;
            max-width: 350px;
            z-index: 1000;
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.5);
            margin-bottom: 8px;
        }}
        .evidence-tooltip:hover::after {{
            content: '';
            position: absolute;
            bottom: 100%;
            left: 50%;
            transform: translateX(-50%);
            border: 6px solid transparent;
            border-top-color: rgba(30, 41, 59, 0.95);
            border-bottom: none;
            margin-bottom: -4px;
        }}

        /* Price Status Badge */
        .price-status {{
            display: inline-block;
            padding: 4px 10px;
            border-radius: 4px;
            font-size: 0.75em;
            font-weight: 600;
            margin-left: 8px;
            vertical-align: middle;
        }}

        .price-status.missing {{
            background: rgba(107, 114, 128, 0.2);
            border: 1px solid rgba(107, 114, 128, 0.5);
            color: #9ca3af;
        }}

        .price-status.undisclosed {{
            background: rgba(139, 92, 246, 0.2);
            border: 1px solid rgba(139, 92, 246, 0.5);
            color: #a78bfa;
        }}

        .price-status.pending {{
            background: rgba(251, 191, 36, 0.2);
            border: 1px solid rgba(251, 191, 36, 0.5);
            color: #fbbf24;
        }}

        .price-status.estimated {{
            background: rgba(249, 115, 22, 0.2);
            border: 1px solid rgba(249, 115, 22, 0.5);
            color: #fb923c;
        }}

        .price-status.unknown {{
            background: rgba(107, 114, 128, 0.2);
            border: 1px solid rgba(107, 114, 128, 0.5);
            color: #9ca3af;
        }}

        .section {{
            margin-bottom: 50px;
        }}

        .section-title {{
            font-size: 2em;
            margin-bottom: 30px;
            color: #ffffff;
            border-left: 5px solid #667eea;
            padding-left: 15px;
            background: linear-gradient(90deg, rgba(102, 126, 234, 0.2) 0%, transparent 100%);
            padding: 15px;
            border-radius: 0 8px 8px 0;
        }}

        .products-grid {{
            display: grid;
            grid-template-columns: repeat(auto-fill, minmax(900px, 1fr));
            gap: 30px;
            max-width: 100%;
            overflow: hidden;
        }}

        .product-card {{
            background: #252f4e;
            border-radius: 16px;
            overflow: hidden;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.3);
            border: 1px solid rgba(255, 255, 255, 0.1);
            display: grid;
            grid-template-columns: 300px 1fr 1fr;
            transition: transform 0.3s, box-shadow 0.3s;
            position: relative;
        }}

        .product-card:hover {{
            transform: translateY(-5px);
            box-shadow: 0 12px 40px rgba(102, 126, 234, 0.3);
            border-color: rgba(102, 126, 234, 0.5);
        }}

        .product-card.hidden {{
            display: none;
        }}

        .no-results {{
            text-align: center;
            padding: 60px 20px;
            color: #718096;
            font-size: 1.2em;
        }}

        /* æ¥æº Badge */
        .source-badge {{
            position: absolute;
            top: 15px;
            right: 15px;
            padding: 6px 12px;
            border-radius: 20px;
            font-size: 0.75em;
            font-weight: 600;
            z-index: 10;
            text-transform: uppercase;
            letter-spacing: 0.5px;
        }}

        .source-badge.inwaishe {{
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            box-shadow: 0 2px 8px rgba(102, 126, 234, 0.4);
        }}

        .source-badge.wstx {{
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            color: white;
            box-shadow: 0 2px 8px rgba(245, 87, 108, 0.4);
        }}

        .source-badge.both {{
            background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);
            color: white;
            box-shadow: 0 2px 8px rgba(79, 172, 254, 0.4);
        }}

        /* äº§å“æ¦‚è§ˆåŒºå— */
        .product-overview {{
            padding: 25px;
            background: rgba(0, 0, 0, 0.2);
            border-right: 1px solid rgba(255, 255, 255, 0.1);
            position: relative;
        }}

        .product-image {{
            width: 100%;
            height: 200px;
            background: linear-gradient(135deg, rgba(102, 126, 234, 0.1) 0%, rgba(118, 75, 162, 0.1) 100%);
            border-radius: 12px;
            display: flex;
            align-items: center;
            justify-content: center;
            margin-bottom: 20px;
            overflow: hidden;
            position: relative;
            cursor: pointer;
        }}

        .product-image img {{
            max-width: 90%;
            max-height: 90%;
            object-fit: contain;
            transition: transform 0.3s;
        }}

        .product-image:hover img {{
            transform: scale(1.05);
        }}

        .product-name {{
            font-size: 1.2em;
            font-weight: 700;
            color: #ffffff;
            margin-bottom: 15px;
            line-height: 1.4;
        }}

        .product-price {{
            font-size: 2em;
            font-weight: 700;
            color: #e74c3c;
            margin-bottom: 10px;
        }}

        .product-date {{
            font-size: 0.85em;
            color: #a0aec0;
        }}

        /* ç¡¬æ ¸å‚æ•°åŒºå— */
        .product-specs {{
            padding: 25px;
            border-right: 1px solid rgba(255, 255, 255, 0.1);
        }}

        .block-title {{
            font-size: 1.1em;
            font-weight: 600;
            color: #667eea;
            margin-bottom: 15px;
            display: flex;
            align-items: center;
            gap: 8px;
        }}

        .block-title::before {{
            content: '';
            width: 4px;
            height: 18px;
            background: #667eea;
            border-radius: 2px;
        }}

        .specs-list {{
            display: flex;
            flex-direction: column;
            gap: 10px;
        }}

        .spec-item {{
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 8px 12px;
            background: rgba(0, 0, 0, 0.2);
            border-radius: 6px;
        }}

        .spec-label {{
            color: #a0aec0;
            font-size: 0.9em;
        }}

        .spec-value {{
            color: #ffffff;
            font-weight: 600;
            font-size: 0.95em;
        }}

        .no-specs {{
            color: #718096;
            font-style: italic;
            text-align: center;
            padding: 20px;
        }}

        /* PM æ´å¯ŸåŒºå— */
        .product-analysis {{
            padding: 25px;
            background: rgba(0, 0, 0, 0.1);
        }}

        /* è‡ªé€‚åº”å¸ƒå±€ï¼šæ²¡æœ‰å‚æ•°æ—¶ï¼ŒPM æ´å¯Ÿå æ»¡ */
        .product-card.no-specs {{
            grid-template-columns: 300px 1fr;
        }}

        .product-card.no-specs .product-overview {{
            border-right: 1px solid rgba(255, 255, 255, 0.1);
        }}

        .product-card.no-specs .product-analysis {{
            border-right: none;
        }}

        /* PM æ´å¯Ÿä¸ºç©ºæ—¶çš„ç¼ºçœçŠ¶æ€ */
        .empty-analysis {{
            text-align: center;
            padding: 40px 20px;
            color: #718096;
        }}

        .empty-analysis-icon {{
            font-size: 3em;
            margin-bottom: 15px;
            opacity: 0.5;
        }}

        .empty-analysis-text {{
            font-size: 0.95em;
        }}

        .analysis-section {{
            margin-bottom: 20px;
        }}

        .analysis-section:last-child {{
            margin-bottom: 0;
        }}

        .analysis-label {{
            font-size: 0.8em;
            color: #667eea;
            text-transform: uppercase;
            letter-spacing: 1px;
            margin-bottom: 8px;
            font-weight: 600;
        }}

        .analysis-text {{
            color: #e0e0e0;
            font-size: 0.95em;
            line-height: 1.5;
        }}

        .verdict-grid {{
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 15px;
            margin-top: 15px;
        }}

        .verdict-box {{
            padding: 15px;
            border-radius: 8px;
        }}

        .verdict-box.pros {{
            background: rgba(72, 187, 120, 0.15);
            border: 1px solid rgba(72, 187, 120, 0.3);
        }}

        .verdict-box.cons {{
            background: rgba(245, 101, 101, 0.15);
            border: 1px solid rgba(245, 101, 101, 0.3);
        }}

        .verdict-title {{
            font-size: 0.85em;
            font-weight: 600;
            margin-bottom: 10px;
            display: flex;
            align-items: center;
            gap: 6px;
        }}

        .verdict-title.pros {{
            color: #48bb78;
        }}

        .verdict-title.cons {{
            color: #f56565;
        }}

        .verdict-list {{
            list-style: none;
            padding: 0;
            margin: 0;
        }}

        .verdict-list li {{
            font-size: 0.9em;
            padding: 4px 0;
            padding-left: 20px;
            position: relative;
            color: #cbd5e0;
            margin-bottom: 6px;
        }}

        .verdict-list li:last-child {{
            margin-bottom: 0;
        }}

        .verdict-list.pros li::before {{
            content: 'âœ“';
            position: absolute;
            left: 0;
            color: #48bb78;
            font-weight: bold;
        }}

        .verdict-list.cons li::before {{
            content: 'âœ—';
            position: absolute;
            left: 0;
            color: #f56565;
            font-weight: bold;
        }}

        .pm-summary {{
            background: linear-gradient(135deg, rgba(102, 126, 234, 0.2) 0%, rgba(118, 75, 162, 0.2) 100%);
            border-left: 4px solid #667eea;
            padding: 15px;
            border-radius: 0 8px 8px 0;
            margin-top: 15px;
        }}

        .pm-summary-text {{
            color: #ffffff;
            font-size: 0.95em;
            font-style: italic;
            line-height: 1.6;
        }}

        .source-links {{
            margin-top: 20px;
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
        }}

        .source-link {{
            font-size: 0.8em;
            color: #667eea;
            text-decoration: none;
            padding: 6px 12px;
            border: 1px solid rgba(102, 126, 234, 0.5);
            border-radius: 4px;
            transition: all 0.3s;
        }}

        .source-link:hover {{
            background: rgba(102, 126, 234, 0.2);
            border-color: #667eea;
        }}

        .footer {{
            text-align: center;
            padding: 30px;
            color: #718096;
            font-size: 0.9em;
            border-top: 1px solid rgba(255, 255, 255, 0.1);
            margin-top: 50px;
        }}

        /* å›åˆ°é¡¶éƒ¨æŒ‰é’® */
        .back-to-top {{
            position: fixed;
            bottom: 30px;
            right: 30px;
            width: 50px;
            height: 50px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            cursor: pointer;
            opacity: 0;
            visibility: hidden;
            transition: all 0.3s;
            box-shadow: 0 4px 12px rgba(102, 126, 234, 0.4);
            z-index: 999;
            font-size: 1.5em;
            color: white;
        }}

        .back-to-top.visible {{
            opacity: 1;
            visibility: visible;
        }}

        .back-to-top:hover {{
            transform: translateY(-5px);
            box-shadow: 0 6px 20px rgba(102, 126, 234, 0.6);
        }}

        /* Lightbox å›¾ç‰‡é¢„è§ˆ */
        .lightbox {{
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0, 0, 0, 0.95);
            display: none;
            align-items: center;
            justify-content: center;
            z-index: 10000;
            cursor: zoom-out;
        }}

        .lightbox.active {{
            display: flex;
        }}

        .lightbox img {{
            max-width: 90%;
            max-height: 90%;
            object-fit: contain;
            border-radius: 8px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.5);
        }}

        .lightbox-close {{
            position: absolute;
            top: 30px;
            right: 30px;
            font-size: 2em;
            color: white;
            cursor: pointer;
            transition: transform 0.3s;
        }}

        .lightbox-close:hover {{
            transform: rotate(90deg);
        }}

        // [FIX] å“åº”å¼æ–­ç‚¹ï¼šæ·»åŠ æ›´å¤šç§»åŠ¨ç«¯é€‚é…
        @media (max-width: 1400px) {{
            .container {{
                max-width: 1200px;
                padding: 15px;
            }}
        }}

        @media (max-width: 1200px) {{
            .products-grid {{
                grid-template-columns: 1fr;
            }}

            .product-card {{
                grid-template-columns: 1fr;
            }}

            .product-overview {{
                border-right: none;
                border-bottom: 1px solid rgba(255, 255, 255, 0.1);
            }}

            .product-specs {{
                border-right: none;
                border-bottom: 1px solid rgba(255, 255, 255, 0.1);
            }}
        }}

        @media (max-width: 900px) {{
            .container {{
                max-width: 100%;
                padding: 10px;
            }}

            .header h1 {{
                font-size: 2em;
            }}

            .stats {{
                gap: 15px;
            }}

            .stat-item {{
                padding: 15px 20px;
                min-width: 120px;
            }}
        }}

        @media (max-width: 768px) {{
            .header h1 {{
                font-size: 1.8em;
            }}

            .stats {{
                flex-direction: column;
            }}

            .verdict-grid {{
                grid-template-columns: 1fr;
            }}

            .nav-bar {{
                flex-direction: column;
                align-items: stretch;
            }}

            .search-box {{
                max-width: none;
            }}
        }}

        @media (max-width: 600px) {{
            .header h1 {{
                font-size: 1.5em;
            }}

            .header .subtitle {{
                font-size: 1em;
            }}

            .section-title {{
                font-size: 1.3em;
            }}

            .charts-grid {{
                grid-template-columns: 1fr;
            }}
        }}

        @media (max-width: 480px) {{
            body {{
                padding: 10px;
            }}

            .header {{
                padding: 20px 10px;
            }}

            .nav-btn {{
                padding: 8px 15px;
                font-size: 0.9em;
            }}

            .product-card {{
                border-radius: 12px;
            }}
        }}
    </style>
</head>
<body>
    <div class="container">
        <!-- å¯¼èˆªæ  -->
        <div class="nav-bar">
            <div class="nav-buttons">
                <a href="#mice" class="nav-btn">ğŸ–±ï¸ é¼ æ ‡ ({len(self.mice)})</a>
                <a href="#keyboards" class="nav-btn">âŒ¨ï¸ é”®ç›˜ ({len(self.keyboards)})</a>
                <a href="#others" class="nav-btn">ğŸ“¦ å…¶ä»– ({len(self.others)})</a>
            </div>
            <div class="search-box">
                <input type="text" class="search-input" id="searchInput" placeholder="æœç´¢äº§å“åç§°æˆ–å“ç‰Œ...">
                <span class="search-icon">ğŸ”</span>
            </div>
        </div>

        <!-- å¤´éƒ¨ -->
        <div class="header">
            <h1>{TARGET_YEAR}å¹´{TARGET_MONTH}æœˆå¤–è®¾æ–°å“ç›‘æ§æŠ¥å‘Š</h1>
            <div class="subtitle">PM æ·±åº¦åˆ†æç‰ˆ | å¤–è®¾å¤©ä¸‹ Ã— inå¤–è®¾ æ–°å“æ±‡æ€»</div>
            <div class="stats">
                <div class="stat-item">
                    <div class="stat-number">{len(self.products)}</div>
                    <div class="stat-label">æ€»äº§å“æ•°</div>
                </div>
                <div class="stat-item">
                    <div class="stat-number">{len(self.mice)}</div>
                    <div class="stat-label">é¼ æ ‡æ–°å“</div>
                </div>
                <div class="stat-item">
                    <div class="stat-number">{len(self.keyboards)}</div>
                    <div class="stat-label">é”®ç›˜æ–°å“</div>
                </div>
            </div>
        </div>

        <!-- æœˆåº¦å¸‚åœºé£å‘æ ‡ -->
        {self._render_executive_summary()}

        <!-- å®è§‚æ•°æ®ä»ªè¡¨ç›˜ -->
        {self._render_charts()}

        <!-- é¼ æ ‡æ–°å“ -->
        {self._render_section('é¼ æ ‡', self.mice, 'mice')}

        <!-- é”®ç›˜æ–°å“ -->
        {self._render_section('é”®ç›˜', self.keyboards, 'keyboards')}

        <!-- å…¶ä»–äº§å“ -->
        {self._render_section('å…¶ä»–', self.others, 'others')}

        <!-- å°¾éƒ¨ -->
        <div class="footer">
            <p>æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
            <p>æ•°æ®æ¥æº: inå¤–è®¾ (inwaishe.com) & å¤–è®¾å¤©ä¸‹ (wstx.com) | PM æ·±åº¦åˆ†æç”± LLM ç”Ÿæˆ</p>
        </div>
    </div>

    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
    <div class="back-to-top" id="backToTop" title="å›åˆ°é¡¶éƒ¨">â†‘</div>

    <!-- Lightbox å›¾ç‰‡é¢„è§ˆ -->
    <div class="lightbox" id="lightbox">
        <span class="lightbox-close">Ã—</span>
        <img src="" alt="äº§å“å›¾ç‰‡é¢„è§ˆ" id="lightboxImg">
    </div>

    <script>
        // æœç´¢åŠŸèƒ½
        const searchInput = document.getElementById('searchInput');
        const productCards = document.querySelectorAll('.product-card');

        searchInput.addEventListener('input', function(e) {{
            const searchTerm = e.target.value.toLowerCase().trim();

            productCards.forEach(card => {{
                const productName = card.querySelector('.product-name')?.textContent.toLowerCase() || '';
                const productPrice = card.querySelector('.product-price')?.textContent.toLowerCase() || '';
                const productSource = card.querySelector('.source-badge')?.textContent.toLowerCase() || '';

                const matches = productName.includes(searchTerm) ||
                              productPrice.includes(searchTerm) ||
                              productSource.includes(searchTerm);

                if (matches || searchTerm === '') {{
                    card.classList.remove('hidden');
                }} else {{
                    card.classList.add('hidden');
                }}
            }});

            // æ£€æŸ¥æ˜¯å¦æœ‰å¯è§å¡ç‰‡
            const visibleCards = document.querySelectorAll('.product-card:not(.hidden)');
            const sections = document.querySelectorAll('.section');

            sections.forEach(section => {{
                const cardsInSection = section.querySelectorAll('.product-card:not(.hidden)');
                if (cardsInSection.length === 0) {{
                    section.style.display = 'none';
                }} else {{
                    section.style.display = 'block';
                }}
            }});
        }});

        // å›åˆ°é¡¶éƒ¨æŒ‰é’®
        const backToTop = document.getElementById('backToTop');

        window.addEventListener('scroll', function() {{
            if (window.pageYOffset > 300) {{
                backToTop.classList.add('visible');
            }} else {{
                backToTop.classList.remove('visible');
            }}
        }});

        backToTop.addEventListener('click', function() {{
            window.scrollTo({{
                top: 0,
                behavior: 'smooth'
            }});
        }});

        // Lightbox å›¾ç‰‡é¢„è§ˆ
        const lightbox = document.getElementById('lightbox');
        const lightboxImg = document.getElementById('lightboxImg');
        const productImages = document.querySelectorAll('.product-image img');

        productImages.forEach(img => {{
            img.addEventListener('click', function() {{
                const src = this.getAttribute('src');
                if (src && !src.includes('unsplash.com')) {{
                    lightboxImg.src = src;
                    lightbox.classList.add('active');
                }}
            }});
        }});

        lightbox.addEventListener('click', function() {{
            lightbox.classList.remove('active');
        }});

        // ESC å…³é—­ Lightbox
        document.addEventListener('keydown', function(e) {{
            if (e.key === 'Escape') {{
                lightbox.classList.remove('active');
            }}
        }});
    </script>
</body>
</html>"""

    def _render_executive_summary(self) -> str:
        """æ¸²æŸ“æœˆåº¦å¸‚åœºé£å‘æ ‡"""
        tech_trends = self.market_analyzer.analyze_tech_trends()
        pricing_insights = self.market_analyzer.analyze_pricing_insights()
        pm_takeaways = self.market_analyzer.generate_pm_takeaways()

        return f"""
        <div class="executive-summary">
            <h2 class="summary-title">ğŸ“Š æœˆåº¦å¸‚åœºé£å‘æ ‡</h2>
            <div class="summary-grid">
                <div class="summary-card">
                    <div class="summary-card-header">
                        <span class="summary-card-icon">ğŸ”¬</span>
                        <span class="summary-card-title">æŠ€æœ¯è¶‹åŠ¿</span>
                    </div>
                    <div class="summary-card-content">{tech_trends}</div>
                </div>
                <div class="summary-card">
                    <div class="summary-card-header">
                        <span class="summary-card-icon">ğŸ’°</span>
                        <span class="summary-card-title">ä»·æ ¼è¡Œæƒ…</span>
                    </div>
                    <div class="summary-card-content">{pricing_insights}</div>
                </div>
                <div class="summary-card">
                    <div class="summary-card-header">
                        <span class="summary-card-icon">ğŸ¯</span>
                        <span class="summary-card-title">PM å¯ç¤ºå½•</span>
                    </div>
                    <div class="summary-card-content">{pm_takeaways}</div>
                </div>
            </div>
        </div>"""

    def _render_charts(self) -> str:
        """æ¸²æŸ“å®è§‚æ•°æ®ä»ªè¡¨ç›˜"""
        chart_data = self.market_analyzer.get_chart_data()

        # Prepare chart data JSON
        import json
        category_labels = json.dumps(chart_data['category']['labels'])
        category_data = json.dumps(chart_data['category']['data'])

        sensor_labels = json.dumps(list(chart_data['sensor'].keys()))
        sensor_data = json.dumps(list(chart_data['sensor'].values()))

        price_labels = json.dumps(list(chart_data['price_range'].keys()))
        price_data = json.dumps(list(chart_data['price_range'].values()))

        # è·å–è¦†ç›–ç‡ç»Ÿè®¡
        sensor_coverage = chart_data['coverage']['sensor']
        price_coverage = chart_data['coverage']['price']

        sensor_title = f"é¼ æ ‡ä¼ æ„Ÿå™¨åˆ†å¸ƒ ({sensor_coverage['known']}/{sensor_coverage['total']})"
        # [FIX C.3] ä»·æ ¼æ ‡é¢˜å†™æ¸…æ¥šæ ·æœ¬é‡ï¼š"å·²å…¬å¼€ X/Y"
        price_title = f"ä»·æ ¼åŒºé—´åˆ†å¸ƒï¼ˆå·²å…¬å¼€ {price_coverage['known']}/{price_coverage['total']}ï¼‰"

        return f"""
        <div class="charts-section">
            <h2 class="section-title">ğŸ“ˆ å®è§‚æ•°æ®ä»ªè¡¨ç›˜</h2>
            <div class="charts-grid">
                <div class="chart-container">
                    <div class="chart-title">å“ç±»å æ¯”åˆ†å¸ƒ</div>
                    <canvas id="categoryChart" class="chart-canvas"></canvas>
                </div>
                <div class="chart-container">
                    <div class="chart-title">{sensor_title}</div>
                    <canvas id="sensorChart" class="chart-canvas"></canvas>
                </div>
                <div class="chart-container">
                    <div class="chart-title">{price_title}</div>
                    <canvas id="priceChart" class="chart-canvas"></canvas>
                </div>
            </div>
        </div>

        <script>
            // Chart.js global config
            Chart.defaults.color = '#a0aec0';
            Chart.defaults.borderColor = 'rgba(255, 255, 255, 0.1)';

            // Category Pie Chart
            new Chart(document.getElementById('categoryChart'), {{
                type: 'pie',
                data: {{
                    labels: {category_labels},
                    datasets: [{{
                        data: {category_data},
                        backgroundColor: [
                            'rgba(102, 126, 234, 0.8)',
                            'rgba(118, 75, 162, 0.8)',
                            'rgba(245, 101, 101, 0.8)'
                        ],
                        borderWidth: 2,
                        borderColor: 'rgba(0, 0, 0, 0.3)'
                    }}]
                }},
                options: {{
                    responsive: true,
                    maintainAspectRatio: true,
                    plugins: {{
                        legend: {{
                            position: 'bottom',
                            labels: {{
                                padding: 15,
                                font: {{ size: 12 }}
                            }}
                        }}
                    }}
                }}
            }});

            // Sensor Doughnut Chart
            const sensorLabels = {sensor_labels};
            // [FIX] åŠ¨æ€ç”Ÿæˆé¢œè‰²æ•°ç»„ï¼Œç¡®ä¿é•¿åº¦åŒ¹é…
            const sensorColors = sensorLabels.map((_, i) => {{
                const colors = [
                    'rgba(72, 187, 120, 0.8)',
                    'rgba(245, 158, 11, 0.8)',
                    'rgba(66, 153, 225, 0.8)',
                    'rgba(159, 122, 234, 0.8)',
                    'rgba(236, 72, 153, 0.8)',
                    'rgba(20, 184, 166, 0.8)',
                    'rgba(102, 126, 234, 0.8)',
                    'rgba(245, 101, 101, 0.8)',
                    'rgba(46, 213, 115, 0.8)',
                    'rgba(237, 137, 54, 0.8)'
                ];
                return colors[i % colors.length];
            }});

            new Chart(document.getElementById('sensorChart'), {{
                type: 'doughnut',
                data: {{
                    labels: {sensor_labels},
                    datasets: [{{
                        data: {sensor_data},
                        backgroundColor: sensorColors,
                        borderWidth: 2,
                        borderColor: 'rgba(0, 0, 0, 0.3)'
                    }}]
                }},
                options: {{
                    responsive: true,
                    maintainAspectRatio: true,
                    plugins: {{
                        legend: {{
                            position: 'bottom',
                            labels: {{
                                padding: 15,
                                font: {{ size: 11 }}
                            }}
                        }}
                    }}
                }}
            }});

            // Price Range Bar Chart
            new Chart(document.getElementById('priceChart'), {{
                type: 'bar',
                data: {{
                    labels: {price_labels},
                    datasets: [{{
                        label: 'äº§å“æ•°é‡',
                        data: {price_data},
                        backgroundColor: 'rgba(102, 126, 234, 0.8)',
                        borderColor: 'rgba(102, 126, 234, 1)',
                        borderWidth: 2,
                        borderRadius: 8
                    }}]
                }},
                options: {{
                    responsive: true,
                    maintainAspectRatio: true,
                    scales: {{
                        y: {{
                            beginAtZero: true,
                            ticks: {{
                                stepSize: 1
                            }}
                        }}
                    }},
                    plugins: {{
                        legend: {{
                            display: false
                        }}
                    }}
                }}
            }});
        </script>"""

    def _render_section(self, title: str, products: List[Dict], anchor_id: str) -> str:
        """æ¸²æŸ“äº§å“åŒºå—"""
        if not products:
            return ""

        cards = '\n'.join([self._render_card(p) for p in products])

        return f"""
        <div class="section" id="{anchor_id}">
            <h2 class="section-title">{title}æ–°å“ ({len(products)})</h2>
            <div class="products-grid">
                {cards}
            </div>
        </div>"""

    def _render_key_specs(self, product: Dict) -> str:
        """æ¸²æŸ“Top 3æ ¸å¿ƒå‚æ•°ï¼ˆå¸¦å›¾æ ‡ï¼‰- ä½¿ç”¨ Top 15 Schema å­—æ®µ"""
        category = product.get('category', '')
        specs = product.get('specs', {})

        if category == 'é¼ æ ‡':
            # é¼ æ ‡Top 3: ä½¿ç”¨ Top 15 Schema å­—æ®µ
            key_specs = [
                ('âš–ï¸', 'weight_center', 'é‡é‡'),
                ('ğŸ–±ï¸', 'sensor_solution', 'ä¼ æ„Ÿå™¨'),
                ('âš¡', 'polling_rate', 'å›æŠ¥ç‡')
            ]
        elif category == 'é”®ç›˜':
            # é”®ç›˜Top 3: ä½¿ç”¨ Top 15 Schema å­—æ®µ
            key_specs = [
                ('âŒ¨ï¸', 'structure_form', 'ç»“æ„'),
                ('ğŸ”Œ', 'connection_storage', 'è¿æ¥'),
                ('ğŸ”˜', 'switch_details', 'è½´ä½“')
            ]
        else:
            return ''

        badges = []
        for icon, spec_key, label in key_specs:
            value = specs.get(spec_key, '')
            value_str = str(value).strip() if value else ''

            # [FIX B.4] ç¼ºå¤±å€¼æ˜¾ç¤ºé€»è¾‘é‡æ„ï¼šä¸å†éšè—ç¼ºå¤±å€¼
            if not value_str:
                # ç©ºå€¼ â†’ æ˜¾ç¤º"æœªæåŠ"
                display_value = 'æœªæåŠ'
                badge_class = 'spec-missing'
            elif any(marker in value_str.lower() for marker in [
                'æœªæåŠ', 'åŸæ–‡æœªæåŠ', 'æœªæä¾›', 'æœªçŸ¥', 'unknown', 'none', 'null'
            ]):
                # æœªæåŠç±»
                display_value = 'æœªæåŠ'
                badge_class = 'spec-missing'
            elif any(marker in value_str.lower() for marker in [
                'æœªå…¬å¼€', 'å‚å•†æœªå…¬å¼€', 'tbd', 'å¾…å…¬å¸ƒ'
            ]):
                # æœªå…¬å¼€ç±»
                display_value = 'æœªå…¬å¼€'
                badge_class = 'spec-undisclosed'
            elif any(marker in value_str.lower() for marker in [
                'å¾…å®æµ‹', 'å¾…å®˜æ–¹å®æµ‹', 'å®æµ‹ä¸­'
            ]):
                # å¾…å®æµ‹ç±»
                display_value = 'å¾…å®æµ‹'
                badge_class = 'spec-pending'
            elif any(marker in value_str.lower() for marker in [
                'é¢„ä¼°', 'æ¨æ–­', 'æ¨æµ‹', 'å¯èƒ½'
            ]):
                # é¢„ä¼°ç±»
                display_value = f'{value} (é¢„ä¼°)'
                badge_class = 'spec-estimated'
            else:
                # æ­£å¸¸å€¼å¤„ç†
                display_value = value
                badge_class = ''

                # ç®€åŒ–å€¼æ˜¾ç¤ºï¼ˆå»é™¤å†—ä½™ä¿¡æ¯ï¼‰
                if spec_key == 'weight_center' and 'g' in str(value):
                    display_value = str(value).replace('g', '').strip() + 'g'
                elif spec_key == 'polling_rate' and 'Hz' in str(value):
                    display_value = str(value).replace('Hz', '').replace('hz', '').strip() + 'Hz'

            # [FIX E] æ£€æŸ¥äºŒæ¬¡è¡¥å…¨çŠ¶æ€ - ä¼˜å…ˆçº§é«˜äºé»˜è®¤åˆ¤å®š
            enrichment = product.get('enrichment', {})
            field_status = enrichment.get('field_status', {})
            evidence = enrichment.get('evidence', {})

            # å¦‚æœå­—æ®µè¢«è¡¥å…¨ï¼Œè¦†ç›– badge_class
            if spec_key in field_status:
                status = field_status[spec_key]
                if status == 'enriched':
                    badge_class = 'spec-enriched'
                elif status == 'inferred':
                    badge_class = 'spec-inferred'

            # æ„å»º badge HTML
            evidence_attr = ''
            wrapper_class = ''

            # å¦‚æœæœ‰è¯æ®ç‰‡æ®µï¼Œæ·»åŠ  tooltip
            if spec_key in evidence:
                evidence_data = evidence[spec_key]
                snippet = evidence_data.get('snippet', '')
                method = evidence_data.get('method', 'unknown')
                source = evidence_data.get('source', 'local')
                if snippet:
                    evidence_attr = f' data-evidence="ğŸ“‹ è¯æ®ç‰‡æ®µ ({method}æå–ï¼Œ{source}æº):\n{snippet}"'
                    wrapper_class = 'evidence-tooltip'

            if badge_class:
                badge_html = f'<span class="key-spec-badge {badge_class}{f" {wrapper_class}" if wrapper_class else ""}"{evidence_attr}><span class="spec-icon">{icon}</span>{label}: <span class="spec-value">{display_value}</span></span>'
            else:
                badge_html = f'<span class="key-spec-badge{f" {wrapper_class}" if wrapper_class else ""}"{evidence_attr}><span class="spec-icon">{icon}</span>{label}: <span class="spec-value">{display_value}</span></span>'
            badges.append(badge_html)

        return f'<div class="key-specs">{"".join(badges)}</div>' if badges else ''

    def _get_price_status(self, price: str) -> tuple:
        """è·å–ä»·æ ¼å’ŒçŠ¶æ€æ ‡ç­¾ - [FIX C.2] ç¦æ­¢å åŠ ï¼Œåªå±•ç¤ºä¸€ç§ status"""
        if not price or not price.strip():
            return ('æœªæåŠ', 'missing')
        elif price == 'ä»·æ ¼æœªå…¬å¼€':
            return ('æœªå…¬å¼€', 'undisclosed')

        price_lower = price.lower().strip()

        # [FIX C.2] ä¼˜å…ˆçº§ï¼šæœªå…¬å¼€ > æœªæåŠ > å¾…å®æµ‹ > é¢„ä¼° > æ­£å¸¸
        if any(marker in price_lower for marker in ['æœªå…¬å¼€', 'å‚å•†æœªå…¬å¼€', 'tbd', 'å¾…å…¬å¸ƒ']):
            return ('æœªå…¬å¼€', 'undisclosed')
        elif any(marker in price_lower for marker in ['æœªæåŠ', 'åŸæ–‡æœªæåŠ', 'æœªæä¾›']):
            return ('æœªæåŠ', 'missing')
        elif any(marker in price_lower for marker in ['å¾…å®æµ‹', 'å¾…å®˜æ–¹å®æµ‹', 'å®æµ‹ä¸­']):
            return ('å¾…å®æµ‹', 'pending')
        elif any(marker in price_lower for marker in ['é¢„ä¼°', 'æ¨æ–­', 'æ¨æµ‹']):
            return (price, 'estimated')  # ä¿ç•™åŸå§‹å€¼ä½†æ ‡è®°ä¸ºé¢„ä¼°
        else:
            return (price, 'normal')  # æ­£å¸¸ä»·æ ¼

    @staticmethod
    def _standardize_price(price_str: str, product_name: str = '') -> str:
        """
        æ ‡å‡†åŒ–ä»·æ ¼æ˜¾ç¤ºï¼Œå¤„ç†å¤–å¸è½¬æ¢å’Œæ ¼å¼ç»Ÿä¸€

        Args:
            price_str: åŸå§‹ä»·æ ¼å­—ç¬¦ä¸²
            product_name: äº§å“åç§°ï¼ˆç”¨äºæ¨æ–­ä»·æ ¼åŒºé—´ï¼‰

        Returns:
            æ ‡å‡†åŒ–åçš„ä»·æ ¼å­—ç¬¦ä¸²
        """
        import re

        if not price_str or price_str == 'ä»·æ ¼æœªå…¬å¼€':
            return 'ä»·æ ¼æœªå…¬å¼€'

        price_str = str(price_str).strip()

        # æ±‡ç‡ï¼ˆç®€åŒ–ç‰ˆï¼Œ2025å¹´å‚è€ƒï¼‰
        exchange_rates = {
            'USD': 7.2,    # 1ç¾å…ƒ = 7.2äººæ°‘å¸
            '$': 7.2,
            'JPY': 0.048,  # 1æ—¥å…ƒ = 0.048äººæ°‘å¸
            'Â¥': 0.048,    # æ—¥å…ƒç¬¦å·ï¼ˆéœ€è¦ä¸Šä¸‹æ–‡åˆ¤æ–­ï¼‰
            'EUR': 7.8,    # 1æ¬§å…ƒ = 7.8äººæ°‘å¸
            'â‚¬': 7.8,
            'HKD': 0.92,   # 1æ¸¯å¸ = 0.92äººæ°‘å¸
            'TWD': 0.23    # 1å°å¸ = 0.23äººæ°‘å¸
        }

        # æå–æ•°å­—å’Œè´§å¸ç¬¦å·
        # åŒ¹é…ï¼š19980æ—¥å…ƒã€$99ã€99USDã€199å…ƒç­‰
        patterns = [
            r'(\d+(?:\.\d+)?)\s*(æ—¥å…ƒ|JPY|Â¥)\s*',  # æ—¥å…ƒ
            r'[\$](\d+(?:\.\d+)?)',                 # ç¾å…ƒ
            r'(\d+(?:\.\d+)?)\s*(USD|EUR|â‚¬|HKD|TWD)\s*',  # å…¶ä»–å¤–å¸
            r'(\d+)\s*(?:å…ƒ|åœ†|RMB|CNY)\s*',        # äººæ°‘å¸
            r'çº¦\s*(\d+)\s*å…ƒ'                      # "çº¦XXXå…ƒ"
        ]

        for pattern in patterns[:1]:  # å…ˆå¤„ç†æ—¥å…ƒ
            match = re.search(pattern, price_str, re.IGNORECASE)
            if match:
                amount = float(match.group(1))
                currency = match.group(2) if len(match.groups()) > 1 else 'JPY'

                # æ—¥å…ƒè½¬æ¢
                if currency in ['æ—¥å…ƒ', 'JPY', 'Â¥']:
                    # åˆ¤æ–­æ˜¯å¦æ˜¯æ—¥å…ƒä»·æ ¼ï¼ˆé€šå¸¸æ—¥å…ƒä»·æ ¼æ•°å­—è¾ƒå¤§ï¼‰
                    if amount > 1000:  # æ—¥å…ƒä»·æ ¼é€šå¸¸>1000
                        cny_price = amount * exchange_rates['JPY']
                        return f'çº¦{int(cny_price)}å…ƒï¼ˆåŸä»·{int(amount)}æ—¥å…ƒï¼‰'

        # å¤„ç†ç¾å…ƒ
        usd_match = re.search(r'\$(\d+(?:\.\d+)?)', price_str)
        if usd_match:
            amount = float(usd_match.group(1))
            cny_price = amount * exchange_rates['$']
            return f'çº¦{int(cny_price)}å…ƒï¼ˆåŸä»·${amount}ï¼‰'

        # å¤„ç†æ¬§å…ƒ
        eur_match = re.search(r'(?:â‚¬|EUR)\s*(\d+(?:\.\d+)?)', price_str, re.IGNORECASE)
        if eur_match:
            amount = float(eur_match.group(1))
            cny_price = amount * exchange_rates['EUR']
            return f'çº¦{int(cny_price)}å…ƒï¼ˆåŸä»·â‚¬{amount}ï¼‰'

        # æå–äººæ°‘å¸æ•°å­—
        cny_match = re.search(r'(\d+)\s*(?:å…ƒ|åœ†|CNY|RMB|çº¦)', price_str)
        if cny_match:
            amount = int(cny_match.group(1))
            if 'é¢„ä¼°' in price_str or 'çº¦' in price_str:
                return f'{amount}å…ƒï¼ˆé¢„ä¼°ï¼‰'
            return f'{amount}å…ƒ'

        # å¦‚æœæ˜¯çº¯æ•°å­—ï¼Œè¡¥å……å•ä½
        digits_match = re.search(r'^(\d+)$', price_str.strip())
        if digits_match:
            amount = int(digits_match.group(1))
            if amount < 200:
                return f'{amount}å…ƒï¼ˆé¢„ä¼°ï¼‰'
            return f'{amount}å…ƒ'

        # åŸæ ·è¿”å›
        return price_str

    def _render_card(self, product: Dict) -> str:
        """æ¸²æŸ“å•ä¸ªäº§å“å¡ç‰‡ - ä¸‰æ å¸ƒå±€"""
        # è·å–åŸå§‹æ•°æ®
        raw_data = product.get('_raw', product)
        records = raw_data.get('records', []) if isinstance(raw_data, dict) else []

        # è·å–ä¸»å›¾ - ä½¿ç”¨å¤šå±‚fallbacké€»è¾‘
        main_image = product.get('main_image', '')

        # Fallback 1: å¦‚æœmain_imageä¸ºç©ºï¼Œå°è¯•ä»_raw.imagesè·å–ç¬¬ä¸€å¼ 
        if not main_image and isinstance(raw_data, dict):
            raw_images = raw_data.get('images', [])
            if raw_images and len(raw_images) > 0:
                main_image = raw_images[0]

        # Fallback 2: å¦‚æœè¿˜æ˜¯ä¸ºç©ºï¼Œå°è¯•ä»recordsä¸­æŸ¥æ‰¾ç¬¬ä¸€å¼ æœ‰å›¾ç‰‡çš„è®°å½•
        if not main_image and records:
            for record in records:
                if isinstance(record, dict):
                    record_images = record.get('images', [])
                    # å¤„ç†å­—ç¬¦ä¸²å½¢å¼çš„åˆ—è¡¨
                    if isinstance(record_images, str) and record_images not in ['[]', 'nan', '']:
                        try:
                            import ast
                            parsed = ast.literal_eval(record_images)
                            if isinstance(parsed, list) and len(parsed) > 0:
                                record_images = parsed
                        except:
                            pass
                    # ç¡®ä¿record_imagesæ˜¯åˆ—è¡¨ä¸”ä¸ä¸ºç©º
                    if isinstance(record_images, list) and len(record_images) > 0:
                        first_img = record_images[0]
                        # éªŒè¯ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯æœ‰æ•ˆçš„URLå­—ç¬¦ä¸²
                        if isinstance(first_img, str) and first_img and first_img not in ['[', ']']:
                            main_image = first_img
                            break

        image_html = self._render_image(main_image, product.get('category', ''))

        # æ¸²æŸ“ç¡¬æ ¸å‚æ•°
        specs = product.get('specs', {})
        # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆå‚æ•°ï¼ˆæ’é™¤"æš‚æ— æ•°æ®"ã€"å¾…å®æµ‹"ç­‰æ— æ•ˆå€¼ï¼‰
        has_specs = self._has_valid_specs(specs)

        # æ¸²æŸ“ PM æ·±åº¦æ´å¯Ÿï¼ˆä¼ å…¥ product ä»¥æ˜¾ç¤ºåˆ›æ–°æ ‡ç­¾ï¼‰
        analysis_html = self._render_analysis(product.get('analysis', {}), has_specs, product)

        # è·å–å‘å¸ƒæ—¥æœŸ
        publish_date = records[0].get('publish_date', '') if records else ''
        date_html = f'<div class="product-date">å‘å¸ƒæ—¶é—´: {publish_date[:10]}</div>' if publish_date else ''

        # æ¸²æŸ“æ¥æºé“¾æ¥
        links_html = self._render_links(records)

        # æ¸²æŸ“æ¥æº Badge
        sources = raw_data.get('sources', []) if isinstance(raw_data, dict) else []
        badge_html = self._render_source_badge(sources)

        # åˆ¤æ–­å¡ç‰‡æ ·å¼ç±»
        card_classes = ['product-card']
        if not has_specs:
            card_classes.append('no-specs')

        # æ¸²æŸ“Top 3æ ¸å¿ƒå‚æ•°
        key_specs_html = self._render_key_specs(product)

        # è·å–ä»·æ ¼å’ŒçŠ¶æ€
        price = product.get('release_price', '')
        display_price, price_status = self._get_price_status(price)

        # [FIX C.2] æ„å»ºä»·æ ¼HTMLï¼ˆå¸¦çŠ¶æ€æ ‡ç­¾ï¼‰- æ›´æ–°çŠ¶æ€æ–‡æœ¬æ˜ å°„
        price_html = f'<div class="product-price">{display_price}'
        if price_status and price_status != 'normal':
            # çŠ¶æ€æ–‡æœ¬æ˜ å°„
            status_text_map = {
                'missing': 'æœªæåŠ',
                'undisclosed': 'æœªå…¬å¼€',
                'pending': 'å¾…å®æµ‹',
                'estimated': 'é¢„ä¼°'
            }
            status_text = status_text_map.get(price_status, price_status)
            price_html += f' <span class="price-status {price_status}">{status_text}</span>'
        price_html += '</div>'

        return f"""
        <div class="{' '.join(card_classes)}">
            {badge_html}
            <!-- å·¦æ ï¼šäº§å“æ¦‚è§ˆ -->
            <div class="product-overview">
                {image_html}
                <div class="product-name">{product.get('product_name', 'æœªçŸ¥äº§å“')}</div>
                {price_html}
                {key_specs_html}
                {date_html}
                {links_html}
            </div>

            <!-- ä¸­æ ï¼šç¡¬æ ¸å‚æ•°ï¼ˆå¦‚æœæœ‰ï¼‰-->
            {f'''<div class="product-specs">
                <div class="block-title">ç¡¬æ ¸å‚æ•°</div>
                {self._render_specs(specs, product.get('data_sources'), product.get('category', ''))}
            </div>''' if has_specs else ''}

            <!-- å³æ ï¼šPM æ·±åº¦æ´å¯Ÿ -->
            <div class="product-analysis">
                <div class="block-title">PM æ·±åº¦æ´å¯Ÿ</div>
                {analysis_html}
            </div>
        </div>
    </div>"""

    def _render_image(self, image_url: str, category: str) -> str:
        """æ¸²æŸ“äº§å“å›¾ç‰‡ - ä½¿ç”¨ç§‘æŠ€æ„Ÿå ä½å›¾ + lazy loading"""
        # ä½¿ç”¨é»˜è®¤ç§‘æŠ€æ„Ÿå ä½å›¾
        final_image = image_url if image_url else DEFAULT_IMAGE_URL

        # å°† http://www.inwaishe.com çš„å›¾ç‰‡ URL è½¬æ¢ä¸º https://
        if final_image and final_image.startswith('http://www.inwaishe.com'):
            final_image = final_image.replace('http://', 'https://', 1)

        return f'''<div class="product-image" title="ç‚¹å‡»æ”¾å¤§é¢„è§ˆ">
                <img src="{final_image}" alt="äº§å“å›¾ç‰‡" loading="lazy" onerror="this.src='{DEFAULT_IMAGE_URL}'">
            </div>'''

    def _render_specs(self, specs: Dict, data_sources: Dict = None, category: str = '') -> str:
        """æ¸²æŸ“ç¡¬æ ¸å‚æ•°åˆ—è¡¨ï¼ˆTop 15 Schemaï¼‰"""
        if not specs:
            return '<div class="no-specs">æš‚æ— è¯¦ç»†å‚æ•°</div>'

        rows = []

        # Top 15 Schema ä¸­æ–‡æ ‡ç­¾æ˜ å°„ï¼ˆé¼ æ ‡ + é”®ç›˜ï¼‰
        label_map = {
            # é¼ æ ‡ Top 15 å‚æ•°
            'product_pricing': 'äº§å“ä¸å®šä»·',
            'mold_lineage': 'æ¨¡å…·è¡€ç»Ÿ',
            'weight_center': 'é‡é‡ä¸é‡å¿ƒ',
            'sensor_solution': 'ä¼ æ„Ÿå™¨æ–¹æ¡ˆ',
            'mcu_chip': 'ä¸»æ§èŠ¯ç‰‡',
            'polling_rate': 'å›æŠ¥ç‡é…ç½®',
            'end_to_end_latency': 'å…¨é“¾è·¯å»¶è¿Ÿ',
            'switch_features': 'å¾®åŠ¨ç‰¹æ€§',
            'scroll_encoder': 'æ»šè½®ç¼–ç å™¨',
            'coating_process': 'æ¶‚å±‚å·¥è‰º',
            'high_refresh_battery': 'é«˜åˆ·ç»­èˆª',
            'structure_quality': 'ç»“æ„åšå·¥',
            'feet_config': 'è„šè´´é…ç½®',
            'wireless_interference': 'æ— çº¿æŠ—å¹²æ‰°',
            'driver_experience': 'é©±åŠ¨ä½“éªŒ',
            # é”®ç›˜ Top 15 å‚æ•°
            'product_layout': 'äº§å“ä¸é…åˆ—',
            'structure_form': 'ç»“æ„å½¢å¼',
            'tech_route': 'æŠ€æœ¯è·¯çº¿',
            'rt_params': 'RTå‚æ•°',
            'sound_dampening': 'å£°éŸ³åŒ…å¡«å……',
            'switch_details': 'è½´ä½“è¯¦è§£',
            'measured_latency': 'å®æµ‹å»¶è¿Ÿ',
            'keycap_craftsmanship': 'é”®å¸½å·¥è‰º',
            'bigkey_tuning': 'å¤§é”®è°ƒæ ¡',
            'pcb_features': 'PCBç‰¹æ€§',
            'case_craftsmanship': 'å¤–å£³å·¥è‰º',
            'front_height': 'å‰é«˜æ•°æ®',
            'battery_efficiency': 'ç”µæ± æ•ˆç‡',
            'connection_storage': 'è¿æ¥ä¸æ”¶çº³',
            'software_support': 'è½¯ä½“æ”¯æŒ'
        }

        # é¼ æ ‡ Top 15 ä¼˜å…ˆçº§æ’åº
        mouse_priority = [
            'product_pricing', 'mold_lineage', 'weight_center', 'sensor_solution',
            'mcu_chip', 'polling_rate', 'end_to_end_latency', 'switch_features',
            'scroll_encoder', 'coating_process', 'high_refresh_battery',
            'structure_quality', 'feet_config', 'wireless_interference',
            'driver_experience'
        ]

        # é”®ç›˜ Top 15 ä¼˜å…ˆçº§æ’åº
        keyboard_priority = [
            'product_layout', 'structure_form', 'tech_route', 'rt_params',
            'sound_dampening', 'switch_details', 'measured_latency',
            'keycap_craftsmanship', 'bigkey_tuning', 'pcb_features',
            'case_craftsmanship', 'front_height', 'battery_efficiency',
            'connection_storage', 'software_support'
        ]

        # æ ¹æ®ç±»åˆ«é€‰æ‹©ä¼˜å…ˆçº§é¡ºåº
        if 'é¼ æ ‡' in category:
            priority_order = mouse_priority
        elif 'é”®ç›˜' in category:
            priority_order = keyboard_priority
        else:
            # æ··åˆæƒ…å†µï¼šä¼˜å…ˆæ˜¾ç¤ºé¼ æ ‡å­—æ®µ
            priority_order = mouse_priority + [k for k in keyboard_priority if k not in mouse_priority]

        # æŒ‰ä¼˜å…ˆçº§æ’åºæ˜¾ç¤º
        for key in priority_order:
            if key in specs:
                value = specs[key]
                if value and str(value).strip():
                    # æ ¼å¼åŒ–æ˜¾ç¤ºå€¼ï¼šå¤„ç†å­—å…¸/JSONæ ¼å¼
                    display_value = self._format_spec_value(value)

                    # è¿‡æ»¤æ‰æ— æ•ˆå€¼ï¼ˆæš‚æ— æ•°æ®ã€å¾…å®æµ‹ã€æœªæåŠç­‰ï¼‰
                    invalid_markers = ['æš‚æ— æ•°æ®', 'å¾…å®æµ‹', 'æœªæåŠ', 'æœªçŸ¥', 'unknown', 'null', 'none']
                    if any(marker in display_value for marker in invalid_markers):
                        continue

                    label = label_map.get(key, key)

                    # æ£€æŸ¥æ•°æ®æ¥æºï¼Œæ·»åŠ æœç´¢å›¾æ ‡
                    source_icon = ''
                    if data_sources and data_sources.get(key) == 'search':
                        source_icon = ' <span style="color: #667eea;">ğŸ”</span>'

                    rows.append(f'''<div class="spec-item">
                        <span class="spec-label">{label}{source_icon}</span>
                        <span class="spec-value">{display_value}</span>
                    </div>''')

        return f'<div class="specs-list">{"".join(rows)}</div>' if rows else '<div class="no-specs">æš‚æ— è¯¦ç»†å‚æ•°</div>'

    @staticmethod
    def _has_valid_specs(specs: Dict) -> bool:
        """
        æ£€æŸ¥ specs å­—å…¸ä¸­æ˜¯å¦æœ‰æœ‰æ•ˆçš„å‚æ•°å€¼

        æœ‰æ•ˆå€¼ï¼šéç©ºã€éçº¯"æš‚æ— æ•°æ®"æ ‡è®°
        æ³¨æ„ï¼š"å¾…å®æµ‹"ã€"æœªæåŠ"ç­‰æè¿°æ€§æ–‡æœ¬ä¼šè¢«ä¿ç•™ï¼Œåªåœ¨æ˜¾ç¤ºæ—¶åšåˆ¤æ–­

        Args:
            specs: å‚æ•°å­—å…¸

        Returns:
            æ˜¯å¦å­˜åœ¨æœ‰æ•ˆå‚æ•°
        """
        # åªæ£€æŸ¥æ˜¯å¦æœ‰éç©ºå€¼ï¼Œä¸åšæ·±åº¦è¿‡æ»¤
        # "å¾…å®æµ‹"ã€"æœªæåŠ"ç­‰æè¿°æ€§æ–‡æœ¬åœ¨æ˜¾ç¤ºæ—¶å†å†³å®šæ˜¯å¦éšè—
        for value in specs.values():
            if value and str(value).strip():
                # æœ‰ä»»ä½•éç©ºå€¼å°±è¿”å› True
                return True

        return False

    @staticmethod
    def _format_spec_value(value: Any) -> str:
        """
        æ ¼å¼åŒ–å‚æ•°å€¼ï¼Œå¤„ç†å­—å…¸/åˆ—è¡¨ç­‰å¤æ‚æ ¼å¼

        Args:
            value: åŸå§‹å‚æ•°å€¼

        Returns:
            æ ¼å¼åŒ–åçš„ HTML å­—ç¬¦ä¸²
        """
        import re

        # å¤„ç† None å€¼
        if value is None:
            return '<span style="color: #718096; font-style: italic;">æš‚æ— æ•°æ®</span>'

        # è½¬ä¸ºå­—ç¬¦ä¸²å¤„ç†
        value_str = str(value).strip()

        # ç©ºå€¼å¤„ç†
        if not value_str or value_str.lower() in ['unknown', 'æœªçŸ¥', 'none', 'null']:
            return '<span style="color: #718096; font-style: italic;">æš‚æ— æ•°æ®</span>'

        # æ£€æµ‹æ˜¯å¦æ˜¯å­—å…¸/JSON æ ¼å¼
        if value_str.startswith('{') and value_str.endswith('}'):
            try:
                import json
                parsed = json.loads(value_str)
                if isinstance(parsed, dict):
                    # è½¬æ¢ä¸ºæ˜“è¯»çš„ HTML åˆ—è¡¨
                    items = []
                    for k, v in parsed.items():
                        # é€’å½’æ ¼å¼åŒ–åµŒå¥—å€¼
                        formatted_v = HTMLReportGenerator._format_spec_value(v)
                        # å»æ‰HTMLæ ‡ç­¾ï¼Œåªä¿ç•™æ–‡æœ¬ï¼ˆé¿å…åµŒå¥—HTMLï¼‰
                        v_clean = re.sub('<[^<]+?>', '', formatted_v)
                        items.append(f'<strong>{k}</strong>: {v_clean}')
                    return '<br>'.join(items)
            except:
                pass

        # æ£€æµ‹æ˜¯å¦æ˜¯åˆ—è¡¨æ ¼å¼
        if value_str.startswith('[') and value_str.endswith(']'):
            try:
                import json
                parsed = json.loads(value_str)
                if isinstance(parsed, list):
                    return 'ã€'.join(str(item) for item in parsed if item)
            except:
                pass

        # å¤„ç†æ¢è¡Œç¬¦
        if '\n' in value_str:
            return '<br>'.join(value_str.split('\n'))

        # é»˜è®¤è¿”å›åŸå€¼
        return value_str

    def _render_analysis(self, analysis: Dict, has_specs: bool, product: Dict = None) -> str:
        """æ¸²æŸ“ PM æ·±åº¦æ´å¯Ÿ"""
        if not analysis or not any(analysis.values()):
            # PM æ´å¯Ÿä¸ºç©ºæ—¶çš„ç¼ºçœçŠ¶æ€
            return '''<div class="empty-analysis">
                <div class="empty-analysis-icon">ğŸ“Š</div>
                <div class="empty-analysis-text">PM æ·±åº¦åˆ†æä¸­...</div>
                <div class="empty-analysis-text" style="font-size: 0.85em; margin-top: 8px;">ç­‰å¾… LLM æ¥å…¥åæä¾›å®Œæ•´åˆ†æ</div>
            </div>'''

        html_parts = []

        # åˆ›æ–°æ ‡ç­¾ï¼ˆæ–°å¢ï¼‰
        innovation_tags = product.get('innovation_tags', []) if product else []
        if innovation_tags:
            tags_html = ' '.join([f'<span style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 4px 10px; border-radius: 4px; font-size: 0.75em; margin-right: 5px; margin-bottom: 5px; display: inline-block; color: white;">{tag}</span>' for tag in innovation_tags])
            html_parts.append(f'''<div class="analysis-section">
                <div class="analysis-label">åˆ›æ–°æ ‡ç­¾</div>
                <div class="analysis-text">{tags_html}</div>
            </div>''')

        # å¸‚åœºå®šä½
        if analysis.get('market_position'):
            html_parts.append(f'''<div class="analysis-section">
                <div class="analysis-label">å¸‚åœºå®šä½</div>
                <div class="analysis-text">{analysis['market_position']}</div>
            </div>''')

        # ç«å“åˆ†æ
        if analysis.get('competitors'):
            html_parts.append(f'''<div class="analysis-section">
                <div class="analysis-label">ç«å“å¯¹æ¯”</div>
                <div class="analysis-text">{analysis['competitors']}</div>
            </div>''')

        # ç›®æ ‡ç”¨æˆ·
        if analysis.get('target_audience'):
            html_parts.append(f'''<div class="analysis-section">
                <div class="analysis-label">ç›®æ ‡ç”¨æˆ·</div>
                <div class="analysis-text">{analysis['target_audience']}</div>
            </div>''')

        # æ ¸å¿ƒå–ç‚¹
        if analysis.get('selling_point'):
            html_parts.append(f'''<div class="analysis-section">
                <div class="analysis-label">æ ¸å¿ƒå–ç‚¹</div>
                <div class="analysis-text">{analysis['selling_point']}</div>
            </div>''')

        # ä¼˜ç¼ºç‚¹åˆ†æ
        verdict = analysis.get('verdict', {})
        if verdict:
            pros_list = ''.join([f'<li>{p}</li>' for p in verdict.get('pros', [])])
            cons_list = ''.join([f'<li>{c}</li>' for c in verdict.get('cons', [])])

            html_parts.append(f'''<div class="analysis-section">
                <div class="verdict-grid">
                    <div class="verdict-box pros">
                        <div class="verdict-title pros">âœ“ ä¼˜ç‚¹</div>
                        <ul class="verdict-list pros">{pros_list}</ul>
                    </div>
                    <div class="verdict-box cons">
                        <div class="verdict-title cons">âœ— ç¼ºç‚¹</div>
                        <ul class="verdict-list cons">{cons_list}</ul>
                    </div>
                </div>
            </div>''')

        # PM æ€»ç»“è®º
        if analysis.get('pm_summary'):
            html_parts.append(f'''<div class="pm-summary">
                <div class="pm-summary-text">"{analysis['pm_summary']}"</div>
            </div>''')

        return ''.join(html_parts) if html_parts else '<div class="no-specs">æš‚æ—  PM åˆ†æ</div>'

    def _render_links(self, records: List[Dict]) -> str:
        """æ¸²æŸ“æ¥æºé“¾æ¥"""
        if not records:
            return ''

        links = []
        seen_urls = set()

        for record in records[:3]:  # æœ€å¤šæ˜¾ç¤º3ä¸ªé“¾æ¥
            url = record.get('url', '')
            if url and url not in seen_urls:
                seen_urls.add(url)
                source = record.get('source', 'è¯¦æƒ…')
                links.append(f'<a class="source-link" href="{url}" target="_blank" rel="noopener noreferrer">{source}</a>')

        return f'<div class="source-links">{"".join(links)}</div>' if links else ''

    def _render_source_badge(self, sources: List[str]) -> str:
        """æ¸²æŸ“æ¥æº Badge"""
        if not sources:
            return ''

        # åˆ¤æ–­æ¥æº
        has_inwaishe = 'inå¤–è®¾' in sources
        has_wstx = 'å¤–è®¾å¤©ä¸‹' in sources

        if has_inwaishe and has_wstx:
            badge_class = 'both'
            badge_text = 'åŒå¹³å°'
        elif has_inwaishe:
            badge_class = 'inwaishe'
            badge_text = 'inå¤–è®¾'
        else:
            badge_class = 'wstx'
            badge_text = 'å¤–è®¾å¤©ä¸‹'

        return f'<div class="source-badge {badge_class}">{badge_text}</div>'


# ==================== ä¸»æµç¨‹ ====================

def mcp_search_wrapper(query: str) -> Optional[str]:
    """
    MCP æœç´¢åŒ…è£…å‡½æ•° - ç”¨äº ParameterCompleter

    æ³¨æ„ï¼šæ­¤å‡½æ•°éœ€è¦åœ¨ Claude Code ç¯å¢ƒä¸­è¿è¡Œï¼Œå¹¶å·²é…ç½® web-search-prime å·¥å…·

    Args:
        query: æœç´¢æŸ¥è¯¢å­—ç¬¦ä¸²

    Returns:
        æœç´¢ç»“æœæ‘˜è¦æ–‡æœ¬ï¼ˆåˆå¹¶å‰3ä¸ªç»“æœçš„contentå­—æ®µï¼‰
    """
    try:
        # è¿™é‡Œéœ€è¦è°ƒç”¨ MCP å·¥å…·
        # ç”±äº Python ä»£ç æ— æ³•ç›´æ¥è®¿é—® MCP å·¥å…·ï¼Œæˆ‘ä»¬éœ€è¦é€šè¿‡ç‰¹æ®Šçš„æ–¹å¼
        # åœ¨å®é™…è¿è¡Œæ—¶ï¼Œæ­¤å‡½æ•°ä¼šè¢«æ›¿æ¢ä¸ºçœŸæ­£çš„ MCP è°ƒç”¨

        # ä¸´æ—¶æ–¹æ¡ˆï¼šè¿”å›ç‰¹æ®Šæ ‡è®°ï¼Œç”±è°ƒç”¨è€…å¤„ç†
        # åœ¨ä¸»æµç¨‹ä¸­ï¼Œæˆ‘ä»¬ä¼šé€šè¿‡å…¶ä»–æ–¹å¼å¤„ç†æœç´¢
        print(f"        [MCPæœç´¢] è¯·æ±‚: {query}")
        return f"MCP_SEARCH:{query}"

    except Exception as e:
        print(f"        [MCPæœç´¢] å¤±è´¥: {str(e)[:100]}")
        return None


# ==================== æ•°æ®å®Œæ•´æ€§æ£€æŸ¥ä¸äºŒæ¬¡æœç´¢è¡¥å…¨ ====================

def check_data_completeness(extracted: Dict) -> Dict:
    """
    æ£€æŸ¥äº§å“æ•°æ®çš„å®Œæ•´æ€§

    Args:
        extracted: LLMæå–çš„äº§å“æ•°æ®

    Returns:
        dict: {
            'is_complete': bool,  # æ•°æ®æ˜¯å¦å®Œæ•´
            'missing_fields': list,  # ç¼ºå¤±çš„å…³é”®å­—æ®µ
            'completeness_score': float  # å®Œæ•´åº¦åˆ†æ•° (0-1)
        }
    """
    category = extracted.get('category', '').lower()
    specs = extracted.get('specs', {})

    # å®šä¹‰å…³é”®å­—æ®µï¼ˆä¸åŒäº§å“ç±»åˆ«ï¼‰
    critical_fields = {
        'mouse': ['sensor', 'weight', 'polling_rate', 'price', 'connection'],
        'keyboard': ['switch', 'connection', 'layout', 'structure', 'price']
    }

    # æ ¹æ®ç±»åˆ«é€‰æ‹©å…³é”®å­—æ®µ
    if 'mouse' in category or 'é¼ æ ‡' in extracted.get('product_name', ''):
        required_fields = critical_fields['mouse']
    elif 'keyboard' in category or 'é”®ç›˜' in extracted.get('product_name', ''):
        required_fields = critical_fields['keyboard']
    else:
        # æœªçŸ¥ç±»åˆ«ï¼Œæ£€æŸ¥æ‰€æœ‰å­—æ®µ
        required_fields = list(set(critical_fields['mouse'] + critical_fields['keyboard']))

    # æ£€æŸ¥ç¼ºå¤±å­—æ®µ
    missing_fields = []
    present_fields = 0

    for field in required_fields:
        value = specs.get(field, '')
        if value and value not in ['æœªçŸ¥', 'æœªå…¬å¼€', 'N/A', '']:
            present_fields += 1
        else:
            missing_fields.append(field)

    completeness_score = present_fields / len(required_fields) if required_fields else 0

    # åˆ¤æ–­æ˜¯å¦å®Œæ•´ï¼ˆå®Œæ•´åº¦ >= 60%ï¼‰
    is_complete = completeness_score >= 0.6

    return {
        'is_complete': is_complete,
        'missing_fields': missing_fields,
        'completeness_score': completeness_score,
        'present_count': present_fields,
        'total_count': len(required_fields)
    }


def second_round_search(product_name: str, category: str, missing_fields: list, search_func) -> Optional[Dict]:
    """
    ç¬¬äºŒæ¬¡æœç´¢è¡¥å…¨ - é’ˆå¯¹ç¼ºå¤±çš„å­—æ®µè¿›è¡Œä¸“é—¨æœç´¢

    Args:
        product_name: äº§å“åç§°
        category: äº§å“ç±»åˆ«
        missing_fields: ç¼ºå¤±çš„å­—æ®µåˆ—è¡¨
        search_func: æœç´¢å‡½æ•°

    Returns:
        è¡¥å…¨åçš„æ•°æ®ï¼Œæˆ– None
    """
    if not search_func or not missing_fields:
        return None

    print(f"        [äºŒæ¬¡æœç´¢] å¯åŠ¨è¡¥å…¨æœç´¢ï¼Œç¼ºå¤±å­—æ®µ: {missing_fields}")

    # æ„é€ æœç´¢å…³é”®è¯
    search_queries = []

    # åŸºç¡€æœç´¢ï¼šäº§å“å + è§„æ ¼
    search_queries.append(f"{product_name} è§„æ ¼ å‚æ•°")

    # é’ˆå¯¹ç¼ºå¤±å­—æ®µçš„ä¸“é—¨æœç´¢
    field_keywords_cn = {
        'sensor': 'ä¼ æ„Ÿå™¨',
        'weight': 'é‡é‡',
        'polling_rate': 'å›æŠ¥ç‡',
        'price': 'ä»·æ ¼',
        'connection': 'è¿æ¥æ–¹å¼',
        'switch': 'è½´ä½“',
        'layout': 'é…åˆ—',
        'structure': 'ç»“æ„'
    }

    for field in missing_fields[:2]:  # æœ€å¤šæœç´¢2ä¸ªç¼ºå¤±å­—æ®µ
        keyword = field_keywords_cn.get(field, field)
        search_queries.append(f"{product_name} {keyword}")

    # æ·»åŠ ç«™ç‚¹é™å®šæœç´¢ï¼ˆä¸“é—¨æœç´¢inå¤–è®¾å’Œå¤–è®¾å¤©ä¸‹ï¼‰
    site_queries = [
        f"site:inwaishe.com {product_name}",
        f"site:wstx.com {product_name}"
    ]
    search_queries.extend(site_queries)

    # æ‰§è¡Œæœç´¢
    all_search_results = []
    for query in search_queries[:4]:  # é™åˆ¶æœç´¢æ¬¡æ•°
        try:
            print(f"        [äºŒæ¬¡æœç´¢] æŸ¥è¯¢: {query}")
            result = search_func(query)
            if result:
                all_search_results.append(result)
        except Exception as e:
            print(f"        [äºŒæ¬¡æœç´¢] å¤±è´¥: {str(e)[:50]}")

    if not all_search_results:
        print(f"        [äºŒæ¬¡æœç´¢] æ— æœç´¢ç»“æœ")
        return None

    # åˆå¹¶æœç´¢ç»“æœ
    combined_content = '\n\n'.join(all_search_results)

    print(f"        [äºŒæ¬¡æœç´¢] è·å¾— {len(all_search_results)} æ¡ç»“æœï¼Œæ€»å­—ç¬¦æ•°: {len(combined_content)}")

    return {
        'search_results': all_search_results,
        'combined_content': combined_content,
        'queries_used': search_queries[:4]
    }


def process_single_product(extractor, completer, product, index):
    """
    å¤„ç†å•ä¸ªäº§å“ï¼ˆç”¨äºå¹¶å‘è°ƒç”¨ï¼‰

    Args:
        extractor: LLMExtractorå®ä¾‹
        completer: ParameterCompleterå®ä¾‹ï¼ˆå‚æ•°è¡¥å…¨å™¨ï¼‰
        product: äº§å“æ•°æ®
        index: äº§å“ç´¢å¼•

    Returns:
        å¤„ç†ç»“æœå­—å…¸ï¼ŒåŒ…å«extractedæ•°æ®æˆ–errorä¿¡æ¯
    """
    try:
        # ç¡®ä¿ product æ˜¯å­—å…¸ç±»å‹
        if not isinstance(product, dict):
            return {
                'error': True,
                'dropped': True,
                'reason': f'ç±»å‹å¼‚å¸¸: {type(product)}'
            }

        product_name = product.get('product_name', 'Unknown')
        if isinstance(product_name, str):
            product_name = product_name[:30]
        else:
            product_name = str(product_name)[:30]

        print(f"    [{index}] å¼€å§‹å¤„ç†: {product_name}...")

        # è°ƒç”¨APIæå–äº§å“ä¿¡æ¯
        extracted = extractor.extract_product_info(product)

        # ä¿ç•™åŸå§‹æ•°æ®
        extracted['_raw'] = product

        # ã€ä¿®å¤ã€‘å‚æ•°è‡ªåŠ¨è¡¥å…¨ V2 - åœ¨ specs æ£€æŸ¥ä¹‹å‰æ‰§è¡Œï¼
        if completer:
            try:
                # ä¸º ParameterCompleterV2 å‡†å¤‡æ•°æ®
                product_for_completion = {
                    'product_name': extracted.get('product_name', ''),
                    'category': extracted.get('category', ''),
                    'content_text': product.get('combined_content', ''),
                    'specs': extracted.get('specs', {}),
                    'data_sources': {}
                }

                # è°ƒç”¨ V2 ç‰ˆæœ¬çš„å‚æ•°è¡¥å…¨
                completed = completer.complete_parameters(product_for_completion)

                # æ›´æ–° extracted æ•°æ®
                extracted['specs'] = completed.get('specs', {})
                extracted['data_sources'] = completed.get('data_sources', {})

            except Exception as e:
                print(f"    [{index}] å‚æ•°è¡¥å…¨å¤±è´¥: {str(e)[:50]}")

        # ã€æ–°å¢ã€‘æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
        completeness_check = check_data_completeness(extracted)
        print(f"    [{index}] æ•°æ®å®Œæ•´åº¦: {completeness_check['completeness_score']:.1%} ({completeness_check['present_count']}/{completeness_check['total_count']})")

        # ã€æ–°å¢ã€‘ç¬¬äºŒæ¬¡æœç´¢è¡¥å…¨ - å¦‚æœæ•°æ®ä¸å®Œæ•´
        if not completeness_check['is_complete'] and completer and completer.search_enabled:
            missing_fields = completeness_check['missing_fields']
            print(f"    [{index}] æ•°æ®ä¸å®Œæ•´ï¼Œç¼ºå¤±: {missing_fields}ï¼Œå¯åŠ¨äºŒæ¬¡æœç´¢...")

            try:
                # æ‰§è¡Œç¬¬äºŒæ¬¡æœç´¢
                search_result = second_round_search(
                    product_name=extracted.get('product_name', ''),
                    category=extracted.get('category', ''),
                    missing_fields=missing_fields,
                    search_func=completer.search_func
                )

                if search_result:
                    # ä½¿ç”¨æœç´¢ç»“æœå†æ¬¡è¡¥å…¨å‚æ•°
                    product_for_completion_v2 = {
                        'product_name': extracted.get('product_name', ''),
                        'category': extracted.get('category', ''),
                        'content_text': search_result.get('combined_content', ''),
                        'specs': extracted.get('specs', {}),
                        'data_sources': {}
                    }

                    completed_v2 = completer.complete_parameters(product_for_completion_v2)

                    # æ›´æ–° extracted æ•°æ®ï¼ˆç¬¬äºŒæ¬¡è¡¥å…¨ï¼‰
                    extracted['specs'].update(completed_v2.get('specs', {}))
                    extracted['data_sources'].update(completed_v2.get('data_sources', {}))

                    # è®°å½•äºŒæ¬¡æœç´¢æ¥æº
                    if '_search_sources' not in extracted:
                        extracted['_search_sources'] = []
                    extracted['_search_sources'].extend(search_result.get('queries_used', []))

                    print(f"    [{index}] äºŒæ¬¡æœç´¢è¡¥å…¨å®Œæˆ")

            except Exception as e:
                print(f"    [{index}] äºŒæ¬¡æœç´¢å¤±è´¥: {str(e)[:50]}")

        # è¡¥å…¨åå†æ£€æŸ¥ specs æ˜¯å¦ä¸ºç©º
        specs = extracted.get('specs', {})
        has_valid_specs = any(specs.values())

        if not has_valid_specs:
            print(f"    [{index}] è·³è¿‡ï¼ˆè¡¥å…¨åä»æ— æœ‰æ•ˆspecsï¼‰: {product_name}")
            return {
                'error': False,
                'dropped': True,
                'data': None
            }

        print(f"    [{index}] å®Œæˆ: {product_name}")
        return {
            'error': False,
            'dropped': False,
            'data': extracted
        }

    except Exception as e:
        print(f"    [{index}] å¤±è´¥: {str(e)[:50]}...")
        return {
            'error': True,
            'dropped': True,
            'reason': str(e)
        }


def _parse_chart_data(html_content: str, chart_id: str) -> dict:
    """
    è§£æ Chart.js å›¾è¡¨çš„ data/labels

    Args:
        html_content: HTMLæŠ¥å‘Šå†…å®¹
        chart_id: å›¾è¡¨å…ƒç´ ID (å¦‚ 'categoryChart', 'sensorChart', 'priceChart')

    Returns:
        dict: {
            'labels': list,      # å›¾è¡¨æ ‡ç­¾åˆ—è¡¨
            'data': list,        # å›¾è¡¨æ•°æ®åˆ—è¡¨
            'labels_count': int, # æ ‡ç­¾æ•°é‡
            'samples_sum': int,  # æ•°æ®æ€»å’Œ
            'error': str or None # è§£æé”™è¯¯ä¿¡æ¯
        }
    """
    result = {
        'labels': [],
        'data': [],
        'labels_count': 0,
        'samples_sum': 0,
        'error': None
    }

    # æŸ¥æ‰¾ new Chart(document.getElementById('{chart_id}')) è°ƒç”¨
    chart_pattern = rf'new Chart\(document\.getElementById\(\'{chart_id}\'\),\s*\{{(.*?)\}}\);'
    chart_match = re.search(chart_pattern, html_content, re.DOTALL)

    if not chart_match:
        result['error'] = f"æœªæ‰¾åˆ°å›¾è¡¨å…ƒç´  '{chart_id}'"
        return result

    chart_content = chart_match.group(1)

    # è§£æ labels æ•°ç»„
    labels_match = re.search(r'labels:\s*\[([^\]]*(?:\[[^\]]*\][^\]]*)*)\]', chart_content, re.DOTALL)
    if not labels_match:
        result['error'] = f"å›¾è¡¨ '{chart_id}' ç¼ºå°‘ labels æ•°ç»„"
        return result

    labels_str = labels_match.group(1)
    # å¤„ç† Unicode è½¬ä¹‰åºåˆ—å’Œ JSON å­—ç¬¦ä¸²
    try:
        # å°è¯•ç›´æ¥è§£æä¸º JSON æ•°ç»„
        labels_str_clean = labels_str.strip()
        # å¤„ç† JavaScript Unicode è½¬ä¹‰ (å¦‚ \u9f20\u6807)
        labels_str_clean = labels_str_clean.encode().decode('unicode-escape')
        labels = json.loads(f'[{labels_str_clean}]')
        result['labels'] = labels
        result['labels_count'] = len(labels)
    except:
        # é™çº§ï¼šç®€å•åˆ†å‰²å¤„ç†
        labels = [l.strip().strip('"').strip("'") for l in labels_str.split(',') if l.strip()]
        result['labels'] = labels
        result['labels_count'] = len(labels)

    # è§£æ data æ•°ç»„
    data_match = re.search(r'data:\s*\[([^\]]*)\]', chart_content, re.DOTALL)
    if not data_match:
        result['error'] = f"å›¾è¡¨ '{chart_id}' ç¼ºå°‘ data æ•°ç»„"
        return result

    data_str = data_match.group(1)
    try:
        data_values = [int(d.strip()) for d in data_str.split(',') if d.strip().isdigit() or d.strip().lstrip('-').isdigit()]
        result['data'] = data_values
        result['samples_sum'] = sum(data_values)
    except:
        result['error'] = f"å›¾è¡¨ '{chart_id}' data æ•°ç»„è§£æå¤±è´¥"

    return result


def _validate_four_way_consistency(html_content: str) -> dict:
    """
    å››å‘ä¸€è‡´æ€§æ ¡éªŒï¼šnav_counts == section_counts == chart_counts == card_counts

    Args:
        html_content: HTMLæŠ¥å‘Šå†…å®¹

    Returns:
        dict: {
            'structural_passed': bool,  # ç»“æ„æ€§æ ¡éªŒæ˜¯å¦é€šè¿‡
            'data_passed': bool,        # æ•°æ®ä¸€è‡´æ€§æ ¡éªŒæ˜¯å¦é€šè¿‡
            'details': dict,            # è¯¦ç»†ä¿¡æ¯
            'errors': list              # é”™è¯¯åˆ—è¡¨
        }
    """
    result = {
        'structural_passed': True,
        'data_passed': True,
        'details': {},
        'errors': [],
        'warnings': []
    }

    # 1. æå–å¯¼èˆªæ åˆ†ç±»æŒ‰é’®æ•° (nav_count)
    # ç»Ÿè®¡ class="nav-btn" çš„æ•°é‡ï¼Œè¿™æ˜¯å¯¼èˆªåˆ†ç±»æŒ‰é’®æ•°ï¼ˆé¼ æ ‡/é”®ç›˜/å…¶ä»–ç­‰ï¼‰
    nav_btn_count = 0
    nav_match = re.search(r'<div[^>]*class="[^"]*nav-bar[^"]*"[^>]*>(.*?)</div>', html_content, re.DOTALL)
    if nav_match:
        nav_content = nav_match.group(1)
        nav_btns = re.findall(r'<a[^>]*class="[^"]*nav-btn[^"]*"[^>]*>', nav_content)
        nav_btn_count = len(nav_btns)

    result['details']['nav_category_buttons'] = nav_btn_count

    # 2. æå–æ¿å—æ•°é‡ (section_count) - ç»Ÿè®¡ <div class="product-card">
    section_count = len(re.findall(r'<div[^>]*class="[^"]*product-card[^"]*"[^>]*>', html_content))
    result['details']['section_count'] = section_count

    # 3. æå–å¡ç‰‡æ•°é‡ (card_count) - ç»Ÿè®¡äº§å“å¡ç‰‡ div
    card_count = len(re.findall(r'<div[^>]*class="[^"]*product-card[^"]*"[^>]*>', html_content))
    result['details']['card_count'] = card_count

    # 4. è§£æå›¾è¡¨æ•°æ® (labels_count, samples_sum)
    charts = {
        'category': 'å“ç±»å æ¯”',
        'sensor': 'é¼ æ ‡ä¼ æ„Ÿå™¨',
        'price': 'ä»·æ ¼åŒºé—´'
    }

    chart_details = {}
    for chart_id, chart_name in charts.items():
        chart_data = _parse_chart_data(html_content, f'{chart_id}Chart')
        chart_details[chart_id] = {
            'name': chart_name,
            'labels_count': chart_data['labels_count'],
            'samples_sum': chart_data['samples_sum'],
            'labels': chart_data['labels'],
            'data': chart_data['data'],
            'error': chart_data.get('error')
        }

        if chart_data.get('error'):
            result['warnings'].append(f"{chart_name}å›¾è¡¨è§£æå¤±è´¥: {chart_data['error']}")

    result['details']['charts'] = chart_details

    # ç»“æ„æ€§æ ¡éªŒï¼šç¡®ä¿å…³é”®è®¡æ•°éƒ½æå–æˆåŠŸ
    if section_count == 0:
        result['errors'].append("äº§å“æ¿å—è®¡æ•°ä¸º0ï¼Œå¯èƒ½ç¼ºå°‘äº§å“å¡ç‰‡")
        result['structural_passed'] = False

    if nav_btn_count == 0:
        result['warnings'].append("å¯¼èˆªæ åˆ†ç±»æŒ‰é’®æ•°ä¸º0ï¼Œå¯èƒ½ç¼ºå°‘å¯¼èˆªæ ")

    # æ•°æ®ä¸€è‡´æ€§æ ¡éªŒï¼šsection == cardï¼ˆæ ¸å¿ƒä¸€è‡´æ€§ï¼‰
    if section_count != card_count:
        result['errors'].append(
            f"æ ¸å¿ƒæ•°é‡ä¸ä¸€è‡´: section={section_count}, card={card_count}"
        )
        result['data_passed'] = False

    # å›¾è¡¨ä¸€è‡´æ€§æ ¡éªŒ
    # category_chart samples_sum åº”ç­‰äºæ€»å¡ç‰‡æ•°
    category_sum = chart_details['category']['samples_sum']
    if category_sum > 0 and category_sum != card_count:
        result['errors'].append(
            f"å“ç±»å›¾è¡¨æ•°æ®æ€»å’Œ({category_sum}) != å¡ç‰‡æ€»æ•°({card_count})"
        )
        result['data_passed'] = False

    # sensor_chart samples_sum åº”ç­‰äºé¼ æ ‡æ•°
    sensor_sum = chart_details['sensor']['samples_sum']
    # ä»å¯¼èˆªæŒ‰é’®ä¸­æŸ¥æ‰¾é¼ æ ‡æ•°é‡ï¼ˆæ ¼å¼ï¼šğŸ–±ï¸ é¼ æ ‡ (9)ï¼‰
    mice_count_match = re.search(r'é¼ æ ‡\s*\((\d+)\)', html_content)
    mice_count = int(mice_count_match.group(1)) if mice_count_match else 0
    if sensor_sum > 0 and mice_count > 0 and sensor_sum != mice_count:
        result['warnings'].append(
            f"ä¼ æ„Ÿå™¨å›¾è¡¨æ•°æ®æ€»å’Œ({sensor_sum}) != é¼ æ ‡æ•°({mice_count})ï¼Œå¯èƒ½å­˜åœ¨é¼ æ ‡äº§å“æœªæ ‡è®°ä¼ æ„Ÿå™¨"
        )

    # price_chart samples_sum åº”ç­‰äºæœ‰æœ‰æ•ˆä»·æ ¼çš„äº§å“æ•°ï¼ˆæˆ–æ ¹æ®ç­–ç•¥ï¼‰
    price_sum = chart_details['price']['samples_sum']
    if price_sum > 0 and price_sum > card_count:
        result['errors'].append(
            f"ä»·æ ¼å›¾è¡¨æ•°æ®æ€»å’Œ({price_sum}) > å¡ç‰‡æ€»æ•°({card_count})"
        )
        result['data_passed'] = False

    return result


def validate_html_report(html_path: str, force: bool = False) -> bool:
    """
    æ ¡éªŒHTMLæŠ¥å‘Šæ˜¯å¦åŒ…å«æ‰€æœ‰å¿…éœ€çš„å…³é”®ç»„ä»¶

    Args:
        html_path: HTMLæŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        force: æ˜¯å¦å¼ºåˆ¶è¾“å‡ºï¼ˆä»…ç»•è¿‡æ•°æ®ä¸€è‡´æ€§æ ¡éªŒï¼Œä¸ç»•è¿‡ç»“æ„æ€§æ ¡éªŒï¼‰

    Returns:
        bool: æ ¡éªŒæ˜¯å¦é€šè¿‡

    Raises:
        SystemExit: ç»“æ„æ€§æ ¡éªŒå¤±è´¥æ—¶é€€å‡ºç¨‹åº
    """
    # [FIX 8] å››å‘ä¸€è‡´æ€§æ ¡éªŒåˆ†çº§ï¼šç»“æ„æ€§å¿…å¤±è´¥ï¼›æ•°æ®ä¸€è‡´æ€§é»˜è®¤å¤±è´¥ä½†æ”¯æŒ --force è¾“å‡º
    required_components = {
        'nav-bar': 'å¯¼èˆªæ ï¼ˆåŒ…å«å¿«é€Ÿè·³è½¬å’Œæœç´¢æ¡†ï¼‰',
        'searchInput': 'æœç´¢è¾“å…¥æ¡†',
        'product-overview': 'äº§å“æ¦‚è§ˆæ¨¡å—ï¼ˆå·¦æ ï¼‰',
        'product-specs': 'ç¡¬æ ¸å‚æ•°æ¨¡å—ï¼ˆä¸­æ ï¼‰',
        'product-analysis': 'PMæ·±åº¦æ´å¯Ÿæ¨¡å—ï¼ˆå³æ ï¼‰',
        'PM æ·±åº¦æ´å¯Ÿ': 'PMæ·±åº¦æ´å¯Ÿæ ‡é¢˜'
    }

    print(f"\n[æ ¡éªŒ] æ£€æŸ¥HTMLæŠ¥å‘Š: {html_path}")

    if not Path(html_path).exists():
        print(f"[ERROR] æ–‡ä»¶ä¸å­˜åœ¨: {html_path}")
        raise SystemExit(1)

    with open(html_path, 'r', encoding='utf-8') as f:
        content = f.read()

    # ===== é˜¶æ®µ 1: ç»“æ„æ€§æ ¡éªŒï¼ˆå¿…å¤±è´¥ï¼‰ =====
    missing_components = []
    for component, description in required_components.items():
        if component not in content:
            missing_components.append(f"  [X] {component}: {description}")

    if missing_components:
        print(f"\n[FAIL] HTMLæŠ¥å‘Šç»“æ„æ€§æ ¡éªŒå¤±è´¥ï¼ç¼ºå°‘ä»¥ä¸‹å…³é”®ç»„ä»¶:")
        for item in missing_components:
            print(item)
        print(f"\nè¯·ä½¿ç”¨ --template pm_deep å‚æ•°é‡æ–°ç”ŸæˆæŠ¥å‘Šï¼")
        raise SystemExit(1)
    else:
        print("[OK] æ‰€æœ‰å…³é”®ç»„ä»¶ç»“æ„æ€§æ ¡éªŒé€šè¿‡:")
        for component, description in required_components.items():
            print(f"  [OK] {component}: {description}")

    # ===== é˜¶æ®µ 2: å››å‘æ•°æ®ä¸€è‡´æ€§æ ¡éªŒï¼ˆå¯ --force å¼ºåˆ¶é€šè¿‡ï¼‰ =====
    print("\n[æ ¡éªŒ] å››å‘æ•°æ®ä¸€è‡´æ€§æ ¡éªŒ...")
    validation_result = _validate_four_way_consistency(content)

    # æ‰“å°è¯¦ç»†ä¿¡æ¯
    details = validation_result['details']
    print(f"  - å¯¼èˆªåˆ†ç±»æŒ‰é’® (nav_btn):  {details.get('nav_category_buttons', 'N/A')}")
    print(f"  - æ¿å—è®¡æ•° (section):      {details.get('section_count', 'N/A')}")
    print(f"  - å¡ç‰‡è®¡æ•° (card):         {details.get('card_count', 'N/A')}")

    # æ‰“å°å›¾è¡¨è¯¦æƒ…
    if details.get('charts'):
        print(f"  - å›¾è¡¨æ•°æ® (charts):")
        for chart_id, chart_info in details['charts'].items():
            name = chart_info.get('name', chart_id)
            labels_count = chart_info.get('labels_count', 0)
            samples_sum = chart_info.get('samples_sum', 0)
            error = chart_info.get('error')
            if error:
                print(f"      * {name}: [ERROR] {error}")
            else:
                print(f"      * {name}: labels_count={labels_count}, samples_sum={samples_sum}")

    # æ‰“å°è­¦å‘Šä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
    if validation_result.get('warnings'):
        print("\n[WARNING] è§£æè­¦å‘Š:")
        for warning in validation_result['warnings']:
            print(f"  [!] {warning}")

    if validation_result['data_passed']:
        print("[OK] å››å‘æ•°æ®ä¸€è‡´æ€§æ ¡éªŒé€šè¿‡")
    else:
        print("[WARNING] å››å‘æ•°æ®ä¸€è‡´æ€§æ ¡éªŒå‘ç°é—®é¢˜:")
        for error in validation_result['errors']:
            print(f"  [!] {error}")

        if force:
            print("\n[FORCE] ä½¿ç”¨ --force å¼ºåˆ¶è¾“å‡ºï¼ˆæ•°æ®ä¸€è‡´æ€§é—®é¢˜å·²å¿½ç•¥ï¼‰")
        else:
            print("\n[FAIL] æ•°æ®ä¸€è‡´æ€§æ ¡éªŒå¤±è´¥ï¼Œä½¿ç”¨ --force å¯å¼ºåˆ¶è¾“å‡º")
            raise SystemExit(1)

    return True


def main(template_mode="pm_deep"):
    """ä¸»æµç¨‹

    Args:
        template_mode: æ¨¡æ¿æ¨¡å¼ï¼Œ"pm_deep" (é»˜è®¤) æˆ– "simple"
    """
    global TEMPLATE_MODE, HTML_REPORT
    TEMPLATE_MODE = template_mode

    print("=" * 60)
    print("å¤–è®¾æ–°å“ç›‘æ§æŠ¥å‘Šç”Ÿæˆç³»ç»Ÿ (Phase 4 æœ€ç»ˆä¼˜åŒ–ç‰ˆ)")
    print(f"æ¨¡æ¿æ¨¡å¼: {AVAILABLE_TEMPLATES.get(template_mode, template_mode)}")
    print("PM æ·±åº¦åˆ†æç‰ˆ | äº§å“å»é‡åˆå¹¶ | äº¤äº’ä¼˜åŒ–")
    print("=" * 60)

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    OUTPUT_DIR.mkdir(exist_ok=True)

    # æ­¥éª¤ 1: æ•°æ®æ¸…æ´—
    print("\n[æ­¥éª¤ 1/5] æ•°æ®é¢„å¤„ç†ä¸æ¸…æ´—")
    cleaner = DataCleaner('output/report_data_2026_01.xlsx')
    filtered_df = cleaner.filter_by_keywords()
    filtered_df = cleaner.filter_by_blacklist(filtered_df)  # é»‘åå•è¿‡æ»¤
    products = cleaner.smart_deduplicate(filtered_df)

    # æ­¥éª¤ 2: LLM PM æ·±åº¦åˆ†æï¼ˆå¹¶å‘å¤„ç†ï¼‰
    print(f"\n[æ­¥éª¤ 2/5] LLM PM æ·±åº¦åˆ†æï¼ˆå¹¶å‘æ¨¡å¼ï¼‰")
    extractor = LLMExtractor(LLM_CONFIG)

    # åˆå§‹åŒ–å‚æ•°è¡¥å…¨å™¨ V2ï¼ˆTop 15 Schemaï¼‰
    print(f"\n[æ­¥éª¤ 2.1/5] åˆå§‹åŒ–å‚æ•°è¡¥å…¨å™¨V2ï¼ˆTop 15 Schemaï¼‰...")

    # å¯¼å…¥ MCP å®¢æˆ·ç«¯
    from mcp_client import get_mcp_client

    mcp_client = get_mcp_client()

    def mcp_search_func(query: str) -> str:
        """MCP æœç´¢å‡½æ•°å°è£…"""
        if mcp_client.is_available():
            result = mcp_client.search(query, max_results=3)
            return result if result else ""
        return ""

    # æ ¹æ® MCP å¯ç”¨æ€§å†³å®šæ˜¯å¦ä¼ å…¥æœç´¢å‡½æ•°
    search_func = mcp_search_func if mcp_client.is_available() else None
    completer = ParameterCompleterV2(llm_config=LLM_CONFIG, search_func=search_func)

    search_status = "å¯ç”¨" if mcp_client.is_available() else "ç¦ç”¨"
    print(f"[OK] å‚æ•°è¡¥å…¨å™¨V2å·²åˆå§‹åŒ–ï¼ˆTop 15 Schemaï¼ŒMCPæœç´¢: {search_status}ï¼‰")

    import concurrent.futures
    import time

    # å¹¶å‘å¤„ç†é…ç½®ï¼ˆé™ä½å¹¶å‘ä»¥æé«˜ç¨³å®šæ€§ï¼‰
    batch_size = 5  # æ¯æ‰¹å¹¶å‘5ä¸ªï¼ˆä»9é™ä½åˆ°5ä»¥å‡å°‘APIå‹åŠ›ï¼‰
    total_products = len(products)
    total_batches = (total_products + batch_size - 1) // batch_size

    print(f"  æ€»äº§å“æ•°: {total_products}")
    print(f"  å¹¶å‘æ•°: {batch_size}")
    print(f"  åˆ†æ‰¹æ•°: {total_batches}")
    print(f"  é¢„è®¡è€—æ—¶: {total_batches * 15}ç§’ â‰ˆ {total_batches * 15 // 60}åˆ†é’Ÿ")
    print(f"  å‚æ•°è¡¥å…¨: {'å¯ç”¨' if completer.search_enabled else 'ç¦ç”¨'}")
    print()

    processed_products = []
    dropped_count = 0
    failed_items = []  # è®°å½•å¤±è´¥çš„äº§å“ä¿¡æ¯
    start_time = time.time()

    # åˆ†æ‰¹å¹¶å‘å¤„ç†
    for batch_idx in range(total_batches):
        start_idx = batch_idx * batch_size
        end_idx = min(start_idx + batch_size, total_products)
        batch_products = products[start_idx:end_idx]

        print(f"[æ‰¹æ¬¡ {batch_idx + 1}/{total_batches}] å¤„ç†äº§å“ {start_idx + 1}-{end_idx}...")

        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¤„ç†å½“å‰æ‰¹æ¬¡
        with concurrent.futures.ThreadPoolExecutor(max_workers=batch_size) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡ï¼ˆæ³¨æ„ï¼šç°åœ¨ä¼ é€’ completer å‚æ•°ï¼‰
            future_to_idx = {
                executor.submit(process_single_product, extractor, completer, product, idx + 1): idx + 1
                for idx, product in enumerate(batch_products, start_idx)
            }

            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            for future in concurrent.futures.as_completed(future_to_idx):
                idx = future_to_idx[future]
                try:
                    result = future.result()
                    if result.get('error'):
                        print(f"      [{idx}] å¤„ç†å¤±è´¥: {result.get('reason', 'Unknown error')}")
                        # è®°å½•å¤±è´¥é¡¹
                        failed_items.append({
                            'index': idx,
                            'reason': result.get('reason', 'Unknown error'),
                            'product_name': batch_products[idx - start_idx - 1].get('product_name', 'Unknown')
                        })
                        dropped_count += 1
                    elif result.get('dropped'):
                        # specsä¸ºç©ºï¼Œæ­£å¸¸è·³è¿‡
                        dropped_count += 1
                    else:
                        # æˆåŠŸæå–
                        processed_products.append(result['data'])
                except Exception as e:
                    print(f"      [{idx}] å¼‚å¸¸: {e}")
                    # è®°å½•å¼‚å¸¸é¡¹
                    failed_items.append({
                        'index': idx,
                        'reason': str(e),
                        'product_name': batch_products[idx - start_idx - 1].get('product_name', 'Unknown')
                    })
                    dropped_count += 1

    elapsed = time.time() - start_time
    print(f"\n  [å®Œæˆ] å¹¶å‘å¤„ç†è€—æ—¶: {elapsed:.1f}ç§’")

    if dropped_count > 0:
        print(f"[OK] è¿‡æ»¤æ‰ {dropped_count} ä¸ªæ— æ•ˆäº§å“")

    # ä¿å­˜å¤±è´¥é¡¹åˆ°æ—¥å¿—
    if failed_items:
        from datetime import datetime
        log_dir = Path('logs')
        log_dir.mkdir(exist_ok=True)
        log_file = log_dir / f'failed_items_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
        with open(log_file, 'w', encoding='utf-8') as f:
            json.dump(failed_items, f, ensure_ascii=False, indent=2)
        print(f"[INFO] å¤±è´¥é¡¹å·²è®°å½•åˆ°: {log_file}")

    # æ­¥éª¤ 2.5: æŒ‰ä¼˜å…ˆçº§æ’åºäº§å“ï¼ˆå“ç‰Œæƒé‡ + æ–‡ç« é•¿åº¦ï¼‰
    print(f"\n[æ­¥éª¤ 2.5/5] æŒ‰ä¼˜å…ˆçº§æ’åºäº§å“...")
    # ä¸ºæ¯ä¸ªäº§å“è®¡ç®—ä¼˜å…ˆçº§åˆ†æ•°
    for product in processed_products:
        product['_priority_score'] = extractor.calculate_product_priority(product)

    # æŒ‰ä¼˜å…ˆçº§åˆ†æ•°é™åºæ’åº
    processed_products.sort(key=lambda p: p.get('_priority_score', 0), reverse=True)
    print(f"[OK] å·²æŒ‰ä¼˜å…ˆçº§æ’åºï¼ˆå“ç‰Œæƒé‡ + æ–‡ç« é•¿åº¦ + å›¾ç‰‡æ•°é‡ï¼‰")

    # æ­¥éª¤ 3: ç”Ÿæˆæ·±è‰²æå®¢é£ HTML æŠ¥å‘Šï¼ˆå«äº§å“åˆå¹¶ï¼‰
    print(f"\n[æ­¥éª¤ 3/5] ç”Ÿæˆæ·±è‰²æå®¢é£ HTML æŠ¥å‘Š")
    generator = HTMLReportGenerator(processed_products)
    generator.generate(HTML_REPORT)

    # ä¿å­˜åˆå¹¶åçš„æ•°æ®
    with open(PROCESSED_JSON, 'w', encoding='utf-8') as f:
        json.dump(generator.products, f, ensure_ascii=False, indent=2)
    print(f"[OK] åˆå¹¶åæ•°æ®å·²ä¿å­˜: {PROCESSED_JSON} ({len(generator.products)} æ¬¾äº§å“)")

    # æ­¥éª¤ 4: å®Œæˆ
    print(f"\n[æ­¥éª¤ 4/5] å…¨éƒ¨å®Œæˆï¼")
    print(f"\näº¤ä»˜ç‰©æ¸…å•:")
    print(f"  1. {PROCESSED_JSON} ({len(generator.products)} æ¬¾äº§å“)")
    print(f"  2. {HTML_REPORT}")
    print(f"\næ–°ç‰¹æ€§:")
    print(f"  [+] äº§å“æ™ºèƒ½å»é‡ä¸åˆå¹¶")
    print(f"  [+] å®æ—¶æœç´¢è¿‡æ»¤")
    print(f"  [+] åˆ†ç±»é”šç‚¹å¯¼èˆª")
    print(f"  [+] å›åˆ°é¡¶éƒ¨æŒ‰é’®")
    print(f"  [+] å›¾ç‰‡æ‡’åŠ è½½ + Lightboxé¢„è§ˆ")
    print(f"  [+] PMæ´å¯Ÿä¸ºç©ºæ—¶çš„è‡ªé€‚åº”å¸ƒå±€")
    print(f"\n" + "=" * 60)


def main(template_mode="pm_deep", input_file=None, target_year=None, target_month=None):
    """ä¸»æµç¨‹

    Args:
        template_mode: æ¨¡æ¿æ¨¡å¼ï¼Œ"pm_deep" (é»˜è®¤) æˆ– "simple"
        input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœä¸º Noneï¼Œåˆ™ä½¿ç”¨é»˜è®¤è·¯å¾„ï¼‰
        target_year: ç›®æ ‡å¹´ä»½ï¼ˆå¦‚æœä¸º Noneï¼Œåˆ™ä½¿ç”¨ TARGET_YEARï¼‰
        target_month: ç›®æ ‡æœˆä»½ï¼ˆå¦‚æœä¸º Noneï¼Œåˆ™ä½¿ç”¨ TARGET_MONTHï¼‰
    """
    global TEMPLATE_MODE, HTML_REPORT, TARGET_YEAR, TARGET_MONTH
    TEMPLATE_MODE = template_mode

    # æ›´æ–°å…¨å±€é…ç½®
    if target_year is not None:
        TARGET_YEAR = target_year
    if target_month is not None:
        TARGET_MONTH = target_month

    print("=" * 60)
    print("å¤–è®¾æ–°å“ç›‘æ§æŠ¥å‘Šç”Ÿæˆç³»ç»Ÿ (Phase 4 æœ€ç»ˆä¼˜åŒ–ç‰ˆ)")
    print(f"æ¨¡æ¿æ¨¡å¼: {AVAILABLE_TEMPLATES.get(template_mode, template_mode)}")
    print(f"ç›®æ ‡æœŸé—´: {TARGET_YEAR}å¹´{TARGET_MONTH}æœˆ")
    print("PM æ·±åº¦åˆ†æç‰ˆ | äº§å“å»é‡åˆå¹¶ | äº¤äº’ä¼˜åŒ–")
    print("=" * 60)

    # ç¡®å®šè¾“å…¥æ–‡ä»¶è·¯å¾„
    if input_file is None:
        input_file = f'output/report_data_{TARGET_YEAR}_{TARGET_MONTH:02d}.json'

    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    input_path = Path(input_file)
    if not input_path.exists():
        # å°è¯• Excel æ ¼å¼
        excel_path = Path(str(input_path).replace('.json', '.xlsx'))
        if excel_path.exists():
            input_path = excel_path
        else:
            print(f"\n[ERROR] è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
            print(f"\nè¯·å…ˆè¿è¡Œçˆ¬è™«é‡‡é›†æ•°æ®ï¼Œæˆ–ä½¿ç”¨ --input å‚æ•°æŒ‡å®šè¾“å…¥æ–‡ä»¶ï¼š")
            print(f"  python etl_pipeline.py --input <your_data.json>")
            print(f"  python etl_pipeline.py --month {TARGET_YEAR}-{TARGET_MONTH:02d}")
            raise SystemExit(1)

    print(f"\n[INFO] è¾“å…¥æ–‡ä»¶: {input_path}")

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    OUTPUT_DIR.mkdir(exist_ok=True)

    # æ­¥éª¤ 1: æ•°æ®æ¸…æ´—
    print("\n[æ­¥éª¤ 1/5] æ•°æ®é¢„å¤„ç†ä¸æ¸…æ´—")
    cleaner = DataCleaner(str(input_path))
    filtered_df = cleaner.filter_by_keywords()
    filtered_df = cleaner.filter_by_blacklist(filtered_df)  # é»‘åå•è¿‡æ»¤
    products = cleaner.smart_deduplicate(filtered_df)

    # æ­¥éª¤ 2: LLM PM æ·±åº¦åˆ†æï¼ˆå¹¶å‘å¤„ç†ï¼‰
    print(f"\n[æ­¥éª¤ 2/5] LLM PM æ·±åº¦åˆ†æï¼ˆå¹¶å‘æ¨¡å¼ï¼‰")
    extractor = LLMExtractor(LLM_CONFIG)

    # åˆå§‹åŒ–å‚æ•°è¡¥å…¨å™¨ V2ï¼ˆTop 15 Schemaï¼‰
    print(f"\n[æ­¥éª¤ 2.1/5] åˆå§‹åŒ–å‚æ•°è¡¥å…¨å™¨V2ï¼ˆTop 15 Schemaï¼‰...")

    completer = ParameterCompleterV2(llm_config=LLM_CONFIG, search_func=None)
    print(f"[OK] å‚æ•°è¡¥å…¨å™¨V2å·²åˆå§‹åŒ–ï¼ˆTop 15 Schemaï¼Œæœç´¢åŠŸèƒ½å·²ç¦ç”¨ï¼‰")

    import concurrent.futures
    import time

    # å¹¶å‘å¤„ç†é…ç½®
    batch_size = 5
    total_products = len(products)
    total_batches = (total_products + batch_size - 1) // batch_size

    print(f"  æ€»äº§å“æ•°: {total_products}")
    print(f"  å¹¶å‘æ•°: {batch_size}")
    print(f"  åˆ†æ‰¹æ•°: {total_batches}")
    print()

    processed_products = []
    dropped_count = 0
    failed_items = []
    start_time = time.time()

    # åˆ†æ‰¹å¹¶å‘å¤„ç†
    for batch_idx in range(total_batches):
        start_idx = batch_idx * batch_size
        end_idx = min(start_idx + batch_size, total_products)
        batch_products = products[start_idx:end_idx]

        print(f"[æ‰¹æ¬¡ {batch_idx + 1}/{total_batches}] å¤„ç†äº§å“ {start_idx + 1}-{end_idx}...")

        with concurrent.futures.ThreadPoolExecutor(max_workers=batch_size) as executor:
            future_to_idx = {
                executor.submit(process_single_product, extractor, completer, product, idx + 1): idx + 1
                for idx, product in enumerate(batch_products, start_idx)
            }

            for future in concurrent.futures.as_completed(future_to_idx):
                idx = future_to_idx[future]
                try:
                    result = future.result()
                    if result.get('error'):
                        print(f"      [{idx}] å¤„ç†å¤±è´¥: {result.get('reason', 'Unknown error')}")
                        failed_items.append({
                            'index': idx,
                            'reason': result.get('reason', 'Unknown error'),
                            'product_name': batch_products[idx - start_idx - 1].get('product_name', 'Unknown')
                        })
                        dropped_count += 1
                    elif result.get('dropped'):
                        dropped_count += 1
                    else:
                        processed_products.append(result['data'])
                except Exception as e:
                    print(f"      [{idx}] å¼‚å¸¸: {e}")
                    failed_items.append({
                        'index': idx,
                        'reason': str(e),
                        'product_name': batch_products[idx - start_idx - 1].get('product_name', 'Unknown')
                    })
                    dropped_count += 1

    elapsed = time.time() - start_time
    print(f"\n  [å®Œæˆ] å¹¶å‘å¤„ç†è€—æ—¶: {elapsed:.1f}ç§’")

    if dropped_count > 0:
        print(f"[OK] è¿‡æ»¤æ‰ {dropped_count} ä¸ªæ— æ•ˆäº§å“")

    # ä¿å­˜å¤±è´¥é¡¹åˆ°æ—¥å¿—
    if failed_items:
        from datetime import datetime
        log_dir = Path('logs')
        log_dir.mkdir(exist_ok=True)
        log_file = log_dir / f'failed_items_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
        with open(log_file, 'w', encoding='utf-8') as f:
            json.dump(failed_items, f, ensure_ascii=False, indent=2)
        print(f"[INFO] å¤±è´¥é¡¹å·²è®°å½•åˆ°: {log_file}")

    # æ­¥éª¤ 2.5: æŒ‰ä¼˜å…ˆçº§æ’åºäº§å“
    print(f"\n[æ­¥éª¤ 2.5/5] æŒ‰ä¼˜å…ˆçº§æ’åºäº§å“...")
    for product in processed_products:
        product['_priority_score'] = extractor.calculate_product_priority(product)
    processed_products.sort(key=lambda p: p.get('_priority_score', 0), reverse=True)
    print(f"[OK] å·²æŒ‰ä¼˜å…ˆçº§æ’åº")

    # æ­¥éª¤ 2.6: äºŒæ¬¡è¡¥å…¨ï¼ˆå¿…ç»æµç¨‹ï¼‰
    print(f"\n[æ­¥éª¤ 2.6/5] äºŒæ¬¡è¡¥å…¨ï¼ˆå¿…ç»æµç¨‹ï¼‰...")

    # ä¿å­˜è¡¥å…¨å‰çš„æ•°æ®ï¼ˆç”¨äºè¦†ç›–ç‡å¯¹æ¯”ï¼‰
    products_before_enrichment = [p.copy() for p in processed_products]

    processed_products = enrich_missing_fields(processed_products)

    # æ‰“å°è¡¥å…¨ç»Ÿè®¡æ‘˜è¦ï¼ˆåŒ…å«è¦†ç›–ç‡å¯¹æ¯”ï¼‰å¹¶è¿”å›ç»Ÿè®¡ä¿¡æ¯
    enrichment_summary = print_enrichment_summary(processed_products, products_before_enrichment)

    # æ£€æŸ¥è¦†ç›–ç‡å‘Šè­¦é˜ˆå€¼
    for category in ['é¼ æ ‡', 'é”®ç›˜']:
        if category in enrichment_summary['coverage']['after']:
            coverage_rate = enrichment_summary['coverage']['after'][category]['coverage']

            if coverage_rate < 30:
                print(f"\n[WARNING] {category} å…³é”®å­—æ®µè¦†ç›–ç‡ä»ç„¶è¾ƒä½: {coverage_rate:.1f}%")
                print(f"  å»ºè®®ï¼šæ£€æŸ¥è¾“å…¥æ•°æ®è´¨é‡ï¼Œæˆ–è€ƒè™‘å¯ç”¨è·¨æºè¡¥å…¨ï¼ˆSECOND_ROUND_MODE=search/bothï¼‰")

    print(f"[OK] äºŒæ¬¡è¡¥å…¨å®Œæˆ")

    # æ­¥éª¤ 3: ç”Ÿæˆ HTML æŠ¥å‘Š
    print(f"\n[æ­¥éª¤ 3/5] ç”Ÿæˆæ·±è‰²æå®¢é£ HTML æŠ¥å‘Š")
    generator = HTMLReportGenerator(processed_products)
    generator.generate(HTML_REPORT)

    # ä¿å­˜åˆå¹¶åçš„æ•°æ®
    with open(PROCESSED_JSON, 'w', encoding='utf-8') as f:
        json.dump(generator.products, f, ensure_ascii=False, indent=2)
    print(f"[OK] åˆå¹¶åæ•°æ®å·²ä¿å­˜: {PROCESSED_JSON} ({len(generator.products)} æ¬¾äº§å“)")
    print(f"[OK] HTML æŠ¥å‘Šå·²ç”Ÿæˆ: {HTML_REPORT}")

    # æ­¥éª¤ 4: å®Œæˆ
    print(f"\n[æ­¥éª¤ 4/5] å…¨éƒ¨å®Œæˆï¼")
    print(f"\näº¤ä»˜ç‰©æ¸…å•:")
    print(f"  1. {PROCESSED_JSON} ({len(generator.products)} æ¬¾äº§å“)")
    print(f"  2. {HTML_REPORT}")
    print(f"\n" + "=" * 60)

if __name__ == '__main__':
    import argparse
    import re

    parser = argparse.ArgumentParser(
        description='å¤–è®¾æ–°å“ç›‘æ§æŠ¥å‘Šç”Ÿæˆç³»ç»Ÿ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog='''
ç¤ºä¾‹ç”¨æ³•:
  # ä¸€é”®æ¨¡å¼ï¼šçˆ¬å– + ç”Ÿæˆ PM æ·±åº¦åˆ†æç‰ˆæŠ¥å‘Šï¼ˆæ¨èï¼‰
  python etl_pipeline.py --month 2026-01 --fetch --template pm_deep

  # ä½¿ç”¨é»˜è®¤è¾“å…¥æ–‡ä»¶ (output/report_data_2026_01.json)
  python etl_pipeline.py

  # æŒ‡å®šæœˆä»½ï¼ˆè‡ªåŠ¨æŸ¥æ‰¾ input/output/report_data_YYYY_MM.jsonï¼‰
  python etl_pipeline.py --month 2026-01

  # æŒ‡å®šè‡ªå®šä¹‰è¾“å…¥æ–‡ä»¶
  python etl_pipeline.py --input data/my_products.json

  # ç»„åˆä½¿ç”¨ï¼šæŒ‡å®šæœˆä»½å’Œæ¨¡æ¿
  python etl_pipeline.py --month 2026-01 --template pm_deep

  # ä»…æ ¡éªŒç°æœ‰æŠ¥å‘Š
  python etl_pipeline.py --validate-only --report-path output/monthly_report_2026_01.html

å¯ç”¨æ¨¡æ¿:
  pm_deep  - PMæ·±åº¦åˆ†æç‰ˆï¼ˆå®Œæ•´ä¸‰æ å¸ƒå±€ + nav-bar + æœç´¢ + PMæ·±åº¦æ´å¯Ÿï¼‰
  simple   - ç®€åŒ–ç‰ˆï¼ˆä»…åŸºæœ¬ä¿¡æ¯ï¼‰
        '''
    )

    parser.add_argument(
        '--template', '-t',
        type=str,
        default='pm_deep',
        choices=['pm_deep', 'simple'],
        help='æŠ¥å‘Šæ¨¡æ¿æ¨¡å¼ï¼ˆé»˜è®¤: pm_deepï¼‰'
    )

    parser.add_argument(
        '--month',
        type=str,
        metavar='YYYY-MM',
        help='ç›®æ ‡æœˆä»½ï¼ˆæ ¼å¼: YYYY-MMï¼Œå¦‚ 2026-01ï¼‰'
    )

    parser.add_argument(
        '--input',
        type=str,
        metavar='PATH',
        help='è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼ˆJSON æˆ– Excel æ ¼å¼ï¼‰'
    )

    parser.add_argument(
        '--validate-only',
        action='store_true',
        help='ä»…æ ¡éªŒç°æœ‰HTMLæŠ¥å‘Šï¼Œä¸ç”Ÿæˆæ–°æŠ¥å‘Š'
    )

    parser.add_argument(
        '--report-path',
        type=str,
        default=None,
        help='è¦æ ¡éªŒçš„HTMLæŠ¥å‘Šè·¯å¾„'
    )

    parser.add_argument(
        '--fetch', '--crawl',
        action='store_true',
        help='å…ˆè¿è¡Œçˆ¬è™«é‡‡é›†æ•°æ®ï¼Œå†ç”ŸæˆæŠ¥å‘Šï¼ˆä¸€é”®æ¨¡å¼ï¼‰'
    )

    parser.add_argument(
        '--force',
        action='store_true',
        help='æ•°æ®ä¸€è‡´æ€§æ ¡éªŒå¤±è´¥æ—¶ä»å¼ºåˆ¶è¾“å‡ºï¼ˆä»…ç»•è¿‡æ•°æ®ä¸€è‡´æ€§æ ¡éªŒï¼Œä¸ç»•è¿‡ç»“æ„æ€§æ ¡éªŒï¼‰'
    )

    args = parser.parse_args()

    # è§£æ --month å‚æ•°
    target_year = None
    target_month = None

    if args.month:
        match = re.match(r'(\d{4})-(\d{2})', args.month)
        if not match:
            print(f"[ERROR] æ— æ•ˆçš„æœˆä»½æ ¼å¼: {args.month}")
            print("æ­£ç¡®æ ¼å¼: YYYY-MM (ä¾‹å¦‚: 2026-01)")
            raise SystemExit(1)
        target_year = int(match.group(1))
        target_month = int(match.group(2))

    # å¦‚æœä½¿ç”¨ --fetchï¼Œç¡®ä¿æä¾›äº† --month
    if args.fetch:
        if target_year is None or target_month is None:
            # ä½¿ç”¨é»˜è®¤å€¼
            target_year = TARGET_YEAR
            target_month = TARGET_MONTH

        # è¿è¡Œçˆ¬è™«
        fetch_data(target_year, target_month)

    # ç¡®å®š report_path é»˜è®¤å€¼
    if args.report_path is None:
        args.report_path = str(HTML_REPORT)

    if args.validate_only:
        # ä»…æ ¡éªŒæ¨¡å¼
        validate_html_report(args.report_path, force=args.force)

        # [FIX E] å¦‚æœå­˜åœ¨ processed_products.jsonï¼Œä¹Ÿè¾“å‡º enrichment summary
        json_path = Path(str(args.report_path).replace('.html', '.json'))
        if not json_path.exists():
            json_path = PROCESSED_JSON

        if json_path.exists():
            print("\n" + "=" * 60)
            print("æ‰§è¡Œ enrichment ç»Ÿè®¡æ ¡éªŒ...")
            print("=" * 60)
            validate_enrichment_summary(str(json_path))
        else:
            print(f"\n[INFO] æœªæ‰¾åˆ° enrichment æ•°æ®æ–‡ä»¶: {json_path}")
            print("  è·³è¿‡ enrichment ç»Ÿè®¡æ ¡éªŒ")
    else:
        # ç”ŸæˆæŠ¥å‘Šæ¨¡å¼
        main(
            template_mode=args.template,
            input_file=args.input,
            target_year=target_year,
            target_month=target_month
        )
        # ç”Ÿæˆåè‡ªåŠ¨æ ¡éªŒ
        print("\n" + "=" * 60)
        print("æ‰§è¡Œç”Ÿæˆåæ ¡éªŒ...")
        print("=" * 60)
        validate_html_report(str(HTML_REPORT), force=args.force)
