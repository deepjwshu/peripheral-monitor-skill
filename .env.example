# ==================== LLM API 配置 ====================

# LLM 服务提供商
# 可选值: deepseek, openai, anthropic, custom
LLM_PROVIDER=deepseek

# API Key (必需)
# 获取方式: https://platform.deepseek.com/api_keys
LLM_API_KEY=your_api_key_here

# API Base URL (必需)
# DeepSeek 官方: https://api.deepseek.com/v1
# 公司内部: http://192.168.0.250:7777
LLM_API_BASE=https://api.deepseek.com/v1

# 模型名称 (必需)
# DeepSeek: deepseek-chat
# 公司内部: xdeepseekv3
LLM_MODEL=deepseek-chat

# 请求超时时间（秒）
LLM_TIMEOUT=120

# ==================== 目标年月配置 ====================

# 目标年份
TARGET_YEAR=2026

# 目标月份
TARGET_MONTH=1

# ==================== 数据采集配置 ====================

# 是否启用爬虫
SPIDER_ENABLED=true

# 爬取来源平台
# 可选值: inwaishe, wstx, all
SPIDER_SOURCES=all

# 请求延时配置（秒）
# [NEW] 统一延时配置：基础延时 + 随机抖动
# 实际延时 = SPIDER_DELAY_SECONDS + random(-SPIDER_DELAY_JITTER, +SPIDER_DELAY_JITTER)
# 示例：2.0 + 1.0 = 实际延时范围 1.0~3.0 秒
SPIDER_DELAY_SECONDS=2.0
SPIDER_DELAY_JITTER=1.0

# 旧配置（已弃用，保留用于向后兼容）
# SPIDER_MIN_DELAY=1.0
# SPIDER_MAX_DELAY=3.0

# ==================== 输出配置 ====================

# 输出目录
OUTPUT_DIR=output

# 是否生成 Excel 文件
OUTPUT_EXCEL=true

# 是否生成 JSON 文件
OUTPUT_JSON=true

# ==================== ETL 配置 ====================

# 并发 LLM 请求数
MAX_WORKERS=10

# ==================== MCP 搜索服务配置 ====================
# 用于二次参数补全的跨源搜索能力（公司内部 MCP 服务）

# 是否启用 MCP 搜索服务
# 可选值: true, false
# - true: 启用 MCP 搜索（需要配置以下参数）
# - false: 禁用 MCP 搜索（默认，仅使用本地数据）
MCP_SEARCH_ENABLED=false

# MCP 服务基础 URL（公司内部部署地址）
# 示例: http://192.168.0.250:7891
MCP_BASE_URL=http://192.168.0.250:7891

# MCP 认证 Token（必需）
# 从管理员处获取
MCP_TOKEN=your_mcp_token_here

# MCP 搜索服务端点（可选，默认为 BASE_URL/mcp_web_search）
MCP_SEARCH_ENDPOINT=http://192.168.0.250:7891/mcp_web_search

# MCP 网页抓取服务端点（可选，默认为 BASE_URL/mcp_web_reader）
MCP_READER_ENDPOINT=http://192.168.0.250:7891/mcp_web_reader

# MCP 请求超时时间（秒）
MCP_TIMEOUT=30

# ==================== 二次补全配置 ====================
# [FIX E] 二次补全现为必经流程（mandatory stage），始终执行
# 以下配置仅用于"上限控制/成本限制"，不影响是否执行

# 二次补全模式（local 为必跑模式）
# local: 仅同源补全（从已抓取文章中提取，无额外成本）【默认必跑】
# search: 跨源补全（需要搜索/MCP服务，会产生额外API调用）【预留】
# both: 同源+跨源（先local后search）【预留】
SECOND_ROUND_MODE=local

# 二次补全：最多处理的产品数（上限控制）
SECOND_ROUND_MAX_ITEMS=10

# 二次补全：每个产品最多补全字段数（上限控制）
SECOND_ROUND_MAX_FIELDS_PER_ITEM=6

# 二次补全：每个产品最多跨源搜索次数（仅 search/both 模式有效）
SECOND_ROUND_MAX_SEARCH_PER_PRODUCT=2

# 二次补全：inferred 字段是否计入 coverage 统计（默认 false）
# true: LLM 推断值计入覆盖率
# false: 只有原始明确值 + 规则补全值计入覆盖率
COUNT_INFERRED_IN_COVERAGE=false

# ⚠️ 已废弃配置（以下配置不再生效，建议删除）：
# SECOND_ROUND_ENABLED=false  （此开关已废弃，二次补全始终执行）

# ==================== 报告配置 ====================

# 报告模板模式
# 可选值: pm_deep, simple
TEMPLATE_MODE=pm_deep

# 是否启用自动校验
AUTO_VALIDATE=true

# ==================== 调试配置 ====================

# 调试模式
DEBUG=false

# 日志级别
# 可选值: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# 日志文件
LOG_FILE=etl_pipeline.log
